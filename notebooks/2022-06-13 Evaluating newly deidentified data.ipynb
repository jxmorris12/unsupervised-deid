{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee3af336-3aa6-4a1f-9697-7f430b398e58",
   "metadata": {},
   "source": [
    "### Evaluating deidentified data\n",
    "\n",
    "After about a month of improving the model I deidentified some new data and want to see how it compares to the old data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d407a-edc2-4835-a333-3a5a81449d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')\n",
    "\n",
    "from dataloader import WikipediaDataModule\n",
    "\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "dm = WikipediaDataModule(\n",
    "    document_model_name_or_path=\"roberta-base\",\n",
    "    profile_model_name_or_path=\"google/tapas-base\",\n",
    "    max_seq_length=128,\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:1]', # not used\n",
    "    dataset_val_split='val[:20%]',\n",
    "    dataset_version='1.2.0',\n",
    "    word_dropout_ratio=0.0,\n",
    "    word_dropout_perc=0.0,\n",
    "    num_workers=1,\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff1f642-1464-4420-a5e7-08df93299d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad55fa6-5343-4387-b24a-a4fe11b2fea6",
   "metadata": {},
   "source": [
    "### Load pre-generated redacted data from various models.\n",
    "\n",
    "Models are explained in `../model_cfg.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8db17d85-a174-4571-9c5e-b32268eef2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_4 ['../adv_csvs/model_4/results_1_100.csv']\n",
      "model_5 ['../adv_csvs/model_5/results_1_100.csv']\n",
      "model_6 ['../adv_csvs/model_6/results_1_100.csv']\n",
      "model_7 []\n",
      "model_8 ['../adv_csvs/model_8_1day/results_1_1000.csv', '../adv_csvs/model_8_ls0.1/results_1_1000.csv', '../adv_csvs/model_8_ls0.01/results_1_1000.csv']\n",
      "model_9 ['../adv_csvs/model_9_ls0.1/results_1_1000.csv', '../adv_csvs/model_9_ls0.01/results_1_1000.csv', '../adv_csvs/model_9_ls0.05/results_1_1000.csv']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "adv_df = None\n",
    "for model_name in ['model_4', 'model_5', 'model_6', 'model_7', 'model_8', 'model_9']:\n",
    "    csv_filenames = glob.glob(f'../adv_csvs/{model_name}*/results_1_*0.csv')\n",
    "    print(model_name, csv_filenames)\n",
    "    for filename in csv_filenames:\n",
    "        df = pd.read_csv(filename)\n",
    "        df['model_name'] = re.search(r'adv_csvs/(model_\\d.*)/.+.csv', filename).group(1)\n",
    "        df['i'] = df.index\n",
    "        mini_df = df[['perturbed_text', 'model_name', 'i']]\n",
    "        \n",
    "        mini_df = mini_df.iloc[:100]\n",
    "        \n",
    "        if adv_df is None:\n",
    "            adv_df = mini_df\n",
    "        else:\n",
    "            adv_df = pd.concat((adv_df, mini_df), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "831f1d03-5195-45a2-bc3d-39f159a0d89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_5</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_6</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8_1day</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8_ls0.01</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_8_ls0.1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_9_ls0.01</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_9_ls0.05</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_9_ls0.1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                perturbed_text    i\n",
       "model_name                         \n",
       "model_4                    100  100\n",
       "model_5                    100  100\n",
       "model_6                    100  100\n",
       "model_8_1day               100  100\n",
       "model_8_ls0.01             100  100\n",
       "model_8_ls0.1              100  100\n",
       "model_9_ls0.01             100  100\n",
       "model_9_ls0.05             100  100\n",
       "model_9_ls0.1              100  100"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_df.groupby('model_name').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3fb6a4-9cbe-4dc6-b55d-f2e582396d2d",
   "metadata": {},
   "source": [
    "### Get baseline redacted data\n",
    "\n",
    "Redacted via NER and Lexical redaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "27f0ab95-ed25-4523-8372-a0f727bfe101",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_val_dataset = dm.val_dataset[:100]\n",
    "ner_df = pd.DataFrame(\n",
    "    columns=['perturbed_text'],\n",
    "    data=mini_val_dataset['document_redact_ner']\n",
    ")\n",
    "ner_df['model_name'] = 'named_entity'\n",
    "ner_df['i'] = ner_df.index\n",
    "       \n",
    "lex_df = pd.DataFrame(\n",
    "    columns=['perturbed_text'],\n",
    "    data=mini_val_dataset['document_redact_lexical']\n",
    ")\n",
    "lex_df['model_name'] = 'lexical'\n",
    "lex_df['i'] = lex_df.index\n",
    "\n",
    "baseline_df = pd.concat((lex_df, ner_df), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "09c8b0d3-2053-4154-98cc-642fa875fb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>model_name</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; ( also know...</td>\n",
       "      <td>lexical</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; is a male former table tennis pl...</td>\n",
       "      <td>lexical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; ( born &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; ) is...</td>\n",
       "      <td>lexical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; , ( born &lt;mask&gt; &lt;mask&gt; , &lt;mask&gt; ...</td>\n",
       "      <td>lexical</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;mask&gt; l. &lt;mask&gt; is a former &lt;mask&gt; member of ...</td>\n",
       "      <td>lexical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      perturbed_text model_name  i\n",
       "0  <mask> <mask> <mask> <mask> <mask> ( also know...    lexical  0\n",
       "1  <mask> <mask> is a male former table tennis pl...    lexical  1\n",
       "2  <mask> <mask> ( born <mask> <mask> <mask> ) is...    lexical  2\n",
       "3  <mask> <mask> , ( born <mask> <mask> , <mask> ...    lexical  3\n",
       "4  <mask> l. <mask> is a former <mask> member of ...    lexical  4"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae7d0c10-2f6a-4ee6-836b-a3cc73e2084d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_4           100\n",
       "model_5           100\n",
       "model_6           100\n",
       "model_8_1day      100\n",
       "model_8_ls0.1     100\n",
       "model_8_ls0.01    100\n",
       "model_9_ls0.1     100\n",
       "model_9_ls0.01    100\n",
       "model_9_ls0.05    100\n",
       "lexical           100\n",
       "named_entity      100\n",
       "Name: model_name, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat((adv_df, baseline_df), axis=0)\n",
    "full_df['model_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e60d4f1-21de-4b56-8294-589c8521cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line puts newlines back\n",
    "full_df['perturbed_text'] = full_df['perturbed_text'].apply(lambda s: s.replace('<SPLIT>', '\\n'))\n",
    "\n",
    "# this line replaces BERT-style masks (from PMLM) with roberta-style ones, so we can\n",
    "# count them in a single command\n",
    "full_df['perturbed_text'] = full_df['perturbed_text'].apply(lambda s: s.replace('[MASK]', '<mask>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a07d4-d5d2-4861-8a1c-e26dcb05d2ef",
   "metadata": {},
   "source": [
    "### Truncating\n",
    "\n",
    "Hugely important step that was missing in the prior analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8d18cd42-940d-412b-a038-a655a4cb8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60f96e1c-b126-4edd-b620-a347db34b9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mask> <mask> (born 4 <mask> <mask>) is a danish professional football midfielder , who currently plays for danish 1st division side <mask> boldklub .\n",
      "<mask> began playing football in kolt-hasselager if , where he was picked for agf , where he got his other footballing education .\n",
      "he was part of the year ' 88 , who won in the junior league , like michael lumb , frederik krabbe , michael vester , niels kristensen , morten beck andersen and anders syberg , who all had the onset of agf 's 1 .\n",
      "hold .\n",
      "in the autumn of 2009 he was loaned to næstved bk , and just before winter transfer window end he switched permanently to the club .\n",
      "in 2010 he changed to fc fredericia , where he played until 2012 when he got vendsyssel ff as a new club in january 2015 he was given at his own request that he want to terminated his contract with the vendsyssel ff .\n",
      "on 6 february 2015 he signed a two-year contract with lyngby boldklub\n",
      "\n",
      "\n",
      "<mask> <mask> (born 4 <mask> <mask> ) is a danish professional football midfielder, who currently plays for danish 1st division side <mask> boldklub. <mask> began playing football in kolt-hasselager if, where he was picked for agf, where he got his other footballing education.\n",
      "he was part of the year'88, who won in the junior league, like michael lumb, frederik krabbe, michael vester, niels kristensen, morten beck andersen and anders syberg, who all had the onset of agf's 1.\n"
     ]
    }
   ],
   "source": [
    "def truncate_text(text: str, max_length=128) -> str:\n",
    "    input_ids = tokenizer(text, truncation=True, max_length=128)['input_ids']\n",
    "    reconstructed_text = (\n",
    "        tokenizer\n",
    "            .decode(input_ids)\n",
    "            .replace('<mask>', ' <mask> ')\n",
    "            .replace('  <mask>', ' <mask>')\n",
    "            .replace('<mask>  ', '<mask> ')\n",
    "            .replace('<s>', '')\n",
    "            .replace('</s>', '')\n",
    "            .strip()\n",
    "    )\n",
    "    return reconstructed_text\n",
    "\n",
    "# truncate_text(sample_long_text)\n",
    "sample_long_text = full_df['perturbed_text'].iloc[14]\n",
    "print(sample_long_text)\n",
    "print()\n",
    "print(truncate_text(sample_long_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bb57c311-625e-4b52-8f9d-0660b844fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['perturbed_text_truncated'] = full_df['perturbed_text'].apply(truncate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7183217-9829-479d-9c48-107dcf058c66",
   "metadata": {},
   "source": [
    "### Measuring utility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca4a54-e410-4cc7-bc4a-b611a34182d4",
   "metadata": {},
   "source": [
    "Unit 1: number of redacted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c8323e45-6c62-4e9f-8481-04abd3cfeeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_masks(s):\n",
    "    return s.count('<mask>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fc33e2cd-5366-44ab-82e6-b5238623177d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "lexical           16.51\n",
       "model_4            9.45\n",
       "model_5           10.14\n",
       "model_6            3.54\n",
       "model_8_1day      14.25\n",
       "model_8_ls0.01    13.10\n",
       "model_8_ls0.1     12.96\n",
       "model_9_ls0.01    10.51\n",
       "model_9_ls0.05     9.41\n",
       "model_9_ls0.1      8.57\n",
       "named_entity      13.94\n",
       "Name: num_masks, dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df['num_masks'] = full_df.apply(lambda s: count_masks(s['perturbed_text_truncated']), axis=1)\n",
    "full_df.groupby('model_name').mean()['num_masks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb4ae06-7b50-4ceb-8ac5-dcebe6b52119",
   "metadata": {},
   "source": [
    "Unit 2: compressed size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ea949db6-a381-41d0-8b86-411d5cccf3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zlib\n",
    "\n",
    "def count_compressed_bytes(s: str) -> int:\n",
    "    return len(zlib.compress(s.encode()))\n",
    "\n",
    "teststr = \"\"\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus\n",
    "pretium justo eget elit eleifend, et dignissim quam eleifend. Nam vehicula nisl\n",
    "posuere velit volutpat, vitae scelerisque nisl imperdiet. Phasellus dignissim,\n",
    "dolor amet.\"\"\"\n",
    "\n",
    "count_compressed_bytes(teststr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "42c2f557-e424-455d-b989-700f2fd2a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text_truncated = [truncate_text(d) for d in mini_val_dataset['document']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dffd904e-fd35-4309-92c9-5179675e7dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "lexical           0.154175\n",
       "model_4           0.097302\n",
       "model_5           0.105630\n",
       "model_6           0.040074\n",
       "model_8_1day      0.128408\n",
       "model_8_ls0.01    0.112535\n",
       "model_8_ls0.1     0.115951\n",
       "model_9_ls0.01    0.091608\n",
       "model_9_ls0.05    0.098014\n",
       "model_9_ls0.1     0.083707\n",
       "named_entity      0.125845\n",
       "dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_total_bytes = count_compressed_bytes('\\n'.join(original_text_truncated))\n",
    "\n",
    "1 - full_df.groupby('model_name').apply(lambda s: count_compressed_bytes('\\n'.join(s['perturbed_text_truncated']))) / original_total_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138c756-198e-48e8-a96d-9a23872c8dea",
   "metadata": {},
   "source": [
    "### Reidentification rate (privacy metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee4b5d33-67a4-4616-b28f-ced248d5ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def get_words_from_doc(s: List[str]) -> List[str]:\n",
    "    words = s.split()\n",
    "    return [w for w in words if not w in eng_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9ac5f5c-be5a-475e-984d-6b6ed128ae82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-ba6837fc22371371.arrow\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def get_words_from_doc(s: List[str]) -> List[str]:\n",
    "    words = s.split()\n",
    "    return [w for w in words if not w in eng_stopwords]\n",
    "\n",
    "import datasets\n",
    "\n",
    "split = 'val[:20%]'\n",
    "prof_data = datasets.load_dataset('wiki_bio', split=split, version='1.2.0')\n",
    "\n",
    "def make_table_str(ex):\n",
    "    ex['table_str'] = (\n",
    "        ' '.join(ex['input_text']['table']['column_header'] + ex['input_text']['table']['content'])\n",
    "    )\n",
    "    return ex\n",
    "\n",
    "prof_data = prof_data.map(make_table_str)\n",
    "profile_corpus = prof_data['table_str']\n",
    "\n",
    "tokenized_profile_corpus = [\n",
    "    get_words_from_doc(prof) for prof in profile_corpus\n",
    "]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_profile_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d7813ad2-5f56-417d-9862-fb14a7cec6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k(ex):\n",
    "    query = ex[\"perturbed_text_truncated\"].split()\n",
    "    top_k = bm25.get_scores(query).argsort()[::-1]\n",
    "    ex[\"correct_idx\"] = top_k.tolist().index(ex[\"i\"])\n",
    "    ex[\"is_correct\"] = 1 if top_k[0] == ex[\"i\"] else 0\n",
    "    return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89400d-350e-498b-9d49-74bca3f9fee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b9add39e0d4549aa0d83badd02cd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_proc = min(8, len(os.sched_getaffinity(0)))\n",
    "full_df = full_df.progress_apply(get_top_k, axis=1)\n",
    "print(full_df[\"is_correct\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bd6f1387-bc18-4699-bc34-ac27112e3c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "lexical            0.0\n",
       "model_4           33.0\n",
       "model_5           34.0\n",
       "model_6           65.0\n",
       "model_8_1day      26.0\n",
       "model_8_ls0.01    37.0\n",
       "model_8_ls0.1     31.0\n",
       "model_9_ls0.01    48.0\n",
       "model_9_ls0.05    46.0\n",
       "model_9_ls0.1     50.0\n",
       "named_entity      66.0\n",
       "Name: is_correct, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby('model_name').mean()['is_correct'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dc13864d-8fcd-4c90-baf0-117c2ab100be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['perturbed_text', 'model_name', 'i', 'perturbed_text_truncated',\n",
       "       'num_masks', 'correct_idx', 'is_correct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "df344a42-4c2e-4bcb-8d93-645a67feb8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "pope michael <mask> of alexandria ( also known as khail <mask> ) was the coptic pope of alexandria and <mask> <mask> the <mask> of st. mark ( <mask> -- <mask> ).\n",
      "in <mask> , the governor of egypt, ahmad ibn tulun, forced khail to pay heavy contributions, forcing him to sell a church and some attached properties to the local jewish community.\n",
      "this building was at one time believed to have later become the site of the cairo geniza.\n",
      "\n",
      "\n",
      "7\n",
      "<mask> <mask> ( born <mask> neil morrison on 22 <mask> <mask> ) is a <mask> musician and author, best known as the singer of indie <mask> band carter <mask> .\n",
      "\n",
      "\n",
      "8\n",
      "<mask> <mask> ( born <mask> <mask> , <mask> in emporia, <mask> ) is a former professional american football defensive <mask> for the seattle seahawks, san diego chargers, new england patriots, baltimore ravens, and san francisco 49ers of the national football league.\n",
      "\n",
      "\n",
      "11\n",
      "<mask> <mask> ( born <mask> <mask> , <mask> in <mask> , switzerland ) is a retired swiss professional ice hockey <mask> .\n",
      "playing <mask> the nla-a, <mask> accumulated 74 goals, 173 assists, and 443 penalty minutes in the regular season.\n",
      "since the nla <mask> season, <mask> has been the general manager ( sports director ) of the <mask> <mask> .\n",
      "on august 1, <mask> <mask> bern's coach suffered, john van boxmeer, a heart attack side-lining him <mask> a month.\n",
      "during van boxmeer's absence, general manager sven leuenberger coached the team\n",
      "\n",
      "\n",
      "18\n",
      "<mask> m. <mask> is an american politician, a democrat and <mask> member of the maryland house <mask> delegates.\n",
      "\n",
      "\n",
      "19\n",
      "<mask> <mask> <mask> ( born <mask> <mask> <mask> ) is a <mask> footballer who currently plays for <mask> <mask> <mask> scottish premiership.\n",
      "his usual position is right <mask> , but can also play at centre back or on the right wing. <mask> started his career at motherwell and has also played for cardiff city, doncaster rovers, and ross county.\n",
      "\n",
      "\n",
      "22\n",
      "<mask> <mask> is an <mask> <mask> <mask> chairman <mask> the <mask> <mask> party ( alp ).\n",
      "first entering <mask> <mask> 1984 when <mask> was made a <mask> without portfolio <mask> the <mask> of <mask> bird, <mask> <mask> minister <mask> finance seven years later, <mask> the <mask> national <mask> and introducing fiscal reforms.\n",
      "after a <mask> scandal in which it was discovered he had used his position to <mask> a 1930s rolls royce for a friend, <mask> normal <mask> duties and <mask> , he was dismissed from the bird administration, <mask> 14 <mask> <mask> to serve as minister for <mask> , implementation and the <mask> .\n",
      "following the <mask> general election he became minister\n",
      "\n",
      "\n",
      "23\n",
      "<mask> henri <mask> <mask> ( b. <mask> wijnegem ( <mask> ), <mask> <mask> <mask> ; d. <mask> leuven, 25 december <mask> ) was a belgian archeologist and historian.\n",
      "sent to the university of leuven immediately after his ordination to the priesthood ( <mask> ), he soon became head librarian of the university ( <mask> -- 1896 ).\n",
      "he collaborated with his rector, pierre françois xavier de ram, in his works on the religious history of belgium, and in <mask> they founded the review, `` analectes pour servir à l\n",
      "\n",
      "\n",
      "24\n",
      "<mask> <mask> <mask> ( ) <mask> the <mask> of <mask> <mask> .\n",
      "he played a major role in the revolt against phocas that brought heraclius to the throne, where he captured egypt for his cousin.\n",
      "nicetas remained <mask> of egypt ( or <mask> least alexandria ) thereafter, and participated also in the byzantine -- sassanid war of <mask> -- <mask> , but failed to stop the sassanid conquest of egypt <mask> . <mask> / <mask> .\n",
      "he disappears from the sources thereafter, but <mask> served as exarch of <mask> until his death.\n",
      "\n",
      "\n",
      "28\n",
      "<mask> <mask> brooks ( 28 <mask> <mask> -- 26 <mask> <mask> ) was an english cricketer.\n",
      "brooks was a left-handed batsman who bowled <mask> <mask> .\n",
      "the son of william james brooks and mabel brooks, he was born at <mask> , <mask> .\n",
      "prior to appearing in first-class cricket, wilson had played second xi cricket for <mask> , and on one notable occasion he bowled the australian don bradman in a practice session at lord's before the <mask> season began, making him a celebrity for a short time.\n",
      "the following year he\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _,ex in full_df[(full_df['model_name'] == 'model_8_1day') & (full_df['is_correct'] == 1)].head(n=10)[['i', 'perturbed_text_truncated']].iterrows():\n",
    "    print(ex['i'])\n",
    "    print(ex['perturbed_text_truncated'])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ba9d146a-81bb-49e6-8e55-ff1c0aec0b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 2.37250826, ..., 3.26690884, 1.46606554,\n",
       "       5.446037  ])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25.get_scores('<mask> m. <mask> is an american politician, a democrat and <mask> member of the maryland house <mask> delegates.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "638c53d9-9720-470a-bf3d-6a498d91e400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "s = bm25.get_scores('<mask> m. <mask> is an american politician, a democrat and <mask> member of the maryland house <mask> delegates.'.split())\n",
    "np.arange(len(s))[s == s.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "86a911ae-2acd-49cd-bf64-15c03491ae87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_text': {'table': {'column_header': ['term_end',\n",
       "    'name',\n",
       "    'order',\n",
       "    'profession',\n",
       "    'religion',\n",
       "    'birth_place',\n",
       "    'state_delegate',\n",
       "    'birth_date',\n",
       "    'article_title',\n",
       "    'party',\n",
       "    'term_start',\n",
       "    'children',\n",
       "    'predecessor'],\n",
       "   'row_number': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "   'content': ['2003',\n",
       "    'darren m. swain',\n",
       "    'maryland house of delegates',\n",
       "    'administrator',\n",
       "    'ame',\n",
       "    'windsor , north carolina',\n",
       "    'maryland',\n",
       "    '06 may 1970',\n",
       "    'darren swain\\n',\n",
       "    'democrat',\n",
       "    'january , 2013 1999',\n",
       "    'one son',\n",
       "    'tiffany alston']},\n",
       "  'context': 'darren swain\\n'},\n",
       " 'target_text': 'darren m. swain is an american politician , a democrat and a member of the maryland house of delegates .\\n',\n",
       " 'table_str': 'term_end name order profession religion birth_place state_delegate birth_date article_title party term_start children predecessor 2003 darren m. swain maryland house of delegates administrator ame windsor , north carolina maryland 06 may 1970 darren swain\\n democrat january , 2013 1999 one son tiffany alston'}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prof_data[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a27453-786e-40ef-a9d3-4f1dacb62fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
