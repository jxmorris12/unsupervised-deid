{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dd8d98-0748-478b-8c82-6b77cfa44e53",
   "metadata": {},
   "source": [
    "### New model redaction tests\n",
    "\n",
    "As of today (2022-06-08) we're training a fleet of new models that have a collection of various improvements:\n",
    "- label smoothing\n",
    "- uniform masking rate sampling on U[0.0, 0.8]\n",
    "- IDF-weighting on masked words (so masked examples are more difficult)\n",
    "- learning rate warmup & linear decay\n",
    "- larger embedding size & bottleneck (3072 and 1536 instead of 768 and 768)\n",
    "- linear head on top of profile embedding\n",
    "\n",
    "The models are pretty slow to train (about 50% done) but I thought it might be possible to see improvements still. So I want to try generating some redacted examples from the best model I have so far, even though it's still training.# Gradient-based word deletion\n",
    "\n",
    "I trained a new model (`model_7`) with uniform sampling on the word masking rate, and no profile dropout. It is logged here: https://wandb.ai/jack-morris/deid-wikibio-2/runs/26w4n18i/logs?workspace=user-jxmorris12\n",
    "\n",
    "**Change in this notebook:** I want to see the effect of ranking words initially (using GreedyWIR) instead of re-ranking to find the absolute minimum a-la beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d252cb9-4ee5-42f2-98df-af6e72555090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e41ec84-b066-4b49-a8ff-33b7e2f90f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: set num_workers to 1, expect dataloader bottleneck\n",
      "Initializing WikipediaDataModule with num_workers = 1 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split val[:20%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-793b771e10f80bbe.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7d07543b6205ca87.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-912d45fbf560a15e.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-4731c171b2d92df3.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-2701d0e4e21f22e6.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-b90a99f65b9e7728.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-55690b488a4addfd.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-da01dd30caccabf4.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-b2f3803736eb1940.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-c0ed217b790fb2a2.arrow\n"
     ]
    }
   ],
   "source": [
    "from datamodule import WikipediaDataModule\n",
    "import os\n",
    "\n",
    "num_cpus = len(os.sched_getaffinity(0))\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    document_model_name_or_path=\"roberta-base\",\n",
    "    profile_model_name_or_path=\"google/tapas-base\",\n",
    "    max_seq_length=128,\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:1024]', # not used in this notebook\n",
    "    dataset_val_split='val[:20%]',\n",
    "    dataset_version='1.2.0',\n",
    "    word_dropout_ratio=0.0,\n",
    "    word_dropout_perc=0.0,\n",
    "    num_workers=1,\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a87966-0c59-45f7-8502-5e7da6710a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with learning_rate = 1e-05 and patience 1\n"
     ]
    }
   ],
   "source": [
    "from model import CoordinateAscentModel\n",
    "from model_cfg import model_paths_dict\n",
    "\n",
    "checkpoint_path = model_paths_dict[\"model_8_1day\"]\n",
    "\n",
    "\n",
    "model = CoordinateAscentModel.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    document_model_name_or_path=\"roberta-base\",\n",
    "    profile_model_name_or_path=\"google/tapas-base\",\n",
    "    learning_rate=1e-5,\n",
    "    pretrained_profile_encoder=False,\n",
    "    lr_scheduler_factor=0.5,\n",
    "    lr_scheduler_patience=1,\n",
    "    train_batch_size=1,\n",
    "    num_workers=1,\n",
    "    gradient_clip_val=10.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1079e-107e-4da5-ac2b-9b941d1f0eda",
   "metadata": {},
   "source": [
    "## 2. Define attack in TextAttack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "996b9503-11dd-4378-bc97-794e195448be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textattack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9137c22-612e-44c4-8557-42dcdabd8fd5",
   "metadata": {},
   "source": [
    "### (a) Beam search + replace with `[MASK]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee1838b-420d-4fc0-a849-45afcf3f1b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<AttackedText \"<mask> my name is Jack\">,\n",
       " <AttackedText \"Hello <mask> name is Jack\">,\n",
       " <AttackedText \"Hello my <mask> is Jack\">,\n",
       " <AttackedText \"Hello my name <mask> Jack\">,\n",
       " <AttackedText \"Hello my name is <mask>\">]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WordSwapSingleWord(textattack.transformations.word_swap.WordSwap):\n",
    "    \"\"\"Takes a sentence and transforms it by replacing with a single fixed word.\n",
    "    \"\"\"\n",
    "    single_word: str\n",
    "    def __init__(self, single_word: str = \"?\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.single_word = single_word\n",
    "\n",
    "    def _get_replacement_words(self, _word: str):\n",
    "        return [self.single_word]\n",
    "\n",
    "transformation = WordSwapSingleWord(single_word=dm.document_tokenizer.mask_token)\n",
    "transformation(textattack.shared.AttackedText(\"Hello my name is Jack\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1de22-75f2-4049-8cf8-6023ddf4403d",
   "metadata": {},
   "source": [
    "### (b) \"Attack success\" as fullfilment of the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d259f78c-2ece-4727-87e6-b7cb714e5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "\n",
    "class ChangeClassificationToBelowTopKClasses(textattack.goal_functions.ClassificationGoalFunction):\n",
    "    k: int\n",
    "    def __init__(self, *args, k: int = 1, **kwargs):\n",
    "        self.k = k\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _is_goal_complete(self, model_output, _):\n",
    "        original_class_score = model_output[self.ground_truth_output]\n",
    "        num_better_classes = (model_output > original_class_score).sum()\n",
    "        return num_better_classes >= self.k\n",
    "\n",
    "    def _get_score(self, model_output, _):\n",
    "        return 1 - model_output[self.ground_truth_output]\n",
    "    \n",
    "    \n",
    "    \"\"\"have to reimplement the following method to change the precision on the sum-to-one condition.\"\"\"\n",
    "    def _process_model_outputs(self, inputs, scores):\n",
    "        \"\"\"Processes and validates a list of model outputs.\n",
    "        This is a task-dependent operation. For example, classification\n",
    "        outputs need to have a softmax applied.\n",
    "        \"\"\"\n",
    "        # Automatically cast a list or ndarray of predictions to a tensor.\n",
    "        if isinstance(scores, list):\n",
    "            scores = torch.tensor(scores)\n",
    "\n",
    "        # Ensure the returned value is now a tensor.\n",
    "        if not isinstance(scores, torch.Tensor):\n",
    "            raise TypeError(\n",
    "                \"Must have list, np.ndarray, or torch.Tensor of \"\n",
    "                f\"scores. Got type {type(scores)}\"\n",
    "            )\n",
    "\n",
    "        # Validation check on model score dimensions\n",
    "        if scores.ndim == 1:\n",
    "            # Unsqueeze prediction, if it's been squeezed by the model.\n",
    "            if len(inputs) == 1:\n",
    "                scores = scores.unsqueeze(dim=0)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "                )\n",
    "        elif scores.ndim != 2:\n",
    "            # If model somehow returns too may dimensions, throw an error.\n",
    "            raise ValueError(\n",
    "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "            )\n",
    "        elif scores.shape[0] != len(inputs):\n",
    "            # If model returns an incorrect number of scores, throw an error.\n",
    "            raise ValueError(\n",
    "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "            )\n",
    "        elif not ((scores.sum(dim=1) - 1).abs() < 1e-4).all():\n",
    "            # Values in each row should sum up to 1. The model should return a\n",
    "            # set of numbers corresponding to probabilities, which should add\n",
    "            # up to 1. Since they are `torch.float` values, allow a small\n",
    "            # error in the summation.\n",
    "            scores = torch.nn.functional.softmax(scores, dim=1)\n",
    "            if not ((scores.sum(dim=1) - 1).abs() < 1e-4).all():\n",
    "                raise ValueError(\"Model scores do not add up to 1.\")\n",
    "        return scores.cpu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4405c-876a-4246-b33d-dbdfc80cd85c",
   "metadata": {},
   "source": [
    "## (c) Model wrapper that computes similarities of input documents with validation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86315cd9-1f98-4c8a-b877-5cc6c015d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              3.06it/s]\r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def precompute_profile_embeddings():\n",
    "    model.profile_model.cuda()\n",
    "    model.profile_model.eval()\n",
    "    model.profile_embed.cuda()\n",
    "    model.profile_embed.eval()\n",
    "\n",
    "    model.val_profile_embeddings = np.zeros((len(dm.val_dataset), model.shared_embedding_dim))\n",
    "    for val_batch in tqdm.tqdm(dm.val_dataloader()[0], desc=\"Precomputing val embeddings\", colour=\"green\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile(batch=val_batch)\n",
    "        model.val_profile_embeddings[val_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.val_profile_embeddings = torch.tensor(model.val_profile_embeddings, dtype=torch.float32)\n",
    "\n",
    "precompute_profile_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd35ad75-a681-4168-87b8-efee22ea41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from model.model import Model\n",
    "\n",
    "class MyModelWrapper(textattack.models.wrappers.ModelWrapper):\n",
    "    model: Model\n",
    "    tokenizer: transformers.AutoTokenizer\n",
    "    profile_embeddings: torch.Tensor\n",
    "    max_seq_length: int\n",
    "    \n",
    "    def __init__(self, model: Model, tokenizer: transformers.AutoTokenizer, max_seq_length: int = 128):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.profile_embeddings = torch.tensor(model.val_profile_embeddings)\n",
    "        self.max_seq_length = max_seq_length\n",
    "                 \n",
    "    def to(self, device):\n",
    "        self.model.to(device)\n",
    "        self.profile_embeddings.to(device)\n",
    "        return self # so semantics `model = MyModelWrapper().to('cuda')` works properly\n",
    "\n",
    "    def __call__(self, text_input_list: List[str], batch_size=32):\n",
    "        model_device = next(self.model.parameters()).device\n",
    "        \n",
    "        doc_tokenized = self.tokenizer.batch_encode_plus(\n",
    "            text_input_list,\n",
    "            max_length=self.max_seq_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        doc_tokenized = {f'document__{k}': v for k,v in doc_tokenized.items()}\n",
    "        with torch.no_grad():\n",
    "            document_embeddings = self.model.forward_document(batch=doc_tokenized, document_type='document')\n",
    "            document_to_profile_logits = document_embeddings @ self.profile_embeddings.T.to(model_device)\n",
    "            document_to_profile_probs = torch.nn.functional.softmax(\n",
    "                document_to_profile_logits, dim=-1\n",
    "            )\n",
    "        assert document_to_profile_probs.shape == (len(text_input_list), len(self.profile_embeddings))\n",
    "        return document_to_profile_probs\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeee781-ae57-47c4-8679-52014830cc7e",
   "metadata": {},
   "source": [
    "## (d) Dataset that loads Wikipedia documents with names as labels\n",
    "\n",
    "Oh, and it filters out examples that are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b35ca719-fdad-45ee-b979-9c2a67d58c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import datasets\n",
    "\n",
    "class WikiDataset(textattack.datasets.Dataset):\n",
    "    dataset: datasets.Dataset\n",
    "    \n",
    "    def __init__(self, dm: WikipediaDataModule):\n",
    "        self.shuffled = True\n",
    "        self.dataset = [ex for ex in dm.val_dataset]\n",
    "        self.label_names = list(dm.val_dataset['name'])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, i: int) -> Tuple[OrderedDict, int]:\n",
    "        input_dict = OrderedDict([\n",
    "            ('document', self.dataset[i]['document'])\n",
    "        ])\n",
    "        return input_dict, self.dataset[i]['text_key_id']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abde44f-912e-4f31-8abd-8706ce99bbc6",
   "metadata": {},
   "source": [
    "## 3. Run attack once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f77f286-3f48-44b5-b341-35582807ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxNumWordsModified(textattack.constraints.PreTransformationConstraint):\n",
    "    def __init__(self, max_num_words: int):\n",
    "        self.max_num_words = max_num_words\n",
    "\n",
    "    def _get_modifiable_indices(self, current_text):\n",
    "        \"\"\"Returns the word indices in current_text which are able to be\n",
    "        modified.\"\"\"\n",
    "\n",
    "        if len(current_text.attack_attrs[\"modified_indices\"]) >= self.max_num_words:\n",
    "            return set()\n",
    "        else:\n",
    "            return set(range(len(current_text.words)))\n",
    "\n",
    "    def extra_repr_keys(self):\n",
    "        return [\"max_num_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a421b8a-9a20-47dd-93ae-2527bca28109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-1c87bb4263f0>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.profile_embeddings = torch.tensor(model.val_profile_embeddings)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyModelWrapper at 0x7f0cab070340>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper = MyModelWrapper(model=model, tokenizer=dm.document_tokenizer)\n",
    "model_wrapper.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31eea9ed-d889-4d57-a763-50b06aaf2a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textattack.shared import utils\n",
    "\n",
    "\n",
    "def get_modified_idxs_in_order(at: textattack.shared.AttackedText) -> List[int]:\n",
    "    \"\"\"Traverses linked-list of attacked texts from attack process\n",
    "    and creates a list of the modified word indices.\n",
    "    \"\"\"\n",
    "    modified_word_idxs = []\n",
    "    while True:\n",
    "        if 'newly_modified_indices' not in at.attack_attrs:\n",
    "            break\n",
    "        modified_word_idxs.extend(at.attack_attrs['newly_modified_indices'])\n",
    "        at = at.attack_attrs['prev_attacked_text']\n",
    "    modified_word_idxs = modified_word_idxs[::-1]\n",
    "    return modified_word_idxs[::-1]\n",
    "\n",
    "\n",
    "def diff_color_with_idxs(at: textattack.attack_results.AttackResult, color_method=None):\n",
    "    \"\"\"Highlights the difference between two texts using color.\n",
    "    \n",
    "    This version also adds idx numbers to show which words were masked in which order.\n",
    "\n",
    "    Has to account for deletions and insertions from original text to\n",
    "    perturbed. Relies on the index map stored in\n",
    "    ``self.original_result.attacked_text.attack_attrs[\"original_index_map\"]``.\n",
    "    \"\"\"\n",
    "    t1 = at.original_result.attacked_text\n",
    "    t2 = at.perturbed_result.attacked_text\n",
    "\n",
    "    if color_method is None:\n",
    "        return t1.printable_text(), t2.printable_text()\n",
    "\n",
    "    color_1 = at.original_result.get_text_color_input()\n",
    "    color_2 = at.perturbed_result.get_text_color_perturbed()\n",
    "\n",
    "    # iterate through and count equal/unequal words\n",
    "    words_1_idxs = []\n",
    "    t2_equal_idxs = set()\n",
    "    original_index_map = t2.attack_attrs[\"original_index_map\"]\n",
    "    for t1_idx, t2_idx in enumerate(original_index_map):\n",
    "        if t2_idx == -1:\n",
    "            # add words in t1 that are not in t2\n",
    "            words_1_idxs.append(t1_idx)\n",
    "        else:\n",
    "            w1 = t1.words[t1_idx]\n",
    "            w2 = t2.words[t2_idx]\n",
    "            if w1 == w2:\n",
    "                t2_equal_idxs.add(t2_idx)\n",
    "            else:\n",
    "                words_1_idxs.append(t1_idx)\n",
    "\n",
    "    # words to color in t2 are all the words that didn't have an equal,\n",
    "    # mapped word in t1\n",
    "    words_2_idxs = list(sorted(set(range(t2.num_words)) - t2_equal_idxs))\n",
    "\n",
    "    # make lists of colored words\n",
    "    words_1 = [t1.words[i] for i in words_1_idxs]\n",
    "    words_1 = [utils.color_text(w, color_1, color_method) for w in words_1]\n",
    "    \n",
    "    # First, replace words with `word_xx` where xx is the index\n",
    "    # of the order that word was modified.\n",
    "    word_modification_order = {word_idx: swap_idx+1 for swap_idx, word_idx in enumerate(get_modified_idxs_in_order(t2))}\n",
    "    words_2 = [f'{t2.words[i]}__{word_modification_order[i]}' for i in words_2_idxs]\n",
    "    words_2 = [utils.color_text(w, color_2, color_method) for w in words_2]\n",
    "\n",
    "    t1 = at.original_result.attacked_text.replace_words_at_indices(\n",
    "        words_1_idxs, words_1\n",
    "    )\n",
    "    t2 = at.perturbed_result.attacked_text.replace_words_at_indices(\n",
    "        words_2_idxs, words_2\n",
    "    )\n",
    "\n",
    "    key_color = (\"bold\", \"underline\")\n",
    "    return (\n",
    "        t1.printable_text(key_color=key_color, key_color_method=color_method),\n",
    "        t2.printable_text(key_color=key_color, key_color_method=color_method),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a665c63-5457-4740-923c-9178fe185729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.loggers import CSVLogger\n",
    "from textattack.shared import AttackedText\n",
    "\n",
    "import pandas as pd\n",
    "class CustomCSVLogger(CSVLogger):\n",
    "    \"\"\"Logs attack results to a CSV.\"\"\"\n",
    "\n",
    "    def log_attack_result(self, result: textattack.goal_function_results.ClassificationGoalFunctionResult):\n",
    "        # TODO print like 'mask1', 'mask2',\n",
    "        original_text, perturbed_text = diff_color_with_idxs(result, color_method=self.color_method)\n",
    "        original_text = original_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
    "        perturbed_text = perturbed_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
    "        result_type = result.__class__.__name__.replace(\"AttackResult\", \"\")\n",
    "        row = {\n",
    "            \"original_person\": result.original_result._processed_output[0],\n",
    "            \"original_text\": original_text,\n",
    "            \"original_text_id_bm25\": bm25.get_scores(result.original_result.attacked_text.text.split()).argmax(),\n",
    "            \"perturbed_person\": result.perturbed_result._processed_output[0],\n",
    "            \"perturbed_text\": perturbed_text,\n",
    "            \"perturbed_text_id_bm25\": bm25.get_scores(result.perturbed_result.attacked_text.text.split()).argmax(),\n",
    "            \"original_score\": result.original_result.score,\n",
    "            \"perturbed_score\": result.perturbed_result.score,\n",
    "            \"original_output\": result.original_result.output,\n",
    "            \"perturbed_output\": result.perturbed_result.output,\n",
    "            \"ground_truth_output\": result.original_result.ground_truth_output,\n",
    "            \"num_queries\": result.num_queries,\n",
    "            \"result_type\": result_type,\n",
    "        }\n",
    "        self.df = pd.concat([self.df, pd.DataFrame([row])], ignore_index=True)\n",
    "        self._flushed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ac1f10-811c-47b5-9bd3-f2f92a0f2183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-f54e536983490a45.arrow\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "eng_stopwords = stopwords.words('english')\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def get_words_from_doc(s: List[str]) -> List[str]:\n",
    "    words = s.split()\n",
    "    return [w for w in words if not w in eng_stopwords]\n",
    "\n",
    "def make_table_str(ex):\n",
    "    ex['table_str'] = (\n",
    "        ' '.join(ex['input_text']['table']['column_header'] + ex['input_text']['table']['content'])\n",
    "    )\n",
    "    return ex\n",
    "\n",
    "prof_data = dm.val_dataset.map(make_table_str)\n",
    "profile_corpus = prof_data['table_str']\n",
    "\n",
    "tokenized_profile_corpus = [\n",
    "    get_words_from_doc(prof) for prof in profile_corpus\n",
    "]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_profile_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ff1b8e-7c8e-47a8-b803-51075ed032ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: No entry found for goal function <class '__main__.ChangeClassificationToBelowTopKClasses'>.\n",
      "textattack: Unknown if model of class <class 'model.coordinate_ascent.CoordinateAscentModel'> compatible with goal function <class '__main__.ChangeClassificationToBelowTopKClasses'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): GreedyWordSwapWIR(\n",
      "    (wir_method):  unk\n",
      "  )\n",
      "  (goal_function):  ChangeClassificationToBelowTopKClasses\n",
      "  (transformation):  WordSwapSingleWord\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): MaxWordIndexModification(\n",
      "        (max_length):  128\n",
      "      )\n",
      "    (2): MaxNumWordsModified(\n",
      "        (max_num_words):  50\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Succeeded / Failed / Skipped / Total] 11 / 4 / 0 / 15: 100%|██████████| 15/15 [00:36<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 11     |\n",
      "| Number of failed attacks:     | 4      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 26.67% |\n",
      "| Attack success rate:          | 73.33% |\n",
      "| Average perturbed word %:     | 48.87% |\n",
      "| Average num. words per input: | 51.87  |\n",
      "| Avg num queries:              | 92.93  |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: Logging to CSV at path results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_person</th>\n",
       "      <th>original_text</th>\n",
       "      <th>original_text_id_bm25</th>\n",
       "      <th>perturbed_person</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>perturbed_text_id_bm25</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael iii of alexandria</td>\n",
       "      <td>pope michael <font color = red>iii</font> of alexandria ( also known as khail iii ) <font color = red>was</font> the coptic pope <font color = red>of</font> <font color = red>alexandria</font> and <font color = red>patriarch</font> <font color = red>of</font> the see <font color = red>of</font> st. <font color = red>mark</font> ( <font color = red>880</font> -- <font color = red>907</font> ) .<SPLIT>in <font color = red>882</font> , the governor <font color = red>of</font> <font color = red>egypt</font> , ahmad <font color = red>ibn</font> tulun , forced khail to pay <font color = red>heavy</font> contributions , forcing <font color = red>him</font> to sell a <font color = red>church</font> and <font color = red>some</font> <font color = red>attached</font> <font color = red>properties</font> to <font color = red>the</font> <font color = red>local</font> jewish <font color = red>community</font> .<SPLIT>this <font color = red>building</font> was at one <font color = red>time</font> believed <font color = red>to</font> have <font color = red>later</font> become <font color = red>the</font> <font color = red>site</font> <font color = red>of</font> the cairo <font color = red>geniza</font> .<SPLIT></td>\n",
       "      <td>0</td>\n",
       "      <td>Michael iv of alexandria</td>\n",
       "      <td>pope michael <<font color = red>mask__31</font>> of alexandria ( also known as khail iii ) <<font color = red>mask__24</font>> the coptic pope <<font color = red>mask__29</font>> <<font color = red>mask__6</font>> and <<font color = red>mask__23</font>> <<font color = red>mask__26</font>> the see <<font color = red>mask__27</font>> st. <<font color = red>mask__25</font>> ( <<font color = red>mask__30</font>> -- <<font color = red>mask__9</font>> ) .<SPLIT>in <<font color = red>mask__28</font>> , the governor <<font color = red>mask__18</font>> <<font color = red>mask__20</font>> , ahmad <<font color = red>mask__16</font>> tulun , forced khail to pay <<font color = red>mask__17</font>> contributions , forcing <<font color = red>mask__10</font>> to sell a <<font color = red>mask__21</font>> and <<font color = red>mask__4</font>> <<font color = red>mask__13</font>> <<font color = red>mask__19</font>> to <<font color = red>mask__8</font>> <<font color = red>mask__2</font>> jewish <<font color = red>mask__1</font>> .<SPLIT>this <<font color = red>mask__5</font>> was at one <<font color = red>mask__11</font>> believed <<font color = red>mask__14</font>> have <<font color = red>mask__15</font>> become <<font color = red>mask__3</font>> <<font color = red>mask__7</font>> <<font color = red>mask__12</font>> the cairo <<font color = red>mask__22</font>> .<SPLIT></td>\n",
       "      <td>0</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.502268</td>\n",
       "      <td>0</td>\n",
       "      <td>12300</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hui jun</td>\n",
       "      <td><font color = green>hui</font> <font color = green>jun</font> is a male <font color = green>former</font> <font color = green>table</font> <font color = green>tennis</font> <font color = green>player</font> <font color = green>from</font> china .<SPLIT></td>\n",
       "      <td>1</td>\n",
       "      <td>Liu xiaolong</td>\n",
       "      <td><<font color = gray>mask__7</font>> <<font color = gray>mask__6</font>> is a male <<font color = gray>mask__4</font>> <<font color = gray>mask__5</font>> <<font color = gray>mask__3</font>> <<font color = gray>mask__2</font>> <<font color = gray>mask__1</font>> china .<SPLIT></td>\n",
       "      <td>11662</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.774241</td>\n",
       "      <td>1</td>\n",
       "      <td>10388</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Okan öztürk</td>\n",
       "      <td><font color = blue>okan</font> <font color = blue>Öztürk</font> ( born <font color = blue>30</font> november <font color = blue>1977</font> ) <font color = blue>is</font> <font color = blue>a</font> <font color = blue>turkish</font> <font color = blue>professional</font> footballer .<SPLIT><font color = blue>he</font> <font color = blue>currently</font> <font color = blue>plays</font> <font color = blue>as</font> a <font color = blue>striker</font> <font color = blue>for</font> <font color = blue>yeni</font> <font color = blue>malatyaspor</font> .<SPLIT></td>\n",
       "      <td>2</td>\n",
       "      <td>Kimoi alexander</td>\n",
       "      <td><<font color = red>mask__15</font>> <<font color = red>mask__1</font>> ( born <<font color = red>mask__6</font>> november <<font color = red>mask__2</font>> ) <<font color = red>mask__10</font>> <<font color = red>mask__13</font>> <<font color = red>mask__3</font>> <<font color = red>mask__14</font>> footballer .<SPLIT><<font color = red>mask__7</font>> <<font color = red>mask__11</font>> <<font color = red>mask__9</font>> <<font color = red>mask__8</font>> a <<font color = red>mask__16</font>> <<font color = red>mask__12</font>> <<font color = red>mask__5</font>> <<font color = red>mask__4</font>> .<SPLIT></td>\n",
       "      <td>6578</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.996702</td>\n",
       "      <td>2</td>\n",
       "      <td>9220</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marie stephan</td>\n",
       "      <td><font color = purple>marie</font> <font color = purple>stephan</font> , ( born <font color = purple>march</font> <font color = purple>14</font> , <font color = purple>1996</font> ) <font color = purple>is</font> <font color = purple>a</font> <font color = purple>professional</font> squash player <font color = purple>who</font> represents <font color = purple>france</font> .<SPLIT><font color = purple>she</font> reached a career-high <font color = purple>world</font> <font color = purple>ranking</font> <font color = purple>of</font> world no. <font color = purple>101</font> <font color = purple>in</font> <font color = purple>july</font> 2015 .<SPLIT></td>\n",
       "      <td>3</td>\n",
       "      <td>Cecelia cortes</td>\n",
       "      <td><<font color = gray>mask__15</font>> <<font color = gray>mask__14</font>> , ( born <<font color = gray>mask__16</font>> <<font color = gray>mask__13</font>> , <<font color = gray>mask__1</font>> ) <<font color = gray>mask__4</font>> <<font color = gray>mask__11</font>> <<font color = gray>mask__2</font>> squash player <<font color = gray>mask__8</font>> represents <<font color = gray>mask__17</font>> .<SPLIT><<font color = gray>mask__7</font>> reached a career-high <<font color = gray>mask__3</font>> <<font color = gray>mask__6</font>> <<font color = gray>mask__9</font>> world no. <<font color = gray>mask__10</font>> <<font color = gray>mask__12</font>> <<font color = gray>mask__5</font>> 2015 .<SPLIT></td>\n",
       "      <td>4624</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.878504</td>\n",
       "      <td>3</td>\n",
       "      <td>12998</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard l. martino</td>\n",
       "      <td><font color = yellow>leonard</font> <font color = yellow>l</font>. <font color = yellow>martino</font> is a former democratic <font color = yellow>member</font> <font color = yellow>of</font> the pennsylvania <font color = yellow>house</font> of <font color = yellow>representatives</font> .<SPLIT><font color = yellow>he</font> was born in butler <font color = yellow>to</font> <font color = yellow>michael</font> and angela <font color = yellow>pitullio</font> martino .<SPLIT></td>\n",
       "      <td>4</td>\n",
       "      <td>William w. pendleton</td>\n",
       "      <td><<font color = gray>mask__11</font>> <<font color = gray>mask__6</font>>. <<font color = gray>mask__10</font>> is a former democratic <<font color = gray>mask__4</font>> <<font color = gray>mask__5</font>> the pennsylvania <<font color = gray>mask__8</font>> of <<font color = gray>mask__3</font>> .<SPLIT><<font color = gray>mask__9</font>> was born in butler <<font color = gray>mask__7</font>> <<font color = gray>mask__1</font>> and angela <<font color = gray>mask__2</font>> martino .<SPLIT></td>\n",
       "      <td>4</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.791578</td>\n",
       "      <td>4</td>\n",
       "      <td>1488</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salome jens</td>\n",
       "      <td><font color = orange>salome</font> <font color = orange>jens</font> ( <font color = orange>born</font> <font color = orange>may</font> <font color = orange>8</font> , <font color = orange>1935</font> ) <font color = orange>is</font> <font color = orange>an</font> <font color = orange>american</font> <font color = orange>stage</font> , <font color = orange>film</font> and television <font color = orange>actress</font> .<SPLIT>she is perhaps best known <font color = orange>for</font> <font color = orange>portraying</font> the <font color = orange>female</font> <font color = orange>changeling</font> on '' '' .<SPLIT></td>\n",
       "      <td>5</td>\n",
       "      <td>Heidi lucas</td>\n",
       "      <td><<font color = yellow>mask__1</font>> <<font color = yellow>mask__16</font>> ( <<font color = yellow>mask__5</font>> <<font color = yellow>mask__9</font>> <<font color = yellow>mask__3</font>> , <<font color = yellow>mask__14</font>> ) <<font color = yellow>mask__15</font>> <<font color = yellow>mask__6</font>> <<font color = yellow>mask__11</font>> <<font color = yellow>mask__10</font>> , <<font color = yellow>mask__8</font>> and television <<font color = yellow>mask__4</font>> .<SPLIT>she is perhaps best known <<font color = yellow>mask__12</font>> <<font color = yellow>mask__2</font>> the <<font color = yellow>mask__13</font>> <<font color = yellow>mask__7</font>> on '' '' .<SPLIT></td>\n",
       "      <td>6420</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.999139</td>\n",
       "      <td>5</td>\n",
       "      <td>13374</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Carl crawford</td>\n",
       "      <td>carl demonte <font color = pink>crawford</font> ( <font color = pink>born</font> <font color = pink>august</font> <font color = pink>5</font> , <font color = pink>1981</font> ) , nicknamed `` the <font color = pink>perfect</font> <font color = pink>storm</font> '' , <font color = pink>is</font> <font color = pink>an</font> american professional <font color = pink>baseball</font> <font color = pink>left</font> <font color = pink>fielder</font> with the los angeles <font color = pink>dodgers</font> of major league baseball ( mlb ) .<SPLIT><font color = pink>he</font> bats and throws <font color = pink>left-handed</font> .<SPLIT>crawford was drafted by <font color = pink>the</font> <font color = pink>tampa</font> <font color = pink>bay</font> devil rays in the second round ( 52nd overall ) <font color = pink>of</font> the 1999 major league baseball <font color = pink>draft</font> .<SPLIT><font color = pink>he</font> made his major league debut <font color = pink>in</font> 2002 .<SPLIT>crawford has <font color = pink>more</font> <font color = pink>triples</font> ( <font color = pink>121</font> ) than any other <font color = pink>active</font> <font color = pink>baseball</font> player .<SPLIT></td>\n",
       "      <td>6</td>\n",
       "      <td>Carl crawford</td>\n",
       "      <td>carl demonte <<font color = pink>mask__27</font>> ( <<font color = pink>mask__9</font>> <<font color = pink>mask__22</font>> <<font color = pink>mask__25</font>> , <<font color = pink>mask__2</font>> ) , nicknamed `` the <<font color = pink>mask__7</font>> <<font color = pink>mask__1</font>> '' , <<font color = pink>mask__6</font>> <<font color = pink>mask__17</font>> american professional <<font color = pink>mask__23</font>> <<font color = pink>mask__16</font>> <<font color = pink>mask__26</font>> with the los angeles <<font color = pink>mask__21</font>> of major league baseball ( mlb ) .<SPLIT><<font color = pink>mask__15</font>> bats and throws <<font color = pink>mask__24</font>> .<SPLIT>crawford was drafted by <<font color = pink>mask__12</font>> <<font color = pink>mask__3</font>> <<font color = pink>mask__4</font>> devil rays in the second round ( 52nd overall ) <<font color = pink>mask__11</font>> the 1999 major league baseball <<font color = pink>mask__20</font>> .<SPLIT><<font color = pink>mask__10</font>> made his major league debut <<font color = pink>mask__18</font>> 2002 .<SPLIT>crawford has <<font color = pink>mask__5</font>> <<font color = pink>mask__19</font>> ( <<font color = pink>mask__13</font>> ) than any other <<font color = pink>mask__8</font>> <<font color = pink>mask__14</font>> player .<SPLIT></td>\n",
       "      <td>6</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jim bob</td>\n",
       "      <td><font color = cyan>jim</font> <font color = cyan>bob</font> ( born james neil morrison on <font color = cyan>22</font> <font color = cyan>november</font> <font color = cyan>1960</font> ) <font color = cyan>is</font> a <font color = cyan>british</font> musician <font color = cyan>and</font> author , best <font color = cyan>known</font> as <font color = cyan>the</font> <font color = cyan>singer</font> <font color = cyan>of</font> indie <font color = cyan>punk</font> band carter <font color = cyan>usm</font> .<SPLIT></td>\n",
       "      <td>7</td>\n",
       "      <td>Norman blake -lrb- scottish musician -rrb-</td>\n",
       "      <td><<font color = cyan>mask__1</font>> <<font color = cyan>mask__13</font>> ( born james neil morrison on <<font color = cyan>mask__8</font>> <<font color = cyan>mask__10</font>> <<font color = cyan>mask__12</font>> ) <<font color = cyan>mask__3</font>> a <<font color = cyan>mask__14</font>> musician <<font color = cyan>mask__6</font>> author , best <<font color = cyan>mask__4</font>> as <<font color = cyan>mask__2</font>> <<font color = cyan>mask__11</font>> <<font color = cyan>mask__5</font>> indie <<font color = cyan>mask__9</font>> band carter <<font color = cyan>mask__7</font>> .<SPLIT></td>\n",
       "      <td>2577</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.774146</td>\n",
       "      <td>7</td>\n",
       "      <td>4677</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Riddick parker</td>\n",
       "      <td><font color = gray>riddick</font> parker ( <font color = gray>born</font> <font color = gray>november</font> 20 , <font color = gray>1972</font> <font color = gray>in</font> emporia , <font color = gray>virginia</font> ) <font color = gray>is</font> <font color = gray>a</font> former <font color = gray>professional</font> american football <font color = gray>defensive</font> <font color = gray>lineman</font> for the <font color = gray>seattle</font> <font color = gray>seahawks</font> , <font color = gray>san</font> diego chargers , <font color = gray>new</font> <font color = gray>england</font> patriots , baltimore ravens , <font color = gray>and</font> san francisco 49ers <font color = gray>of</font> the national football <font color = gray>league</font> .<SPLIT></td>\n",
       "      <td>8</td>\n",
       "      <td>Glenn parker</td>\n",
       "      <td><<font color = red>mask__19</font>> parker ( <<font color = red>mask__3</font>> <<font color = red>mask__6</font>> 20 , <<font color = red>mask__17</font>> <<font color = red>mask__15</font>> emporia , <<font color = red>mask__18</font>> ) <<font color = red>mask__2</font>> <<font color = red>mask__4</font>> former <<font color = red>mask__8</font>> american football <<font color = red>mask__5</font>> <<font color = red>mask__16</font>> for the <<font color = red>mask__1</font>> <<font color = red>mask__13</font>> , <<font color = red>mask__9</font>> diego chargers , <<font color = red>mask__12</font>> <<font color = red>mask__10</font>> patriots , baltimore ravens , <<font color = red>mask__11</font>> san francisco 49ers <<font color = red>mask__14</font>> the national football <<font color = red>mask__7</font>> .<SPLIT></td>\n",
       "      <td>8</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>8</td>\n",
       "      <td>9550</td>\n",
       "      <td>8</td>\n",
       "      <td>72</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blessed osanna of cattaro -lrb- ozana kotorska -rrb-</td>\n",
       "      <td>blessed <font color = brown>osanna</font> <font color = brown>of</font> <font color = brown>cattaro</font> t.<font color = brown>o</font>.s.d. ( ) was a catholic visionary <font color = brown>and</font> anchoress from cattaro ( kotor ) .<SPLIT>she <font color = brown>was</font> a teenage convert from <font color = brown>orthodoxy</font> of <font color = brown>serbian</font> descent from <font color = brown>montenegro</font> ( <font color = brown>zeta</font> ) .<SPLIT><font color = brown>she</font> became a dominican <font color = brown>tertiary</font> <font color = brown>and</font> was posthumously venerated <font color = brown>as</font> a <font color = brown>saint</font> <font color = brown>in</font> kotor .<SPLIT>she <font color = brown>was</font> later <font color = brown>beatified</font> in 1934 .<SPLIT></td>\n",
       "      <td>9</td>\n",
       "      <td>Blessed anna maria rubatto</td>\n",
       "      <td>blessed <<font color = cyan>mask__10</font>> <<font color = cyan>mask__18</font>> <<font color = cyan>mask__16</font>> t.<<font color = cyan>mask__2</font>>.s.d. ( ) was a catholic visionary <<font color = cyan>mask__8</font>> anchoress from cattaro ( kotor ) .<SPLIT>she <<font color = cyan>mask__4</font>> a teenage convert from <<font color = cyan>mask__6</font>> of <<font color = cyan>mask__1</font>> descent from <<font color = cyan>mask__17</font>> ( <<font color = cyan>mask__13</font>> ) .<SPLIT><<font color = cyan>mask__7</font>> became a dominican <<font color = cyan>mask__5</font>> <<font color = cyan>mask__9</font>> was posthumously venerated <<font color = cyan>mask__12</font>> a <<font color = cyan>mask__14</font>> <<font color = cyan>mask__3</font>> kotor .<SPLIT>she <<font color = cyan>mask__15</font>> later <<font color = cyan>mask__11</font>> in 1934 .<SPLIT></td>\n",
       "      <td>9</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.793293</td>\n",
       "      <td>9</td>\n",
       "      <td>3107</td>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thaila ayala</td>\n",
       "      <td><font color = red>thaila</font> <font color = red>ayala</font> <font color = red>sales</font> ( <font color = red>born</font> <font color = red>april</font> 14 , <font color = red>1986</font> <font color = red>in</font> presidente <font color = red>prudente</font> ) is <font color = red>a</font> brazilian actress <font color = red>and</font> <font color = red>model</font> .<SPLIT></td>\n",
       "      <td>10</td>\n",
       "      <td>Thaila ayala</td>\n",
       "      <td><<font color = red>mask__6</font>> <<font color = red>mask__3</font>> <<font color = red>mask__8</font>> ( <<font color = red>mask__5</font>> <<font color = red>mask__11</font>> 14 , <<font color = red>mask__10</font>> <<font color = red>mask__9</font>> presidente <<font color = red>mask__2</font>> ) is <<font color = red>mask__4</font>> brazilian actress <<font color = red>mask__7</font>> <<font color = red>mask__1</font>> .<SPLIT></td>\n",
       "      <td>10</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.026017</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sven leuenberger</td>\n",
       "      <td><font color = green>sven</font> <font color = green>leuenberger</font> ( born <font color = green>august</font> <font color = green>25</font> , <font color = green>1969</font> in <font color = green>niederuzwil</font> , <font color = green>switzerland</font> ) <font color = green>is</font> a <font color = green>retired</font> <font color = green>swiss</font> <font color = green>professional</font> ice <font color = green>hockey</font> <font color = green>defender</font> .<SPLIT>playing <font color = green>in</font> the nla-a , leuenberger <font color = green>accumulated</font> 74 goals , <font color = green>173</font> assists , and <font color = green>443</font> <font color = green>penalty</font> minutes in <font color = green>the</font> <font color = green>regular</font> season .<SPLIT><font color = green>since</font> <font color = green>the</font> nla 2006 <font color = green>season</font> , leuenberger has been the general manager ( sports director ) of the <font color = green>sc</font> <font color = green>bern</font> .<SPLIT>on august <font color = green>1</font> , 2008 <font color = green>sc</font> bern '<font color = green>s</font> coach <font color = green>suffered</font> , <font color = green>john</font> <font color = green>van</font> <font color = green>boxmeer</font> , a heart <font color = green>attack</font> side-lining <font color = green>him</font> for a month .<SPLIT>during van <font color = green>boxmeer</font> '<font color = green>s</font> absence , general manager <font color = green>sven</font> leuenberger coached the team along with assistant coach konstantin kurashev -lsb- http://www.iihf.com/home-of-hockey/news/news-singleview/article/van-boxmeer-suffers-heart-attack/leuenberger.html] .<SPLIT></td>\n",
       "      <td>11</td>\n",
       "      <td>Sven leuenberger</td>\n",
       "      <td><<font color = green>mask__37</font>> <<font color = green>mask__1</font>> ( born <<font color = green>mask__36</font>> <<font color = green>mask__30</font>> , <<font color = green>mask__29</font>> in <<font color = green>mask__33</font>> , <<font color = green>mask__8</font>> ) <<font color = green>mask__14</font>> a <<font color = green>mask__26</font>> <<font color = green>mask__31</font>> <<font color = green>mask__12</font>> ice <<font color = green>mask__18</font>> <<font color = green>mask__34</font>> .<SPLIT>playing <<font color = green>mask__35</font>> the nla-a , leuenberger <<font color = green>mask__7</font>> 74 goals , <<font color = green>mask__6</font>> assists , and <<font color = green>mask__27</font>> <<font color = green>mask__25</font>> minutes in <<font color = green>mask__24</font>> <<font color = green>mask__21</font>> season .<SPLIT><<font color = green>mask__2</font>> <<font color = green>mask__11</font>> nla 2006 <<font color = green>mask__5</font>> , leuenberger has been the general manager ( sports director ) of the <<font color = green>mask__32</font>> <<font color = green>mask__28</font>> .<SPLIT>on august <<font color = green>mask__23</font>> , 2008 <<font color = green>mask__15</font>> bern '<<font color = green>mask__9</font>> coach <<font color = green>mask__19</font>> , <<font color = green>mask__20</font>> <<font color = green>mask__4</font>> <<font color = green>mask__10</font>> , a heart <<font color = green>mask__3</font>> side-lining <<font color = green>mask__22</font>> for a month .<SPLIT>during van <<font color = green>mask__13</font>> '<<font color = green>mask__16</font>> absence , general manager <<font color = green>mask__17</font>> leuenberger coached the team along with assistant coach konstantin kurashev -lsb- http://www.iihf.com/home-of-hockey/news/news-singleview/article/van-boxmeer-suffers-heart-attack/leuenberger.html] .<SPLIT></td>\n",
       "      <td>11</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.546525</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>205</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brett scott</td>\n",
       "      <td><font color = blue>brett</font> <font color = blue>scott</font> ( born <font color = blue>10</font> <font color = blue>april</font> <font color = blue>1962</font> ) is a former australian rules footballer who <font color = blue>played</font> <font color = blue>with</font> the sydney football <font color = blue>club</font> in <font color = blue>the</font> victorian football <font color = blue>league</font> during <font color = blue>the</font> <font color = blue>1980s</font> .<SPLIT>scott played his <font color = blue>early</font> football with the rock-yerong creek before being recruited to <font color = blue>south</font> melbourne and <font color = blue>making</font> his league debut in <font color = blue>1981</font> .<SPLIT>the following year the club relocated <font color = blue>to</font> sydney and he took part in the inaugural game for their new city .<SPLIT>injuries restricted his appearances over the years and when he finished in <font color = blue>1989</font> he had managed just <font color = blue>59</font> senior games .<SPLIT>after gary buckenara was sacked <font color = blue>as</font> <font color = blue>sydney</font> 's coach in 1993 , scott acted as a caretaker coach for two games .<SPLIT></td>\n",
       "      <td>12</td>\n",
       "      <td>Stephen mount</td>\n",
       "      <td><<font color = pink>mask__20</font>> <<font color = pink>mask__19</font>> ( born <<font color = pink>mask__18</font>> <<font color = pink>mask__21</font>> <<font color = pink>mask__9</font>> ) is a former australian rules footballer who <<font color = pink>mask__11</font>> <<font color = pink>mask__8</font>> the sydney football <<font color = pink>mask__7</font>> in <<font color = pink>mask__17</font>> victorian football <<font color = pink>mask__1</font>> during <<font color = pink>mask__15</font>> <<font color = pink>mask__12</font>> .<SPLIT>scott played his <<font color = pink>mask__2</font>> football with the rock-yerong creek before being recruited to <<font color = pink>mask__16</font>> melbourne and <<font color = pink>mask__5</font>> his league debut in <<font color = pink>mask__4</font>> .<SPLIT>the following year the club relocated <<font color = pink>mask__6</font>> sydney and he took part in the inaugural game for their new city .<SPLIT>injuries restricted his appearances over the years and when he finished in <<font color = pink>mask__13</font>> he had managed just <<font color = pink>mask__3</font>> senior games .<SPLIT>after gary buckenara was sacked <<font color = pink>mask__14</font>> <<font color = pink>mask__10</font>> 's coach in 1993 , scott acted as a caretaker coach for two games .<SPLIT></td>\n",
       "      <td>12</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.805617</td>\n",
       "      <td>12</td>\n",
       "      <td>6296</td>\n",
       "      <td>12</td>\n",
       "      <td>136</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Marlon evans</td>\n",
       "      <td><font color = purple>marlon</font> <font color = purple>evans</font> ( born 3 <font color = purple>august</font> <font color = purple>1997</font> ) is a guamanian <font color = purple>international</font> footballer who <font color = purple>plays</font> <font color = purple>for</font> <font color = purple>wings</font> in the guam <font color = purple>men</font> 's <font color = purple>soccer</font> <font color = purple>league</font><SPLIT></td>\n",
       "      <td>13</td>\n",
       "      <td>Marlon evans</td>\n",
       "      <td><<font color = purple>mask__11</font>> <<font color = purple>mask__1</font>> ( born 3 <<font color = purple>mask__6</font>> <<font color = purple>mask__10</font>> ) is a guamanian <<font color = purple>mask__7</font>> footballer who <<font color = purple>mask__3</font>> <<font color = purple>mask__5</font>> <<font color = purple>mask__8</font>> in the guam <<font color = purple>mask__9</font>> 's <<font color = purple>mask__2</font>> <<font color = purple>mask__4</font>><SPLIT></td>\n",
       "      <td>13</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.091527</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>Failed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jesper blicher</td>\n",
       "      <td><font color = yellow>jesper</font> <font color = yellow>blicher</font> ( <font color = yellow>born</font> <font color = yellow>4</font> october <font color = yellow>1988</font> ) is <font color = yellow>a</font> danish <font color = yellow>professional</font> football <font color = yellow>midfielder</font> , who currently <font color = yellow>plays</font> <font color = yellow>for</font> danish <font color = yellow>1st</font> division side <font color = yellow>lyngby</font> boldklub .<SPLIT>blicher began playing <font color = yellow>football</font> in <font color = yellow>kolt-hasselager</font> <font color = yellow>if</font> , <font color = yellow>where</font> <font color = yellow>he</font> was picked for <font color = yellow>agf</font> , <font color = yellow>where</font> <font color = yellow>he</font> <font color = yellow>got</font> his <font color = yellow>other</font> footballing <font color = yellow>education</font> .<SPLIT><font color = yellow>he</font> was part <font color = yellow>of</font> the <font color = yellow>year</font> ' 88 , <font color = yellow>who</font> won <font color = yellow>in</font> the <font color = yellow>junior</font> <font color = yellow>league</font> , <font color = yellow>like</font> michael <font color = yellow>lumb</font> , frederik krabbe , michael vester , niels kristensen , morten beck andersen <font color = yellow>and</font> anders syberg , <font color = yellow>who</font> all <font color = yellow>had</font> the <font color = yellow>onset</font> of <font color = yellow>agf</font> 's 1 .<SPLIT>hold .<SPLIT>in the autumn of 2009 he was loaned to næstved bk , and just before winter transfer window end he switched permanently to the club .<SPLIT>in 2010 he changed to fc fredericia , where he played until 2012 when he got vendsyssel ff as a new club in january 2015 he was given at his own request that he want to terminated his contract with the vendsyssel ff .<SPLIT>on 6 february 2015 he signed a two-year contract with lyngby boldklub<SPLIT></td>\n",
       "      <td>14</td>\n",
       "      <td>Carsten broe</td>\n",
       "      <td><<font color = blue>mask__1</font>> <<font color = blue>mask__2</font>> ( <<font color = blue>mask__8</font>> <<font color = blue>mask__14</font>> october <<font color = blue>mask__36</font>> ) is <<font color = blue>mask__26</font>> danish <<font color = blue>mask__5</font>> football <<font color = blue>mask__7</font>> , who currently <<font color = blue>mask__11</font>> <<font color = blue>mask__27</font>> danish <<font color = blue>mask__3</font>> division side <<font color = blue>mask__37</font>> boldklub .<SPLIT>blicher began playing <<font color = blue>mask__32</font>> in <<font color = blue>mask__35</font>> <<font color = blue>mask__34</font>> , <<font color = blue>mask__31</font>> <<font color = blue>mask__17</font>> was picked for <<font color = blue>mask__24</font>> , <<font color = blue>mask__29</font>> <<font color = blue>mask__12</font>> <<font color = blue>mask__15</font>> his <<font color = blue>mask__10</font>> footballing <<font color = blue>mask__4</font>> .<SPLIT><<font color = blue>mask__18</font>> was part <<font color = blue>mask__33</font>> the <<font color = blue>mask__16</font>> ' 88 , <<font color = blue>mask__30</font>> won <<font color = blue>mask__25</font>> the <<font color = blue>mask__13</font>> <<font color = blue>mask__28</font>> , <<font color = blue>mask__9</font>> michael <<font color = blue>mask__22</font>> , frederik krabbe , michael vester , niels kristensen , morten beck andersen <<font color = blue>mask__23</font>> anders syberg , <<font color = blue>mask__6</font>> all <<font color = blue>mask__21</font>> the <<font color = blue>mask__20</font>> of <<font color = blue>mask__19</font>> 's 1 .<SPLIT>hold .<SPLIT>in the autumn of 2009 he was loaned to næstved bk , and just before winter transfer window end he switched permanently to the club .<SPLIT>in 2010 he changed to fc fredericia , where he played until 2012 when he got vendsyssel ff as a new club in january 2015 he was given at his own request that he want to terminated his contract with the vendsyssel ff .<SPLIT>on 6 february 2015 he signed a two-year contract with lyngby boldklub<SPLIT></td>\n",
       "      <td>14</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.951861</td>\n",
       "      <td>14</td>\n",
       "      <td>2322</td>\n",
       "      <td>14</td>\n",
       "      <td>285</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "#  Initialize attack\n",
    "# \n",
    "\n",
    "from textattack import Attack\n",
    "from textattack.constraints.pre_transformation import MaxWordIndexModification, RepeatModification\n",
    "\n",
    "goal_function = ChangeClassificationToBelowTopKClasses(model_wrapper, k=1)\n",
    "constraints = [\n",
    "    RepeatModification(),\n",
    "    MaxWordIndexModification(max_length=dm.max_seq_length),\n",
    "    MaxNumWordsModified(max_num_words=50)\n",
    "]\n",
    "transformation = WordSwapSingleWord(single_word=dm.document_tokenizer.mask_token)\n",
    "search_method = textattack.search_methods.GreedyWordSwapWIR(unk_token=dm.document_tokenizer.mask_token)\n",
    "\n",
    "attack = Attack(\n",
    "    goal_function, constraints, transformation, search_method\n",
    ")\n",
    "\n",
    "from tqdm import tqdm # tqdm provides us a nice progress bar.\n",
    "from textattack.attack_results import SuccessfulAttackResult\n",
    "from textattack import Attacker\n",
    "from textattack import AttackArgs\n",
    "\n",
    "attack_args = AttackArgs(num_examples=15, disable_stdout=True)\n",
    "dataset = WikiDataset(dm)\n",
    "\n",
    "attacker = Attacker(attack, dataset, attack_args)\n",
    "\n",
    "results_iterable = attacker.attack_dataset()\n",
    "\n",
    "logger = CustomCSVLogger(color_method='html')\n",
    "\n",
    "# \n",
    "# Run attack\n",
    "# \n",
    "from tqdm import tqdm\n",
    "for result in results_iterable:\n",
    "    tqdm._instances.clear() # Doesn't fix the progress bar :-(\n",
    "    logger.log_attack_result(result)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(logger.df.to_html(escape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac766e58-f90b-458b-b3d4-a9c80b9f25e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marlon_evans_text = \"guamanian footballer guam\"\n",
    "bm25.get_scores(marlon_evans_text.split()).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf13b46a-671a-4518-8294-fd1c388ed772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"marlon evans ( born 3 august 1997 ) is a guamanian international footballer who plays for wings in the guam men 's soccer league\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.val_dataset['document'][bm25.get_scores([\"guam\"]).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65582454-c351-45fc-bf6c-0a6bb4d9bfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14566"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bm25.get_scores([\"guam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e1b46b-a852-4682-99d4-7133153dbc8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
