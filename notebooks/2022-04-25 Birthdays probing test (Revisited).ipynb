{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dd8d98-0748-478b-8c82-6b77cfa44e53",
   "metadata": {},
   "source": [
    "# Birthdays probing test\n",
    "\n",
    "final results, comparing my trained model vs. distilbert pretrained:\n",
    "\n",
    "```\n",
    "                   month    day\n",
    "my model:             10    3.5 \n",
    "distilbert:           25    8.0\n",
    "random guessing:       8    3.2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d252cb9-4ee5-42f2-98df-af6e72555090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529344f2-556a-49e3-92e4-b5055c9b0469",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DocumentProfileMatchingTransformer\n",
    "\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "model = DocumentProfileMatchingTransformer.load_from_checkpoint(\n",
    "    # distilbert-distilbert model\n",
    "    #    '/home/jxm3/research/deidentification/unsupervised-deidentification/saves/distilbert-base-uncased__dropout_0.8_0.8/deid-wikibio_default/1irhznnp_130/checkpoints/epoch=25-step=118376.ckpt',\n",
    "    # roberta-distilbert model\n",
    "    # '/home/jxm3/research/deidentification/unsupervised-deidentification/saves/roberta__distilbert-base-uncased__dropout_0.8_0.8/deid-wikibio_default/1f7mlhxn_162/checkpoints/epoch=16-step=309551.ckpt',\n",
    "    # roberta-distilbert model trained for longer\n",
    "    '/home/jxm3/research/deidentification/unsupervised-deidentification/saves/roberta__distilbert-base-uncased__dropout_0.8_0.8/deid-wikibio_default/3nbt75gp_171/checkpoints/epoch=20-step=382387.ckpt',\n",
    "    document_model_name_or_path='roberta-base',\n",
    "    profile_model_name_or_path='distilbert-base-uncased',\n",
    "    num_workers=min(8, num_cpus),\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64,\n",
    "    learning_rate=1e-6,\n",
    "    max_seq_length=256,\n",
    "    pretrained_profile_encoder=False,\n",
    "    word_dropout_ratio=0.0,\n",
    "    word_dropout_perc=0.0,\n",
    "    lr_scheduler_factor=0.5,\n",
    "    lr_scheduler_patience=3,\n",
    "    adversarial_mask_k_tokens=0,\n",
    "    train_without_names=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "29132408-7f12-472e-896b-494b99fda702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WikipediaDataModule with num_workers = 8 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:100%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split val[:20%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-58e5e96e220311ed.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-778e9a6d1b0dfab7.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-3c4e94260fbd4dd3.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-9e279afc7bfb46f2.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7c5ac0e6f364c103.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-02418e1d9ade71ab.arrow\n"
     ]
    }
   ],
   "source": [
    "from datamodule import WikipediaDataModule\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    mask_token=model.document_tokenizer.mask_token,\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:100%]',\n",
    "    dataset_val_split='val[:20%]',\n",
    "    dataset_version='1.2.0',\n",
    "    num_workers=min(8, num_cpus),\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64,\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea5280-96de-48cd-9ccc-23d8c3f3237d",
   "metadata": {},
   "source": [
    "## Get the birthday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "774c9b7c-aedb-4ea6-9635-4c9ddd5c0639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "d = datetime.datetime.strptime('17 january 1943', \"%d %B %Y\")\n",
    "d.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d2c6da6f-9788-4a13-bb05-46383951d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "def process_dataset(_dataset) -> List[Tuple[int, int]]:\n",
    "    _processed_data = []\n",
    "    for idx, d in enumerate(tqdm(_dataset, 'processing birthdays')):\n",
    "        profile = d['profile']\n",
    "        date_str_matches = re.search(r\"birth_date \\| ([\\d]{1,4} [a-z]+ [\\d]{1,4})\", profile)\n",
    "        if date_str_matches:\n",
    "            date_str = date_str_matches.group(1)\n",
    "            # print(date_str)\n",
    "            # parse to datetime.datetime\n",
    "            try:\n",
    "                dt = datetime.datetime.strptime(date_str, \"%d %B %Y\")\n",
    "            except ValueError as e:\n",
    "                # print(e)\n",
    "                continue\n",
    "            # day_class_num = (dt.month - 1) * 31 + (dt.day - 1)\n",
    "            # _processed_data.append((idx, day_class_num))\n",
    "            _processed_data.append((idx, dt.month-1, dt.day-1))\n",
    "    return _processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f793a8c-de55-4c12-8dd2-c3e6fa1f9e60",
   "metadata": {},
   "source": [
    "## Create birthday data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ce4eaea4-daf0-4996-96c9-0826a537b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "class BirthdayDataModule(LightningDataModule):\n",
    "    train_dataset: List[Tuple[int, int, int]]\n",
    "    val_dataset: List[Tuple[int, int, int]]\n",
    "    batch_size: int\n",
    "    def __init__(self, dm: WikipediaDataModule, batch_size: int = 64):\n",
    "        super().__init__()\n",
    "        self.train_dataset = process_dataset(dm.train_dataset)\n",
    "        self.val_dataset = process_dataset(dm.val_dataset)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = min(4, num_cpus)\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        return\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False # Only shuffle for train\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "13aa79a4-cced-4f94-a39b-1534759fd5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ea624443c9429790510057255cb9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing birthdays:   0%|          | 0/582659 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b73aa4721e04bd09a367b89688fc993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "processing birthdays:   0%|          | 0/14566 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "birthday_dm = BirthdayDataModule(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2982e8b-786a-4e7e-a0c8-957ecbef6e29",
   "metadata": {},
   "source": [
    "## Create birthday model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1057c57f-21af-4795-953b-68ab3a829427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing profile embeddings before first epoch...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/2] Precomputing train embeddings - profile:   0%|          | 0/9105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[2/2] Precomputing val embeddings - profile:   0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def precompute_embeddings(model: DocumentProfileMatchingTransformer, datamodule: WikipediaDataModule):\n",
    "    model.profile_model.cuda()\n",
    "    model.profile_model.eval()\n",
    "    print('Precomputing profile embeddings before first epoch...')\n",
    "    \n",
    "    model.train_profile_embeddings = np.zeros((len(datamodule.train_dataset), model.profile_embedding_dim))\n",
    "    for train_batch in tqdm(datamodule.train_dataloader(), desc=\"[1/2] Precomputing train embeddings - profile\", colour=\"cyan\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile_text(text=train_batch[\"profile\"])\n",
    "        model.train_profile_embeddings[train_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.train_profile_embeddings = torch.tensor(model.train_profile_embeddings, dtype=torch.float32)\n",
    "    \n",
    "    model.val_profile_embeddings = np.zeros((len(datamodule.val_dataset), model.profile_embedding_dim))\n",
    "    for val_batch in tqdm(datamodule.val_dataloader(), desc=\"[2/2] Precomputing val embeddings - profile\", colour=\"green\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile_text(text=val_batch[\"profile\"])\n",
    "        model.val_profile_embeddings[val_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.val_profile_embeddings = torch.tensor(model.val_profile_embeddings, dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    model.profile_model.train()\n",
    "\n",
    "precompute_embeddings(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "07850e58-4195-4b64-bc1c-899d3df4820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import transformers\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from transformers import AdamW\n",
    "\n",
    "class BirthdayModel(LightningModule):\n",
    "    \"\"\"Probes the PROFILE for birthday info.\"\"\"\n",
    "    profile_embeddings: torch.Tensor\n",
    "    classifier: torch.nn.Module\n",
    "    learning_rate: float\n",
    "    \n",
    "    def __init__(self, model: DocumentProfileMatchingTransformer, learning_rate: float):\n",
    "        super().__init__()\n",
    "        # We can pre-calculate these embeddings bc\n",
    "        self.train_profile_embeddings = torch.tensor(model.train_profile_embeddings.cpu())\n",
    "        self.val_profile_embeddings = torch.tensor(model.val_profile_embeddings.cpu())\n",
    "        self.month_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(model.profile_embedding_dim, 64),\n",
    "            # torch.nn.Dropout(p=0.01),\n",
    "            torch.nn.Linear(64, 12),\n",
    "        )\n",
    "        self.day_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(model.profile_embedding_dim, 64),\n",
    "            # torch.nn.Dropout(p=0.01),\n",
    "            torch.nn.Linear(64, 31),\n",
    "        )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy   = torchmetrics.Accuracy()\n",
    "        self.loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def training_step(self, batch: Tuple[int, int], batch_idx: int) -> torch.Tensor:\n",
    "        profile_idxs, months, days = batch\n",
    "        assert ((0 <= profile_idxs) & (profile_idxs < len(self.train_profile_embeddings))).all()\n",
    "        assert ((0 <= months) & (months < 12)).all()\n",
    "        assert ((0 <= days) & (days < 31)).all()\n",
    "        \n",
    "        clf_device = next(self.month_classifier.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            embedding = self.train_profile_embeddings[profile_idxs].to(clf_device)\n",
    "        \n",
    "        \n",
    "        month_logits = self.month_classifier(embedding)\n",
    "        day_logits = self.day_classifier(embedding)\n",
    "        \n",
    "        \n",
    "        month_loss = torch.nn.functional.cross_entropy(month_logits, months)\n",
    "        day_loss = torch.nn.functional.cross_entropy(day_logits, days)\n",
    "        \n",
    "        self.log('train_acc_month', self.train_accuracy(month_logits, months))\n",
    "        self.log('train_acc_day', self.train_accuracy(day_logits, days))\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print('train_acc_month', self.train_accuracy(month_logits, months))\n",
    "            print('train_acc_day', self.train_accuracy(day_logits, days))\n",
    "        \n",
    "        return (month_loss + day_loss)\n",
    "    \n",
    "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n",
    "        profile_idxs, months, days = batch\n",
    "        assert ((0 <= profile_idxs) & (profile_idxs < len(self.val_profile_embeddings))).all()\n",
    "        assert ((0 <= months) & (months < 12)).all()\n",
    "        assert ((0 <= days) & (days < 31)).all()\n",
    "        \n",
    "        clf_device = next(self.month_classifier.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            embedding = self.val_profile_embeddings[profile_idxs].to(clf_device)\n",
    "        \n",
    "        \n",
    "        month_logits = self.month_classifier(embedding)\n",
    "        day_logits = self.day_classifier(embedding)\n",
    "        \n",
    "        \n",
    "        month_loss = torch.nn.functional.cross_entropy(month_logits, months)\n",
    "        day_loss = torch.nn.functional.cross_entropy(day_logits, days)\n",
    "        \n",
    "        self.log('val_acc_month', self.val_accuracy(month_logits, months))\n",
    "        self.log('val_acc_day', self.val_accuracy(day_logits, days))\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print('val_acc_month', self.val_accuracy(month_logits, months))\n",
    "            print('val_acc_day', self.val_accuracy(day_logits, days))\n",
    "\n",
    "        return (month_loss + day_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
    "        optimizer = AdamW(\n",
    "            list(self.parameters()), lr=self.learning_rate\n",
    "        )\n",
    "        return optimizer\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8da2e-b0c4-417e-8a39-34e2b20fdbb4",
   "metadata": {},
   "source": [
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "99ae16d1-a388-4352-8e46-ef86bc8232ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "num_validations_per_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f9ca3e84-33e7-4cde-a4ad-a12334cbcb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-189-e59b770caefb>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.train_profile_embeddings = torch.tensor(model.train_profile_embeddings.cpu())\n",
      "<ipython-input-189-e59b770caefb>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.val_profile_embeddings = torch.tensor(model.val_profile_embeddings.cpu())\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "birthday_model = BirthdayModel(model, 1e-3)\n",
    "birthday_dm.batch_size = 512\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "trainer = Trainer(\n",
    "    default_root_dir=f\"saves/jup/birthday_probing\",\n",
    "    val_check_interval=1.0,\n",
    "    max_epochs=25,\n",
    "    log_every_n_steps=50,\n",
    "    gpus=torch.cuda.device_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3ad30bce-e533-47d8-9cd0-756bd000973d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name             | Type             | Params\n",
      "------------------------------------------------------\n",
      "0 | month_classifier | Sequential       | 50.0 K\n",
      "1 | day_classifier   | Sequential       | 51.2 K\n",
      "2 | train_accuracy   | Accuracy         | 0     \n",
      "3 | val_accuracy     | Accuracy         | 0     \n",
      "4 | loss_criterion   | CrossEntropyLoss | 0     \n",
      "------------------------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.405     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0938, device='cuda:0')\n",
      "val_acc_day tensor(0.0273, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a29c36ce9e942928913da24cbcc75c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc_month tensor(0.0977, device='cuda:0')\n",
      "train_acc_day tensor(0.0371, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0957, device='cuda:0')\n",
      "val_acc_day tensor(0.0312, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc_month tensor(0.0762, device='cuda:0')\n",
      "train_acc_day tensor(0.0430, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f2f78ec29d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jxm3/.conda/envs/textattack/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0996, device='cuda:0')\n",
      "val_acc_day tensor(0.0293, device='cuda:0')\n",
      "train_acc_month tensor(0.0781, device='cuda:0')\n",
      "train_acc_day tensor(0.0391, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0996, device='cuda:0')\n",
      "val_acc_day tensor(0.0234, device='cuda:0')\n",
      "train_acc_month tensor(0.0723, device='cuda:0')\n",
      "train_acc_day tensor(0.0430, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.1016, device='cuda:0')\n",
      "val_acc_day tensor(0.0312, device='cuda:0')\n",
      "train_acc_month tensor(0.0801, device='cuda:0')\n",
      "train_acc_day tensor(0.0391, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0977, device='cuda:0')\n",
      "val_acc_day tensor(0.0195, device='cuda:0')\n",
      "train_acc_month tensor(0.0801, device='cuda:0')\n",
      "train_acc_day tensor(0.0352, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0977, device='cuda:0')\n",
      "val_acc_day tensor(0.0273, device='cuda:0')\n",
      "train_acc_month tensor(0.0801, device='cuda:0')\n",
      "train_acc_day tensor(0.0391, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0996, device='cuda:0')\n",
      "val_acc_day tensor(0.0312, device='cuda:0')\n",
      "train_acc_month tensor(0.0742, device='cuda:0')\n",
      "train_acc_day tensor(0.0391, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0996, device='cuda:0')\n",
      "val_acc_day tensor(0.0352, device='cuda:0')\n",
      "train_acc_month tensor(0.0781, device='cuda:0')\n",
      "train_acc_day tensor(0.0352, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.1016, device='cuda:0')\n",
      "val_acc_day tensor(0.0332, device='cuda:0')\n",
      "train_acc_month tensor(0.0781, device='cuda:0')\n",
      "train_acc_day tensor(0.0391, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.1016, device='cuda:0')\n",
      "val_acc_day tensor(0.0273, device='cuda:0')\n",
      "train_acc_month tensor(0.0820, device='cuda:0')\n",
      "train_acc_day tensor(0.0391, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0957, device='cuda:0')\n",
      "val_acc_day tensor(0.0273, device='cuda:0')\n",
      "train_acc_month tensor(0.0801, device='cuda:0')\n",
      "train_acc_day tensor(0.0391, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0957, device='cuda:0')\n",
      "val_acc_day tensor(0.0293, device='cuda:0')\n",
      "train_acc_month tensor(0.0762, device='cuda:0')\n",
      "train_acc_day tensor(0.0410, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0918, device='cuda:0')\n",
      "val_acc_day tensor(0.0293, device='cuda:0')\n",
      "train_acc_month tensor(0.0703, device='cuda:0')\n",
      "train_acc_day tensor(0.0410, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0898, device='cuda:0')\n",
      "val_acc_day tensor(0.0352, device='cuda:0')\n",
      "train_acc_month tensor(0.0684, device='cuda:0')\n",
      "train_acc_day tensor(0.0430, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0918, device='cuda:0')\n",
      "val_acc_day tensor(0.0332, device='cuda:0')\n",
      "train_acc_month tensor(0.0684, device='cuda:0')\n",
      "train_acc_day tensor(0.0449, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_acc_month tensor(0.0898, device='cuda:0')\n",
      "val_acc_day tensor(0.0352, device='cuda:0')\n",
      "train_acc_month tensor(0.0703, device='cuda:0')\n",
      "train_acc_day tensor(0.0449, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(birthday_model, birthday_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ee97b0-bae0-4da5-a3b8-37c7a907a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab25fb93-cb9e-4e9a-a240-82bb354a5e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emebdding.shape: torch.Size([64, 768])\n",
      "birthday_logits.shape: torch.Size([64, 372])\n",
      "loss: tensor(6.0617, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "val_batch = next(iter(birthday_dm.val_dataloader()))\n",
    "\n",
    "def do_validation_batch(batch, batch_idx):\n",
    "    profile_idxs, birthday_idxs = batch\n",
    "    clf_device = next(birthday_model.classifier.parameters()).device\n",
    "    embedding = birthday_model.val_profile_embeddings[profile_idxs].to(clf_device)\n",
    "    print('emebdding.shape:', embedding.shape)\n",
    "    birthday_logits = birthday_model.classifier(embedding)\n",
    "    print('birthday_logits.shape:', birthday_logits.shape)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        birthday_logits, birthday_idxs\n",
    "    )\n",
    "    # self.log('val_accuracy', self.val_accuracy(birthday_logits, birthday_idxs))\n",
    "    print('loss:', loss)\n",
    "\n",
    "do_validation_batch(val_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c4109e40-b072-4cc9-990b-ed8ea0b7801a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 18, 19, 20, 21, 23,\n",
       "         26, 28, 30, 31, 32, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 47, 48, 49,\n",
       "         50, 51, 52, 53, 54, 55, 56, 60, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73,\n",
       "         74, 76, 77, 78, 79, 80, 81, 82, 83, 85]),\n",
       " tensor([339,  75,  93, 131, 221, 331, 329, 334, 106, 241, 102, 219, 282, 129,\n",
       "         206, 211,  14, 117, 170, 151, 101, 222, 232, 312, 347, 254,  36, 361,\n",
       "          47, 207, 250, 212,  85, 272, 266, 204,  94,   4, 148, 141, 267, 325,\n",
       "          87, 228, 371,  74, 285, 193,  48, 209, 126,  16,  21, 365, 183,  25,\n",
       "         317, 247,  66,  74,  39,  58, 251,  55])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch # last element: idx 85, birthday 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39966a7e-07e2-4656-bbdc-c9e990927b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': \"ben wilson (born 25 february 1977) is a former australian rules footballer who played with collingwood and the sydney swans in the australian football league (afl) .\\nwilson was secured by collingwood from norwood in the 1994 afl draft with the ninth selection , but first not from a tac cup side .\\nthe south australian did n't feature in the 1995 afl season and then appeared twice for collingwood in 1996 .\\nhe was traded to sydney at the end of 1996 , along with mark orchard and two draft picks , for which collingwood received anthony rocca .\\nhe played in the opening three rounds of the 1997 season but made only one further appearance .\\n\",\n",
       " 'profile': \"fullname | ben wilson\\nname | ben wilson\\noriginalteam | norwood\\nyears | 1996 1997 '' ` total - '' '\\ndraftpick | 9th , 1994 afl draft\\nclubs | collingwood sydney swans\\nbirth_date | 25 february 1977\\narticle_title | ben wilson -lrb- australian footballer -rrb-\\nheightweight | 191 ; kg & nbsp ; cm / 87 & nbsp\\nstatsend | 1997\",\n",
       " 'profile_without_name': \"fullname | ben wilson\\noriginalteam | norwood\\nyears | 1996 1997 '' ` total - '' '\\ndraftpick | 9th , 1994 afl draft\\nclubs | collingwood sydney swans\\nbirth_date | 25 february 1977\\nheightweight | 191 ; kg & nbsp ; cm / 87 & nbsp\\nstatsend | 1997\",\n",
       " 'document_redact_lexical': '<mask> <mask> (born <mask> <mask> <mask>) is a former <mask> rules <mask> who played with <mask> and the <mask> <mask> in the <mask> football league (<mask>) .\\n<mask> was secured by <mask> from <mask> in the <mask> <mask> <mask> with the ninth selection <mask> but first not from a tac cup side .\\nthe south <mask> did n<mask>t feature in the 1995 <mask> season and then appeared twice for <mask> in <mask> .\\nhe was traded to <mask> at the end of <mask> <mask> along with mark orchard and two <mask> picks <mask> for which <mask> received anthony rocca .\\nhe played in the opening three rounds of the <mask> season but made only one further appearance .\\n',\n",
       " 'document_redact_ner': \"<mask> <mask> (born <mask> <mask> <mask>) is a former <mask> rules footballer who played with collingwood and the sydney swans in the <mask> football league (afl) .\\n<mask> was secured by <mask> from norwood in the <mask> afl draft with the <mask> selection , but <mask> not from a tac cup side .\\nthe south <mask> did n't feature in the 1995 afl season and then appeared twice for collingwood in <mask> .\\nhe was traded to sydney at <mask> <mask> <mask> <mask> , along with mark orchard and <mask> draft picks , for which <mask> received <mask> <mask> .\\nhe played in the opening <mask> rounds of the 1997 season but made <mask> <mask> further appearance .\\n\",\n",
       " 'text_key_id': 85}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55 % 31 # february 24th\n",
    "\n",
    "dm.val_dataset[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cab00193-3ebf-4e66-9a56-dcac1efffd25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0936,  0.3824,  0.6874,  0.7990, -0.5991])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birthday_model.val_profile_embeddings[85][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "fa29c237-a9d7-4b3a-9e15-46e4a164e9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0936,  0.3824,  0.6874,  0.7990, -0.5991], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.forward_profile_text(text=[dm.val_dataset[85]['profile']])[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9add825b-edad-46ba-8f55-0c9a54715782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_batch = next(iter(birthday_dm.train_dataloader()))\n",
    "train_batch # 682, 78\n",
    "78 % 31 # 16 -> this is march 17th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a190c107-567b-4994-a35f-1b3691200206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nationalgoals | 12\\nfullname | jesús candelas rodrigo\\nmanagerclubs | netherlands assistant -rrb- iran netherlands malta thailand -lrb- assistant -rrb- hong kong malaysia netherlands -lrb-\\nname | victor hermans\\narticle_title | victor hermans\\nnationalyears | 1977 -- 1989\\nposition | manager -lrb- association football -rrb-\\ncurrentclub | thailand national futsal team -lrb- head coach -rrb-\\nclubs | mvv maastricht k.s.k. tongeren\\nnationalteam | netherlands -lrb- futsal -rrb-\\nbirth_place | maastricht , netherlands\\nbirth_date | 17 march 1953\\nnationalcaps | 50\\nmanageryears | 1990 2000 2001 2001-2007 2009 -- 2011 2012 -- -- 1992 1992 -- 1996 1996 1997 --\\nheight | 1.72'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_dataset[682]['profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9ed50693-d79b-41c3-8b4b-5e95a5b28822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3974,  0.4090,  0.3919,  1.2626, -0.1960])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "birthday_model.train_profile_embeddings[682][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b09f9a55-3d33-414d-83c1-743be75183fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3974,  0.4090,  0.3919,  1.2626, -0.1960], device='cuda:0',\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.forward_profile_text(text=[dm.train_dataset[682]['profile']])[0, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "54081f5a-d022-41b6-b342-d15ebc793b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0123,  0.0198, -0.0286,  ...,  0.0052, -0.0202,  0.0360],\n",
       "          [-0.0107,  0.0232,  0.0180,  ...,  0.0116, -0.0154, -0.0274],\n",
       "          [-0.0222, -0.0221,  0.0122,  ...,  0.0234,  0.0198,  0.0023],\n",
       "          ...,\n",
       "          [ 0.0127,  0.0177, -0.0266,  ..., -0.0159, -0.0071,  0.0111],\n",
       "          [-0.0245,  0.0075,  0.0298,  ..., -0.0179, -0.0173,  0.0030],\n",
       "          [ 0.0115,  0.0255,  0.0330,  ..., -0.0075, -0.0049, -0.0297]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('0.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0013,  0.0079,  0.0005, -0.0231,  0.0133, -0.0023,  0.0213, -0.0355,\n",
       "          -0.0328, -0.0144, -0.0042,  0.0066, -0.0263, -0.0157,  0.0100,  0.0275,\n",
       "           0.0136, -0.0305, -0.0026, -0.0168,  0.0358, -0.0242,  0.0104,  0.0301,\n",
       "           0.0180,  0.0171,  0.0291,  0.0126,  0.0347,  0.0225,  0.0016, -0.0308,\n",
       "           0.0349, -0.0179, -0.0320,  0.0195, -0.0254,  0.0104,  0.0150, -0.0162,\n",
       "           0.0283, -0.0039, -0.0328, -0.0060, -0.0165, -0.0120, -0.0170, -0.0235,\n",
       "          -0.0352,  0.0144, -0.0301, -0.0137,  0.0017,  0.0382,  0.0244, -0.0185,\n",
       "           0.0283, -0.0119,  0.0005, -0.0137,  0.0091,  0.0157, -0.0030,  0.0207],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0337, -0.0920,  0.0875,  ..., -0.0636, -0.0773, -0.0574],\n",
       "          [-0.0012,  0.0175, -0.0539,  ...,  0.0705, -0.0700, -0.1099],\n",
       "          [ 0.0043,  0.0764,  0.1039,  ...,  0.0481, -0.0374,  0.0520],\n",
       "          ...,\n",
       "          [-0.0468,  0.0516, -0.0190,  ...,  0.0290,  0.0435,  0.0048],\n",
       "          [ 0.0811,  0.0976,  0.1089,  ...,  0.0472,  0.0555, -0.0006],\n",
       "          [ 0.1114,  0.0204, -0.0691,  ..., -0.0351,  0.0810,  0.0931]],\n",
       "         device='cuda:0', requires_grad=True)),\n",
       " ('2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0870,  0.0729, -0.0289, -0.0677, -0.1012, -0.0503, -0.1068, -0.0736,\n",
       "          -0.0143, -0.0717,  0.1077,  0.1260,  0.0432,  0.0496,  0.0426,  0.0949,\n",
       "          -0.0696,  0.0289,  0.0497, -0.0227, -0.0836,  0.1024,  0.0082,  0.0697,\n",
       "           0.1041,  0.0171, -0.0586,  0.0934, -0.0383,  0.0688,  0.0113,  0.0479,\n",
       "          -0.0159,  0.0595,  0.0331,  0.0836,  0.0340,  0.0831, -0.0236,  0.0065,\n",
       "          -0.0666,  0.0432,  0.1012,  0.0874, -0.0021,  0.0061,  0.1215, -0.0815,\n",
       "          -0.1043, -0.1065,  0.0998, -0.0668, -0.0047, -0.0433,  0.1000,  0.0227,\n",
       "           0.0069, -0.0552, -0.0885, -0.0664, -0.0543, -0.0206,  0.0647,  0.0276,\n",
       "          -0.0650, -0.0591,  0.0337, -0.0533, -0.1014,  0.0148, -0.1074,  0.0308,\n",
       "          -0.0283, -0.0592, -0.0138,  0.0201, -0.0741,  0.1059,  0.0424, -0.0520,\n",
       "           0.0312, -0.0373,  0.1128, -0.0843, -0.0305,  0.0604,  0.1067, -0.0756,\n",
       "          -0.0319, -0.0095,  0.0547, -0.0938,  0.0381, -0.0927, -0.0105, -0.0383,\n",
       "          -0.0553,  0.0072, -0.0008, -0.0551,  0.0037, -0.0960,  0.0292,  0.0733,\n",
       "          -0.0770, -0.0393,  0.0506,  0.0515, -0.0379,  0.0058,  0.0905, -0.1010,\n",
       "           0.0301, -0.0783, -0.0690, -0.0564, -0.0969, -0.0117,  0.0309,  0.0514,\n",
       "           0.0855, -0.0640, -0.1065,  0.0596, -0.0990, -0.1059,  0.1231, -0.0824,\n",
       "          -0.1071,  0.0441,  0.0796, -0.1159,  0.1165,  0.0653,  0.0500,  0.0850,\n",
       "          -0.1092, -0.1192,  0.1046,  0.0314, -0.0910,  0.0083, -0.0866, -0.0979,\n",
       "          -0.0468, -0.0417, -0.0700,  0.1078, -0.0765,  0.1205, -0.1118, -0.0391,\n",
       "           0.0744,  0.0143,  0.0579, -0.0214, -0.0187,  0.0729, -0.1145,  0.0646,\n",
       "           0.0203, -0.0803,  0.0310,  0.0142,  0.0529, -0.1170, -0.0574, -0.0777,\n",
       "           0.0722,  0.1140,  0.0138,  0.0686,  0.0280,  0.0759,  0.0291,  0.0638,\n",
       "          -0.0835, -0.0931, -0.0023, -0.0523,  0.0399,  0.1182,  0.0241,  0.0227,\n",
       "           0.0461, -0.0870, -0.0151,  0.1126,  0.0321,  0.1166,  0.0236,  0.0940,\n",
       "           0.1077, -0.0153, -0.1018,  0.1101,  0.0903, -0.0384,  0.0784,  0.0968,\n",
       "          -0.0963,  0.1054, -0.0868,  0.0435, -0.0348,  0.1197, -0.0928,  0.0439,\n",
       "          -0.0535,  0.1018, -0.0820,  0.0969, -0.0435, -0.0491,  0.0295,  0.0219,\n",
       "          -0.1105, -0.0891,  0.0638,  0.0108,  0.0004, -0.0958,  0.0603,  0.0995,\n",
       "           0.0916, -0.0900, -0.0864,  0.0795, -0.0619, -0.1045,  0.1262, -0.0020,\n",
       "          -0.0095, -0.0310,  0.1080,  0.1055, -0.0381, -0.0963,  0.0451, -0.0762,\n",
       "           0.0488, -0.1098,  0.0326,  0.0781, -0.1216,  0.1130,  0.0296,  0.0486,\n",
       "           0.0601,  0.0250, -0.0084, -0.0991, -0.0696,  0.0300,  0.1073,  0.1068,\n",
       "          -0.0739, -0.0928,  0.0370,  0.0423,  0.0324,  0.0262, -0.1137, -0.0627,\n",
       "           0.1169,  0.0193,  0.0189, -0.0620, -0.0192,  0.1051,  0.0163,  0.0367,\n",
       "          -0.0548,  0.0488,  0.0557,  0.0543, -0.0147,  0.0607,  0.0415,  0.0175,\n",
       "           0.0685, -0.0815, -0.0398,  0.0738,  0.0428,  0.0353,  0.0300,  0.1131,\n",
       "          -0.1003,  0.0438, -0.0313,  0.1084,  0.0659, -0.0906,  0.0310,  0.0552,\n",
       "           0.0548, -0.0414, -0.0009,  0.0893, -0.0711,  0.0315, -0.0204, -0.0999,\n",
       "           0.1099,  0.0822, -0.0023, -0.0762,  0.0335,  0.0416,  0.0140, -0.0180,\n",
       "          -0.0040,  0.0926, -0.0071,  0.0358,  0.0071, -0.0459,  0.0902,  0.0263,\n",
       "          -0.0395, -0.0252, -0.0707,  0.0845, -0.0741, -0.0770,  0.0208,  0.1066,\n",
       "           0.0664, -0.0090,  0.0465,  0.0395, -0.0772,  0.0421,  0.0837,  0.0723,\n",
       "           0.0209,  0.0426,  0.0318, -0.0349,  0.0747, -0.0111, -0.0689,  0.0749,\n",
       "          -0.0526,  0.0575,  0.0819,  0.0539,  0.0136,  0.0303, -0.0580,  0.0291,\n",
       "          -0.0238,  0.0401,  0.0906,  0.0128, -0.0979, -0.0738, -0.0750, -0.0478,\n",
       "          -0.0342,  0.0235, -0.0975, -0.0043, -0.0867, -0.0494,  0.0917,  0.0062,\n",
       "           0.0014, -0.0199, -0.1200, -0.1088], device='cuda:0',\n",
       "         requires_grad=True))]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(birthday_model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929e3d8-5928-4038-8fd1-b14457c4228a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
