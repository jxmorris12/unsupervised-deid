{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dd8d98-0748-478b-8c82-6b77cfa44e53",
   "metadata": {},
   "source": [
    "# Birthdays probing test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d252cb9-4ee5-42f2-98df-af6e72555090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "529344f2-556a-49e3-92e4-b5055c9b0469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with learning_rate = 1e-05 and patience 3\n"
     ]
    }
   ],
   "source": [
    "from model import CoordinateAscentModel\n",
    "\n",
    "import os\n",
    "\n",
    "num_cpus = len(os.sched_getaffinity(0))\n",
    "\n",
    "model = CoordinateAscentModel(\n",
    "    document_model_name_or_path='roberta-base',\n",
    "    profile_model_name_or_path='google/tapas-base',\n",
    "    num_workers=min(8, num_cpus),\n",
    "    learning_rate=1e-5,\n",
    "    pretrained_profile_encoder=False,\n",
    "    word_dropout_ratio=0.0,\n",
    "    word_dropout_perc=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29132408-7f12-472e-896b-494b99fda702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WikipediaDataModule with num_workers = 24 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:100%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split val[:20%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-3c0ffadd02c12daf.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7d07543b6205ca87.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f8a28259e34ec4bdfcce8bbbdfc255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11e3c06864142258382f1879cb4649f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36087678d194f1386645d3b413bbf71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6b5462162d4950a2365a921e4c56a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56c1a646fcc405ba085c3e3dcb0855c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f306f67e7e142bdad77a032b609814c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd6bd7675e84d1d9d2fb091d69bcfb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e262f2c59fbd43a691de970453944e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6437f9bdd72e49a091331babd12452d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#8:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b755b896c22b48b59bb204ca5cbcbcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#9:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2117eb01d7dd4eaca5ed4f4b9263a4b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#10:   0%|          | 0/24278 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244f9f3534ca409f8db0618f3ce35a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#11:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5a065a940847b9a6b2b5d3fc21f5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#13:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6195e861550941acbdbcdcb9229a556a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#12:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23ccf2a395b49b69b5d65b5ffd7bcff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#14:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8b9e3266674d1e9a099e2fd73c529f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#16:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8397027f103b40c2a64061e29828e640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#15:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afa0cc1de5848bd8af879b0c6628d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#17:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45400a680d524d439018f1ee295157c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#18:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a063a58649943e49d67554dc53e09ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#19:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d820f604954eda8012d7cbca32ae5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#21:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0ab4bd8f464239ad434db52638a8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#20:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc237b882a3419aa06cda1fa71eef67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#22:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090d4c65640a49fcb57095821137bd73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#23:   0%|          | 0/24277 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataloader import WikipediaDataModule\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    document_model_name_or_path='roberta-base',\n",
    "    profile_model_name_or_path='google/tapas-base',\n",
    "    max_seq_length=128,\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:100%]',\n",
    "    dataset_val_split='val[:20%]',\n",
    "    dataset_version='1.2.0',\n",
    "    num_workers=num_cpus,\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea5280-96de-48cd-9ccc-23d8c3f3237d",
   "metadata": {},
   "source": [
    "## Get the birthday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6da6f-9788-4a13-bb05-46383951d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import datasets\n",
    "\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "def process_dataset_example(ex: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"Parses example. Returns tuple (idx, month, day) or None.\"\"\"\n",
    "    profile = ex['profile']\n",
    "    date_str_matches = re.search(r\"birth_date \\|\\| ([\\d]{1,4} [a-z]+ [\\d]{1,4})\", profile)\n",
    "    try:\n",
    "        date_str = date_str_matches.group(1)\n",
    "        dt = datetime.datetime.strptime(date_str, \"%d %B %Y\")\n",
    "        ex['birthday'] = (ex['text_key_id'], dt.month-1, dt.day-1)\n",
    "    except (AttributeError, ValueError) as e:\n",
    "        # no birthdate or date in unknown format (just skip these ones)\n",
    "        ex['birthday'] = None\n",
    "    return ex\n",
    "\n",
    "def process_dataset(dataset: datasets.Dataset) -> List[Tuple[int, int, int]]:\n",
    "    new_dataset = dataset.map(process_dataset_example)\n",
    "    filtered_dataset = new_dataset.filter(lambda ex: ex['birthday'])\n",
    "    return filtered_dataset['birthday']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f793a8c-de55-4c12-8dd2-c3e6fa1f9e60",
   "metadata": {},
   "source": [
    "## Create birthday data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4eaea4-daf0-4996-96c9-0826a537b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningDataModule\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class BirthdayDataModule(LightningDataModule):\n",
    "    train_dataset: List[Tuple[int, int]]\n",
    "    val_dataset: List[Tuple[int, int]]\n",
    "    batch_size: int\n",
    "    def __init__(self, dm: WikipediaDataModule, batch_size: int = 64):\n",
    "        super().__init__()\n",
    "        self.train_dataset = process_dataset(dm.train_dataset)\n",
    "        self.val_dataset = process_dataset(dm.val_dataset)\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = min(4, num_cpus)\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        return\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False # Only shuffle for train\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa79a4-cced-4f94-a39b-1534759fd5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthday_dm = BirthdayDataModule(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2982e8b-786a-4e7e-a0c8-957ecbef6e29",
   "metadata": {},
   "source": [
    "## Create birthday model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057c57f-21af-4795-953b-68ab3a829427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def precompute_profile_embeddings(model: CoordinateAscentModel, dm: WikipediaDataModule):\n",
    "    model.profile_model.cuda()\n",
    "    model.profile_model.eval()\n",
    "    model.profile_embed.cuda()\n",
    "    model.profile_embed.eval()\n",
    "\n",
    "\n",
    "    model.train_profile_embeddings = np.zeros((len(dm.train_dataset), model.shared_embedding_dim))\n",
    "    for train_batch in tqdm(dm.train_dataloader(), desc=\"Precomputing train embeddings\", colour=\"#008080\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile(batch=train_batch)\n",
    "        model.train_profile_embeddings[train_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.train_profile_embeddings = torch.tensor(model.train_profile_embeddings, dtype=torch.float32)\n",
    "    \n",
    "    model.val_profile_embeddings = np.zeros((len(dm.val_dataset), model.shared_embedding_dim))\n",
    "    for val_batch in tqdm(dm.val_dataloader()[0], desc=\"Precomputing val embeddings\", colour=\"#c09591\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile(batch=val_batch)\n",
    "        model.val_profile_embeddings[val_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.val_profile_embeddings = torch.tensor(model.val_profile_embeddings, dtype=torch.float32)\n",
    "\n",
    "\n",
    "precompute_profile_embeddings(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07850e58-4195-4b64-bc1c-899d3df4820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import transformers\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from transformers import AdamW\n",
    "\n",
    "class BirthdayModel(LightningModule):\n",
    "    \"\"\"Probes the PROFILE for birthday info.\"\"\"\n",
    "    profile_embeddings: torch.Tensor\n",
    "    classifier: torch.nn.Module\n",
    "    learning_rate: float\n",
    "    \n",
    "    def __init__(self, model: CoordinateAscentModel, learning_rate: float):\n",
    "        super().__init__()\n",
    "        # We can pre-calculate these embeddings bc\n",
    "        self.train_profile_embeddings = torch.tensor(model.train_profile_embeddings.cpu())\n",
    "        self.val_profile_embeddings = torch.tensor(model.val_profile_embeddings.cpu())\n",
    "        self.month_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(model.shared_embedding_dim, 64),\n",
    "            # torch.nn.Dropout(p=0.01),\n",
    "            torch.nn.Linear(64, 12),\n",
    "        )\n",
    "        self.day_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(model.shared_embedding_dim, 64),\n",
    "            # torch.nn.Dropout(p=0.01),\n",
    "            torch.nn.Linear(64, 31),\n",
    "        )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy   = torchmetrics.Accuracy()\n",
    "        self.loss_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def training_step(self, batch: Tuple[int, int], batch_idx: int) -> torch.Tensor:\n",
    "        profile_idxs, months, days = batch\n",
    "        assert ((0 <= profile_idxs) & (profile_idxs < len(self.train_profile_embeddings))).all()\n",
    "        assert ((0 <= months) & (months < 12)).all()\n",
    "        assert ((0 <= days) & (days < 31)).all()\n",
    "        \n",
    "        clf_device = next(self.month_classifier.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            embedding = self.train_profile_embeddings[profile_idxs].to(clf_device)\n",
    "        \n",
    "        \n",
    "        month_logits = self.month_classifier(embedding)\n",
    "        day_logits = self.day_classifier(embedding)\n",
    "        \n",
    "        \n",
    "        month_loss = torch.nn.functional.cross_entropy(month_logits, months)\n",
    "        day_loss = torch.nn.functional.cross_entropy(day_logits, days)\n",
    "        \n",
    "        self.log('train_acc_month', self.train_accuracy(month_logits, months))\n",
    "        self.log('train_acc_day', self.train_accuracy(day_logits, days))\n",
    "        \n",
    "#         if batch_idx == 0:\n",
    "#             print('train_acc_month', self.train_accuracy(month_logits, months))\n",
    "#             print('train_acc_day', self.train_accuracy(day_logits, days))\n",
    "        \n",
    "        return (month_loss + day_loss)\n",
    "    \n",
    "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n",
    "        profile_idxs, months, days = batch\n",
    "        assert ((0 <= profile_idxs) & (profile_idxs < len(self.val_profile_embeddings))).all()\n",
    "        assert ((0 <= months) & (months < 12)).all()\n",
    "        assert ((0 <= days) & (days < 31)).all()\n",
    "        \n",
    "        clf_device = next(self.month_classifier.parameters()).device\n",
    "        with torch.no_grad():\n",
    "            embedding = self.val_profile_embeddings[profile_idxs].to(clf_device)\n",
    "        \n",
    "        \n",
    "        month_logits = self.month_classifier(embedding)\n",
    "        day_logits = self.day_classifier(embedding)\n",
    "        \n",
    "        \n",
    "        month_loss = torch.nn.functional.cross_entropy(month_logits, months)\n",
    "        day_loss = torch.nn.functional.cross_entropy(day_logits, days)\n",
    "        \n",
    "        self.log('val_acc_month', self.val_accuracy(month_logits, months))\n",
    "        self.log('val_acc_day', self.val_accuracy(day_logits, days))\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print('val_acc_month', self.val_accuracy(month_logits, months).item(), '//', 'val_acc_day', self.val_accuracy(day_logits, days).item())\n",
    "\n",
    "        return (month_loss + day_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"\n",
    "        optimizer = AdamW(\n",
    "            list(self.parameters()), lr=self.learning_rate\n",
    "        )\n",
    "        return optimizer\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8da2e-b0c4-417e-8a39-34e2b20fdbb4",
   "metadata": {},
   "source": [
    "## Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae16d1-a388-4352-8e46-ef86bc8232ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer, seed_everything\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "num_validations_per_epoch = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca3e84-33e7-4cde-a4ad-a12334cbcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthday_model = BirthdayModel(model, 1e-4)\n",
    "birthday_dm.batch_size = 2048\n",
    "\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "trainer = Trainer(\n",
    "    default_root_dir=f\"saves/jup/birthday_probing\",\n",
    "    val_check_interval=1,\n",
    "    max_epochs=100,\n",
    "    log_every_n_steps=50,\n",
    "    gpus=torch.cuda.device_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad30bce-e533-47d8-9cd0-756bd000973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(birthday_model, birthday_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb7f6ae-4633-49b3-9628-53e6915782d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
