{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44162e52-42eb-41df-8037-27316a8577d0",
   "metadata": {},
   "source": [
    "# Evaluating ElasticSearch BM-25 top-k accuracy documents & baseline-redacted documents\n",
    "\n",
    "First, we need to connect to ElasticSearch and add all the profiles (as strings) to indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2aba53b8-3e23-4c8a-9030-17c019088301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/elasticsearch/connection/http_urllib3.py:209: UserWarning: Connecting to https://rush-compute-01.tech.cornell.edu:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "username = \"elastic\"\n",
    "password = \"FjZD_LI-=AJOtsfpq9U*\"\n",
    "\n",
    "url = f\"https://elastic:{password}@rush-compute-01.tech.cornell.edu:9200\"\n",
    "\n",
    "es = Elasticsearch(\n",
    "    url,\n",
    "    # use_ssl = True,\n",
    "    # ca_certs=False,\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eeae46e-7f61-4379-a252-d95e8809e45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'rush-compute-01.tech.cornell.edu', 'port': 9200, 'use_ssl': True, 'http_auth': 'elastic:FjZD_LI-=AJOtsfpq9U*'}])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809b97eb-b05a-46b6-b189-11374d07093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete an existing index\n",
    "# es.indices.delete(index='val_5_profile_str', ignore=[400, 404])\n",
    "# for idx in [idx for idx in es.indices.get_alias().keys() if not idx.startswith('.')]:\n",
    "    # print('deleting', idx)\n",
    "    # es.indices.delete(index=idx, ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d784a03a-5a8a-422b-bf79-787beaf43f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from elasticsearch import helpers\n",
    "from elasticsearch_dsl import Index\n",
    "\n",
    "\n",
    "def create_index_from_profiles(index_name: str, dataset_split: str, b: float = 0.9, k1: float = 4.5):\n",
    "    index = Index(index_name, es)\n",
    "    index.settings(\n",
    "        number_of_shards=1, # need one shard since scores are calculated with a single shard!\n",
    "        # https://www.elastic.co/guide/en/elasticsearch/reference/current/consistent-scoring.html\n",
    "        # need zero replicas for consistent scoring!\n",
    "        number_of_replicas=0,\n",
    "        index={\n",
    "            'mapping': {\n",
    "                'ignore_malformed': True,\n",
    "                'total_fields.limit': 20_000\n",
    "            },\n",
    "            \"similarity\" : {\n",
    "              \"default\" : {\n",
    "                \"type\" : \"BM25\",\n",
    "                \"b\": b,\n",
    "                \"k1\": k1\n",
    "              }\n",
    "            },\n",
    "            \n",
    "            #     'settings': {\n",
    "            #         'analysis': {\n",
    "            #           {\n",
    "            #             \"my_analyzer\": {\n",
    "            #               \"tokenizer\": \"whitespace\",\n",
    "            #               \"filter\": [ \"stop\" ]\n",
    "            #             }\n",
    "            #         }\n",
    "            #     }\n",
    "            # }\n",
    "        }\n",
    "    )\n",
    "    index.create()\n",
    "    \n",
    "\n",
    "    dataset = datasets.load_dataset('wiki_bio', split=dataset_split, version='1.2.0')\n",
    "\n",
    "    def make_prof_table(prof):\n",
    "        table = prof['input_text']['table']\n",
    "        prof_dict = dict(zip(table['column_header'], table['content']))\n",
    "        prof_dict = { k.strip().strip('.|<>'): v.strip().strip('.|<>') for k,v in prof_dict.items() }\n",
    "        if 'no.of.children' in prof_dict:\n",
    "            # fix for one weird error\n",
    "            prof_dict['no of children'] = prof_dict['no.of.children']\n",
    "            del prof_dict['no.of.children']\n",
    "        prof_dict = {k: v for k,v in prof_dict.items() if (len(k) and len(v))}\n",
    "        prof_str = ''\n",
    "        for k,v in prof_dict.items():\n",
    "            prof_str += f'{k} : {v}'\n",
    "            prof_str += '\\n'\n",
    "        return prof_str\n",
    "\n",
    "    prof_data = [make_prof_table(prof) for prof in dataset]\n",
    "\n",
    "    print('inserting', len(prof_data), 'profiles')\n",
    "\n",
    "    prof_data_json = [{'_id': idx, 'body': { 'profile': profile_str, 'id': idx }} for idx, profile_str in enumerate(prof_data)]\n",
    "    return helpers.bulk(es, prof_data_json, index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a69ea09-1780-4c76-bd11-35af6731b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_index_from_profiles('val_100_profile_str', 'val[:100%]')\n",
    "# create_index_from_profiles('test_100_profile_str', 'test[:100%]')\n",
    "# create_index_from_profiles('train_100_profile_str', 'train[:100%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4cf1e-4b18-492e-aed7-7b079019d91e",
   "metadata": {},
   "source": [
    "Now that the indices are created, we can iterate over documents and compute the top-K accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671fe92a-470f-4087-9199-b32d4912580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WikipediaDataModule with num_workers = 8 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:100%]\n",
      "loading wiki_bio[1.2.0] split val[:100%]\n",
      "loading wiki_bio[1.2.0] split test[:100%]\n",
      "                        "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')\n",
    "\n",
    "import os\n",
    "from datamodule import WikipediaDataModule\n",
    "\n",
    "num_cpus = len(os.sched_getaffinity(0))\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    document_model_name_or_path = 'roberta-base',\n",
    "    profile_model_name_or_path = 'google/tapas-base',\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:100%]',\n",
    "    dataset_val_split='val[:100%]',\n",
    "    dataset_test_split='test[:100%]',\n",
    "    dataset_version='1.2.0',\n",
    "    num_workers=num_cpus,\n",
    "    train_batch_size=256,\n",
    "    eval_batch_size=256,\n",
    "    max_seq_length=128,\n",
    "    sample_spans=False,\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bd8feb6f-c59e-45cb-b670-ad4ae450f6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_100__analyzer_nostopfilter_profile_str {'count': 72831, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
      "val_100_profile_str {'count': 72831, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
      "val_100__analyzer_yesstopfilter_profile_str {'count': 72831, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
      "test_100_profile_str {'count': 72831, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n",
      "train_100_profile_str {'count': 582659, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/textattack/lib/python3.9/site-packages/elasticsearch/connection/base.py:200: ElasticsearchWarning: this request accesses system indices: [.security-7], but in a future major version, direct access to system indices will be prevented by default\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "for index_name in [idx for idx in es.indices.get_alias().keys() if not idx.startswith('.')]:\n",
    "    print(index_name, es.count(index=index_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "183d2416-7b0f-4faf-a233-32e72c30e68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 2,\n",
       " 'responses': [{'took': 2,\n",
       "   'timed_out': False,\n",
       "   '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0},\n",
       "   'hits': {'total': {'value': 408, 'relation': 'eq'},\n",
       "    'max_score': 36.159836,\n",
       "    'hits': [{'_index': 'train_100_profile_str',\n",
       "      '_id': '286083',\n",
       "      '_score': 36.159836,\n",
       "      '_ignored': ['body.profile.keyword'],\n",
       "      '_source': {'body': {'profile': \"image_caption : fort worth , texas , 1900\\nparents : maximillian parker ann campbell gillies\\nnationality : american\\ncause : gunshot\\nconviction : imprisoned for horse theft in the state prison in laramie , wyoming\\ndeath_place : near san vicente , bolivia\\nimage_name : butch cassidy with bowler hat.jpg\\nallegiance : butch cassidy 's wild bunch\\ndeath_date : 7 november 1908\\nbirth_date : 13 april 1866\\narticle_title : butch cassidy\\nbirth_name : robert leroy parker\\nname : butch cassidy\\nimage_size : 250px\\nconviction_penalty : served 1896 18 months of 2-year sentence ; released january\\nalias : butch jim lowe , santiago maxwell , cassidy , mike cassidy , george cassidy ,\\npartner : harry , matt warner longabaugh , aka sundance kid , elzy lay\\nbirth_place : beaver , utah\\ncharge : horse robbery theft , cattle rustling , bank and train\\noccupation : bank thief and train robber , old west outlaw ,\\n\",\n",
       "        'id': 286083}}},\n",
       "     {'_index': 'train_100_profile_str',\n",
       "      '_id': '398154',\n",
       "      '_score': 29.086437,\n",
       "      '_ignored': ['body.profile.keyword'],\n",
       "      '_source': {'body': {'profile': 'name : patrick cassidy\\nrelatives : shaun -rrb- david cassidy -lrb- half-brother -rrb- katie cassidy -lrb- niece cassidy -rrb- -lrb- brother -rrb- ryan cassidy -lrb- brother\\nspouse : melissa hurley\\nparents : jack cassidy shirley jones\\nbirth_place : los angeles , california\\nbirth_date : 4 january 1962\\narticle_title : patrick cassidy -lrb- actor -rrb-\\noccupation : actor\\nchildren : cole patrick cassidy jack gordon cassidy\\n',\n",
       "        'id': 398154}}}]},\n",
       "   'status': 200},\n",
       "  {'took': 2,\n",
       "   'timed_out': False,\n",
       "   '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0},\n",
       "   'hits': {'total': {'value': 1722, 'relation': 'eq'},\n",
       "    'max_score': 36.832985,\n",
       "    'hits': [{'_index': 'val_100_profile_str',\n",
       "      '_id': '13',\n",
       "      '_score': 36.832985,\n",
       "      '_ignored': ['body.profile.keyword'],\n",
       "      '_source': {'body': {'profile': 'nationalgoals : 0 0\\nfullname : marlon evans\\ncaption : marlon bank of guam autograph signing in june 2015 evans taking pictures with the fans at the\\nname : marlon evans\\narticle_title : marlon evans\\nnationalyears : 2013 -- 2014 --\\nposition : midfield\\nimage_size : 250\\ncurrentclub : wings\\nntupdate : 17 october 2014\\nnationalteam : guam u-18 guam\\nclubnumber : 17\\nbirth_date : 3 august 1997\\nnationalcaps : 5 1\\nheight : 1.80\\n',\n",
       "        'id': 13}}},\n",
       "     {'_index': 'train_100_profile_str',\n",
       "      '_id': '193563',\n",
       "      '_score': 29.410042,\n",
       "      '_source': {'body': {'profile': 'occupation : conductor\\nimage : mdphotofeb2012.jpg\\nname : marlon daniel\\narticle_title : marlon daniel\\n',\n",
       "        'id': 193563}}}]},\n",
       "   'status': 200}]}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "import json\n",
    "\n",
    "def msearch(\n",
    "        es: Elasticsearch,\n",
    "        max_hits: int,\n",
    "        query_strings: List[str],\n",
    "        index: str = 'train_100_profile_str,test_100_profile_str,val_100_profile_str',\n",
    "        include_source: bool = False,\n",
    "    ):\n",
    "    search_arr = []\n",
    "    # req_head\n",
    "    \n",
    "    for q in query_strings:\n",
    "        search_arr.append({'index': index })\n",
    "        # req_body\n",
    "        search_arr.append(\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"query_string\": {\n",
    "                        \"query\": q\n",
    "                    },\n",
    "                },\n",
    "                'size': max_hits ,\n",
    "                '_source': include_source\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    request = ''\n",
    "    request = ' \\n'.join([json.dumps(x) for x in search_arr])\n",
    "\n",
    "    # as you can see, you just need to feed the <body> parameter,\n",
    "    # and don't need to specify the <index> and <doc_type> as usual \n",
    "    resp = es.msearch(body = request)\n",
    "    return resp\n",
    "\n",
    "msearch_results = msearch(es, query_strings=['Butch Cassidy', 'Marlon Evans'], max_hits=2, include_source=True)\n",
    "msearch_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7073c827-d0a4-4768-b3d5-1d7483598208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 3,\n",
       " 'responses': [{'took': 2,\n",
       "   'timed_out': False,\n",
       "   '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0},\n",
       "   'hits': {'total': {'value': 1, 'relation': 'eq'},\n",
       "    'max_score': 29.086437,\n",
       "    'hits': [{'_index': 'train_100_profile_str',\n",
       "      '_id': '398154',\n",
       "      '_score': 29.086437,\n",
       "      '_ignored': ['body.profile.keyword']}]},\n",
       "   'status': 200},\n",
       "  {'took': 2,\n",
       "   'timed_out': False,\n",
       "   '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0},\n",
       "   'hits': {'total': {'value': 1, 'relation': 'eq'},\n",
       "    'max_score': 36.832985,\n",
       "    'hits': [{'_index': 'val_100_profile_str',\n",
       "      '_id': '13',\n",
       "      '_score': 36.832985,\n",
       "      '_ignored': ['body.profile.keyword']}]},\n",
       "   'status': 200}]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def msearch_by_id(\n",
    "        es: Elasticsearch,\n",
    "        query_strings: List[str],\n",
    "        ids: List[int],\n",
    "        index: str = 'train_100_profile_str,test_100_profile_str,val_100_profile_str'\n",
    "    ):\n",
    "    search_arr = []\n",
    "    \n",
    "    assert len(ids) == len(query_strings)\n",
    "    for q, _id in zip(query_strings, ids):\n",
    "        search_arr.append({'index': index })\n",
    "        # req_body\n",
    "        search_arr.append(\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\n",
    "                                \"query_string\": {\n",
    "                                    \"query\": q\n",
    "                                }\n",
    "                            },\n",
    "                        ],\n",
    "                    \"filter\": {\n",
    "                          \"ids\": {\n",
    "                            \"values\": [_id]\n",
    "                          }\n",
    "                    }\n",
    "                    },\n",
    "                },\n",
    "                'size': 1 ,\n",
    "                'track_total_hits': True,\n",
    "                '_source': False\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    request = ''\n",
    "    request = ' \\n'.join([json.dumps(x) for x in search_arr])\n",
    "\n",
    "    # as you can see, you just need to feed the <body> parameter,\n",
    "    # and don't need to specify the <index> and <doc_type> as usual \n",
    "    resp = es.msearch(body = request)\n",
    "    return resp\n",
    "\n",
    "msearch_by_id(\n",
    "    es=es,\n",
    "    query_strings=['butch cassidy', 'marlon evans'], \n",
    "    # 286083 -> butch cassidy, (ranked #1)\n",
    "    # 398154 -> patrick cassidy  (ranked #2)\n",
    "    # ids=[398154, 13]\n",
    ")\n",
    "test_msearch_by_id_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3752d864-b89d-4dfa-bb41-514f2abcfead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': {'value': 1, 'relation': 'eq'},\n",
       " 'max_score': 29.086437,\n",
       " 'hits': [{'_index': 'train_100_profile_str',\n",
       "   '_id': '398154',\n",
       "   '_score': 29.086437,\n",
       "   '_ignored': ['body.profile.keyword']}]}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msearch_by_id_responses['responses'][0]['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9bc495e9-eb45-4462-b227-b9beb0cb003d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.086437"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_msearch_by_id_responses['responses'][0]['hits']['max_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1121248f-7d44-4f1d-9b62-11a4e121c4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 2,\n",
       " 'responses': [{'took': 2,\n",
       "   'timed_out': False,\n",
       "   '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0},\n",
       "   'hits': {'total': {'value': 9, 'relation': 'eq'},\n",
       "    'max_score': 36.159836,\n",
       "    'hits': [{'_index': 'train_100_profile_str',\n",
       "      '_id': '286083',\n",
       "      '_score': 36.159836,\n",
       "      '_ignored': ['body.profile.keyword']}]},\n",
       "   'status': 200},\n",
       "  {'took': 2,\n",
       "   'timed_out': False,\n",
       "   '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0},\n",
       "   'hits': {'total': {'value': 1, 'relation': 'eq'},\n",
       "    'max_score': 36.832985,\n",
       "    'hits': [{'_index': 'val_100_profile_str',\n",
       "      '_id': '13',\n",
       "      '_score': 36.832985,\n",
       "      '_ignored': ['body.profile.keyword']}]},\n",
       "   'status': 200}]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def msearch_total_hits_by_min_score(\n",
    "        es: Elasticsearch,\n",
    "        query_strings: List[str],\n",
    "        min_scores: List[float],\n",
    "        index: str = 'train_100_profile_str,test_100_profile_str,val_100_profile_str'\n",
    "    ):\n",
    "    search_arr = []\n",
    "    \n",
    "    # from https://stackoverflow.com/a/60857312/2287177:\n",
    "    #  If _search must be used instead of _count, and you're on Elasticsearch 7.0+,\n",
    "    # setting size: 0 and track_total_hits: true will provide the same info as _count\n",
    "    \n",
    "    assert len(query_strings) == len(min_scores)\n",
    "    for q, min_score in zip(query_strings, min_scores):\n",
    "        search_arr.append({'index': index })\n",
    "        # req_body\n",
    "        search_arr.append(\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"bool\": {\n",
    "                        \"must\": [\n",
    "                            {\n",
    "                                \"query_string\": {\n",
    "                                    \"query\": q\n",
    "                                }\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                },\n",
    "                \"min_score\": min_score,\n",
    "                \"track_total_hits\": True,\n",
    "                'size': 1,\n",
    "                '_source': False\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    request = ''\n",
    "    request = ' \\n'.join([json.dumps(x) for x in search_arr])\n",
    "\n",
    "    # as you can see, you just need to feed the <body> parameter,\n",
    "    # and don't need to specify the <index> and <doc_type> as usual \n",
    "    resp = es.msearch(body = request)\n",
    "    return resp\n",
    "\n",
    "sample_msearch_total_hits_by_min_score = msearch_total_hits_by_min_score(\n",
    "    es=es,\n",
    "    query_strings=['butch cassidy', 'marlon evans'], \n",
    "    # 286083 -> butch cassidy, (ranked #1)\n",
    "    # 398154 -> patrick cassidy  (ranked #2)\n",
    "    # ids=[398154, 13]\n",
    "    min_scores=[26.159836, 30.0]\n",
    ")\n",
    "sample_msearch_total_hits_by_min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "45d0a303-8fda-4947-9d7d-08cec45e7df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': {'value': 9, 'relation': 'eq'},\n",
       " 'max_score': 36.159836,\n",
       " 'hits': [{'_index': 'train_100_profile_str',\n",
       "   '_id': '286083',\n",
       "   '_score': 36.159836,\n",
       "   '_ignored': ['body.profile.keyword']}]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_msearch_total_hits_by_min_score['responses'][0]['hits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "06236740-2540-41c1-97ef-08bd03aa230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'286083'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_msearch_total_hits_by_min_score['responses'][0]['hits']['hits'][0]['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "305c372a-55c0-43c0-b810-5b66f7e765a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_msearch_total_hits_by_min_score['responses'][0]['hits']['total']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b4b073e-994e-4680-ab43-37aaec5d9b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.159836"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msearch_results['responses'][0]['hits']['hits'][0]['_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6feb124-eb7b-4e18-b1f2-c21dd495dc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['took', 'responses'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msearch_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60a1f923-720b-4084-8627-66f1f7b72ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'train_100_profile_str',\n",
       " '_id': '286083',\n",
       " '_score': 36.159836,\n",
       " '_ignored': ['body.profile.keyword'],\n",
       " '_source': {'body': {'profile': \"image_caption : fort worth , texas , 1900\\nparents : maximillian parker ann campbell gillies\\nnationality : american\\ncause : gunshot\\nconviction : imprisoned for horse theft in the state prison in laramie , wyoming\\ndeath_place : near san vicente , bolivia\\nimage_name : butch cassidy with bowler hat.jpg\\nallegiance : butch cassidy 's wild bunch\\ndeath_date : 7 november 1908\\nbirth_date : 13 april 1866\\narticle_title : butch cassidy\\nbirth_name : robert leroy parker\\nname : butch cassidy\\nimage_size : 250px\\nconviction_penalty : served 1896 18 months of 2-year sentence ; released january\\nalias : butch jim lowe , santiago maxwell , cassidy , mike cassidy , george cassidy ,\\npartner : harry , matt warner longabaugh , aka sundance kid , elzy lay\\nbirth_place : beaver , utah\\ncharge : horse robbery theft , cattle rustling , bank and train\\noccupation : bank thief and train robber , old west outlaw ,\\n\",\n",
       "   'id': 286083}}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msearch_results['responses'][1]['hits']['hits'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf890c73-f0f1-4c47-864e-557383bed7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "inf\n",
      "0\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_doc(doc: str) -> str:\n",
    "    # limit 500 words\n",
    "    doc = ' '.join(doc.split(' ')[:500])\n",
    "    # fix braces and remove weird characters\n",
    "    doc = doc.replace('-lrb-', '(').replace('-rrb-', ')')\n",
    "    return re.sub(r'[^\\w|\\s]', ' ',doc)\n",
    "\n",
    "def search_results_for_query_by_index(query: str, index: str, max_hits: int = 10):\n",
    "    # print(query)\n",
    "    search_results = es.search(index=index, q=query, size=max_hits, search_type='dfs_query_then_fetch')\n",
    "    num_hits = search_results[\"hits\"][\"total\"][\"value\"]\n",
    "    # print(\"got\", num_hits, \"hits\")\n",
    "    return num_hits, search_results[\"hits\"][\"hits\"]\n",
    "\n",
    "def index_of_doc_id_in_results_list(doc: str, doc_id: int, max_hits=100):\n",
    "    \"\"\"Searches for test doc in all three indices. Returns index of doc in results if found.\"\"\"\n",
    "    _, results = search_results_for_query_by_index(\n",
    "        query=preprocess_doc(doc),\n",
    "        index=\"val_100_profile_str,test_100_profile_str,train_100_profile_str\",\n",
    "        max_hits=max_hits\n",
    "    )\n",
    "    results_from_test_set = [\n",
    "        (idx, result) for (idx, result) in enumerate(results) if result['_index'] == 'test_100_profile_str'\n",
    "    ]\n",
    "    # print(len(results_from_test_set), \"results from test set\")\n",
    "    \n",
    "    for result_idx, result in enumerate(results):\n",
    "        if (result['_index'] == 'test_100_profile_str') and (int(result['_id']) == doc_id):\n",
    "            return result_idx\n",
    "    return float('inf')\n",
    "\n",
    "for i in range(4):\n",
    "    print(index_of_doc_id_in_results_list(dm.test_dataset[i]['document'], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0152be2a-c103-47b9-b20b-f0f05a52573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [03:03<00:00,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy = 71.30\n",
      "Top-10 accuracy = 85.10\n",
      "Top-100 accuracy = 93.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import tqdm\n",
    "\n",
    "k_values = [1, 10, 100]\n",
    "total_correct_by_k_doc = collections.defaultdict(lambda: 0)\n",
    "total = 1000\n",
    "for j in tqdm.trange(total):\n",
    "    result_idx = index_of_doc_id_in_results_list(dm.test_dataset[j]['document'], j)\n",
    "    for k in k_values:\n",
    "        if result_idx < k: total_correct_by_k_doc[k] += 1\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    acc = total_correct_by_k_doc[k] / total\n",
    "    acc_str = f'Top-{k} accuracy = {acc*100.0:.2f}'\n",
    "    print(acc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28010b3-58ec-41d1-80c6-2fb624aeb0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:03<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy = 0.00\n",
      "Top-10 accuracy = 0.10\n",
      "Top-100 accuracy = 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_correct_by_k_lex = collections.defaultdict(lambda: 0)\n",
    "total = 1000\n",
    "for j in tqdm.trange(total):\n",
    "    result_idx = index_of_doc_id_in_results_list(dm.test_dataset[j]['document_redact_lexical'], j)\n",
    "    for k in k_values:\n",
    "        if result_idx < k: total_correct_by_k_lex[k] += 1\n",
    "\n",
    "        \n",
    "for k in k_values:\n",
    "    acc = total_correct_by_k_lex[k] / total\n",
    "    acc_str = f'Top-{k} accuracy = {acc*100.0:.2f}'\n",
    "    print(acc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bb5a5-515a-4dab-9fc5-7978bb62cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:33<00:00,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy = 0.10\n",
      "Top-10 accuracy = 0.60\n",
      "Top-100 accuracy = 11.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_correct_by_k_ner = collections.defaultdict(lambda: 0)\n",
    "total = 1000\n",
    "for j in tqdm.trange(total):\n",
    "    result_idx = index_of_doc_id_in_results_list(dm.test_dataset[j]['document_redact_ner_bert'], j)\n",
    "    for k in k_values:\n",
    "        if result_idx < k: total_correct_by_k_ner[k] += 1\n",
    "\n",
    "        \n",
    "for k in k_values:\n",
    "    acc = total_correct_by_k_ner[k] / total\n",
    "    acc_str = f'Top-{k} accuracy = {acc*100.0:.2f}'\n",
    "    print(acc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "574e7522-63d4-4036-b734-e3b4d8fcd927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_3_1 ['../adv_csvs_full/model_3_1/results__b_1__k_1__n_1000.csv']\n",
      "model_3_2 ['../adv_csvs_full/model_3_2/results__b_1__k_1__n_1000.csv', '../adv_csvs_full/model_3_2__idf/results__b_1__k_1__n_1000.csv']\n",
      "model_3_3 ['../adv_csvs_full/model_3_3__placeholder/results__b_1__k_1__n_1000.csv']\n",
      "model_3_4 ['../adv_csvs_full/model_3_4/results__b_1__k_1__n_1000.csv', '../adv_csvs_full/model_3_4__idf/results__b_1__k_1__n_1000.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "adv_df = None\n",
    "for model_name in ['model_3_1', 'model_3_2', 'model_3_3', 'model_3_4']:\n",
    "    csv_filenames = glob.glob(f'../adv_csvs_full/{model_name}*/results__b_1__k_1__n_1000.csv')\n",
    "    print(model_name, csv_filenames)\n",
    "    for filename in csv_filenames:\n",
    "        df = pd.read_csv(filename)\n",
    "        df['model_name'] = re.search(r'adv_csvs_full/(model_\\d.*)/.+.csv', filename).group(1)\n",
    "        df['i'] = df.index\n",
    "        mini_df = df[['perturbed_text', 'model_name', 'i']]\n",
    "        \n",
    "        if adv_df is None:\n",
    "            adv_df = mini_df\n",
    "        else:\n",
    "            adv_df = pd.concat((adv_df, mini_df), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "766d580e-25bb-4e07-9144-52878e23a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_val_dataset = dm.test_dataset[:1000]\n",
    "ner_df = pd.DataFrame(\n",
    "    columns=['perturbed_text'],\n",
    "    data=mini_val_dataset['document_redact_ner_bert']\n",
    ")\n",
    "ner_df['model_name'] = 'named_entity'\n",
    "ner_df['i'] = ner_df.index\n",
    "       \n",
    "lex_df = pd.DataFrame(\n",
    "    columns=['perturbed_text'],\n",
    "    data=mini_val_dataset['document_redact_lexical']\n",
    ")\n",
    "lex_df['model_name'] = 'lexical'\n",
    "lex_df['i'] = lex_df.index\n",
    "\n",
    "baseline_df = pd.concat((lex_df, ner_df), axis=0)\n",
    "# baseline_df = pd.concat((lex_df, ), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8cfd5b3-b35d-4eb5-bc98-71ceb0f4cb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_3_1                 1000\n",
       "model_3_2                 1000\n",
       "model_3_2__idf            1000\n",
       "model_3_3__placeholder    1000\n",
       "model_3_4                 1000\n",
       "model_3_4__idf            1000\n",
       "lexical                   1000\n",
       "named_entity              1000\n",
       "Name: model_name, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df = pd.concat((adv_df, baseline_df), axis=0)\n",
    "full_df['model_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6295dabd-0f82-4b37-aef8-b917b7c9c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line puts newlines back\n",
    "full_df['perturbed_text'] = full_df['perturbed_text'].apply(lambda s: s.replace('<SPLIT>', '\\n'))\n",
    "\n",
    "# this line replaces BERT-style masks (from PMLM) with roberta-style ones, so we can\n",
    "# count them in a single command\n",
    "full_df['perturbed_text'] = full_df['perturbed_text'].apply(lambda s: s.replace('[MASK]', '<mask>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1531e276-496e-419c-b29d-cd38039e34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def truncate_text(text: str, max_length=128) -> str:\n",
    "    input_ids = tokenizer(text, truncation=True, max_length=128)['input_ids']\n",
    "    reconstructed_text = (\n",
    "        tokenizer\n",
    "            .decode(input_ids)\n",
    "            .replace('<mask>', ' <mask> ')\n",
    "            .replace('  <mask>', ' <mask>')\n",
    "            .replace('<mask>  ', '<mask> ')\n",
    "            .replace('<s>', '')\n",
    "            .replace('</s>', '')\n",
    "            .strip()\n",
    "    )\n",
    "    return reconstructed_text\n",
    "\n",
    "full_df['perturbed_text_truncated'] = full_df['perturbed_text'].apply(truncate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "544c8d67-c6a1-4778-b147-1127e9cb738d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "lexical                   0.282113\n",
       "model_3_1                 0.089857\n",
       "model_3_2                 0.148340\n",
       "model_3_2__idf            0.142445\n",
       "model_3_3__placeholder    0.164442\n",
       "model_3_4                 0.125632\n",
       "model_3_4__idf            0.119776\n",
       "named_entity              0.245707\n",
       "Name: percent_masks, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_percent_masks(s):\n",
    "    return s.count('<mask>') / len(s.split(' '))\n",
    "\n",
    "full_df['percent_masks'] = full_df.apply(lambda s: count_percent_masks(s['perturbed_text_truncated']), axis=1)\n",
    "full_df.groupby('model_name').mean()['percent_masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db7f15e3-e0b6-45bd-959b-f903086d3d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "lexical                   15.465\n",
       "model_3_1                  4.410\n",
       "model_3_2                  8.546\n",
       "model_3_2__idf             7.044\n",
       "model_3_3__placeholder     8.944\n",
       "model_3_4                  5.736\n",
       "model_3_4__idf             5.240\n",
       "named_entity              14.738\n",
       "Name: num_masks, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_masks(s):\n",
    "    return s.count('<mask>')\n",
    "\n",
    "full_df['num_masks'] = full_df.apply(lambda s: count_masks(s['perturbed_text_truncated']), axis=1)\n",
    "full_df.groupby('model_name').mean()['num_masks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39bfaebc-1cfa-45be-9155-5147b5d4c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "lexical                   0.150269\n",
       "model_3_1                 0.047802\n",
       "model_3_2                 0.092045\n",
       "model_3_2__idf            0.065432\n",
       "model_3_3__placeholder    0.092021\n",
       "model_3_4                 0.070358\n",
       "model_3_4__idf            0.051691\n",
       "named_entity              0.207786\n",
       "dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zlib\n",
    "\n",
    "original_text_truncated = [truncate_text(d) for d in mini_val_dataset['document']]\n",
    "\n",
    "def count_compressed_bytes(s: str) -> int:\n",
    "    return len(zlib.compress(s.encode()))\n",
    "\n",
    "original_total_bytes = count_compressed_bytes('\\n'.join(original_text_truncated))\n",
    "\n",
    "1 - full_df.groupby('model_name').apply(lambda s: count_compressed_bytes('\\n'.join(s['perturbed_text_truncated']))) / original_total_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d95616e6-b6cc-4a21-aa0f-c87518dc9479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>model_name</th>\n",
       "      <th>i</th>\n",
       "      <th>perturbed_text_truncated</th>\n",
       "      <th>percent_masks</th>\n",
       "      <th>num_masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; joseph `` &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt; -- ...</td>\n",
       "      <td>model_3_1</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; joseph `` &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt; -- ...</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt;...</td>\n",
       "      <td>model_3_2</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt;...</td>\n",
       "      <td>0.076087</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( 1913 -...</td>\n",
       "      <td>model_3_2__idf</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( 1913 -...</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt;...</td>\n",
       "      <td>model_3_3__placeholder</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt;...</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( 1913 -...</td>\n",
       "      <td>model_3_4</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; &lt;mask&gt; &lt;mask&gt; '' &lt;mask&gt; ( 1913 -...</td>\n",
       "      <td>0.091837</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; joseph &lt;mask&gt; bus '' &lt;mask&gt; ( &lt;mask&gt; --...</td>\n",
       "      <td>model_3_4__idf</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; joseph &lt;mask&gt; bus '' &lt;mask&gt; ( &lt;mask&gt; --...</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; `` &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt; -- ...</td>\n",
       "      <td>lexical</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; `` &lt;mask&gt; '' &lt;mask&gt; ( &lt;mask&gt; -- ...</td>\n",
       "      <td>0.092784</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; `` &lt;mask&gt; '' &lt;mask&gt; ( 1913 -- se...</td>\n",
       "      <td>named_entity</td>\n",
       "      <td>999</td>\n",
       "      <td>&lt;mask&gt; &lt;mask&gt; `` &lt;mask&gt; '' &lt;mask&gt; ( 1913 -- se...</td>\n",
       "      <td>0.177083</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        perturbed_text  \\\n",
       "999  <mask> joseph `` <mask> '' <mask> ( <mask> -- ...   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( <mask>...   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( 1913 -...   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( <mask>...   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( 1913 -...   \n",
       "999  <mask> joseph <mask> bus '' <mask> ( <mask> --...   \n",
       "999  <mask> <mask> `` <mask> '' <mask> ( <mask> -- ...   \n",
       "999  <mask> <mask> `` <mask> '' <mask> ( 1913 -- se...   \n",
       "\n",
       "                 model_name    i  \\\n",
       "999               model_3_1  999   \n",
       "999               model_3_2  999   \n",
       "999          model_3_2__idf  999   \n",
       "999  model_3_3__placeholder  999   \n",
       "999               model_3_4  999   \n",
       "999          model_3_4__idf  999   \n",
       "999                 lexical  999   \n",
       "999            named_entity  999   \n",
       "\n",
       "                              perturbed_text_truncated  percent_masks  \\\n",
       "999  <mask> joseph `` <mask> '' <mask> ( <mask> -- ...       0.054348   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( <mask>...       0.076087   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( 1913 -...       0.093750   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( <mask>...       0.154639   \n",
       "999  <mask> <mask> <mask> <mask> '' <mask> ( 1913 -...       0.091837   \n",
       "999  <mask> joseph <mask> bus '' <mask> ( <mask> --...       0.054348   \n",
       "999  <mask> <mask> `` <mask> '' <mask> ( <mask> -- ...       0.092784   \n",
       "999  <mask> <mask> `` <mask> '' <mask> ( 1913 -- se...       0.177083   \n",
       "\n",
       "     num_masks  \n",
       "999          5  \n",
       "999          7  \n",
       "999          9  \n",
       "999         15  \n",
       "999          9  \n",
       "999          5  \n",
       "999          9  \n",
       "999         17  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df[full_df['i'] == 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ba350-9384-469b-afd6-ff8d5e049f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['bm25_test_guess_result_index'] = full_df.apply(lambda row: index_of_doc_id_in_results_list(row['perturbed_text_truncated'], row['i']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df768b5d-ab73-47a2-869e-d369ce74a887",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df[full_df['bm25_test_guess_result_index'] == -1] = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467cfa74-f9fc-404b-b4f5-728c17e0ba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['bm25_was_correct'] = (full_df['bm25_test_guess_result_index'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d1d46dc-1443-4f9a-a6ce-a0e771e20165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_name\n",
       "lexical                   0.000\n",
       "model_3_1                 0.138\n",
       "model_3_2                 0.043\n",
       "model_3_2__idf            0.045\n",
       "model_3_3__placeholder    0.036\n",
       "model_3_4                 0.067\n",
       "model_3_4__idf            0.117\n",
       "named_entity              0.001\n",
       "Name: bm25_was_correct, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby('model_name')['bm25_was_correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40d03743-f207-4fba-bec7-d9a556a98087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>percent_masks</th>\n",
       "      <th>num_masks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lexical</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.282113</td>\n",
       "      <td>15.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_1</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.089857</td>\n",
       "      <td>4.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_2</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.148340</td>\n",
       "      <td>8.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_2__idf</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.142445</td>\n",
       "      <td>7.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_3__placeholder</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.164442</td>\n",
       "      <td>8.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_4</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.125632</td>\n",
       "      <td>5.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3_4__idf</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.119776</td>\n",
       "      <td>5.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>named_entity</th>\n",
       "      <td>499.5</td>\n",
       "      <td>0.245707</td>\n",
       "      <td>14.738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            i  percent_masks  num_masks\n",
       "model_name                                             \n",
       "lexical                 499.5       0.282113     15.465\n",
       "model_3_1               499.5       0.089857      4.410\n",
       "model_3_2               499.5       0.148340      8.546\n",
       "model_3_2__idf          499.5       0.142445      7.044\n",
       "model_3_3__placeholder  499.5       0.164442      8.944\n",
       "model_3_4               499.5       0.125632      5.736\n",
       "model_3_4__idf          499.5       0.119776      5.240\n",
       "named_entity            499.5       0.245707     14.738"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.groupby('model_name').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c74e0d0-4cfb-4134-aa9e-eb805cd6c4b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
