{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54dd8d98-0748-478b-8c82-6b77cfa44e53",
   "metadata": {},
   "source": [
    "# Gradient-based word deletion\n",
    "\n",
    "Trained **new** new models that are much better than the previous. They're still training, and hopefully will continue to get better, but I want to test them now to see how they do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d252cb9-4ee5-42f2-98df-af6e72555090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e41ec84-b066-4b49-a8ff-33b7e2f90f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: set num_workers to 1, expect dataloader bottleneck\n",
      "Initializing WikipediaDataModule with num_workers = 1 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:1024]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split val[:20%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-793b771e10f80bbe.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7d07543b6205ca87.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-7440752484ad8676.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-2c6f94b0d2dcc153.arrow\n"
     ]
    }
   ],
   "source": [
    "from dataloader import WikipediaDataModule\n",
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    document_model_name_or_path=\"roberta-base\",\n",
    "    profile_model_name_or_path=\"google/tapas-base\",\n",
    "    max_seq_length=128,\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:1024]', # not used in this notebook\n",
    "    dataset_val_split='val[:20%]',\n",
    "    dataset_version='1.2.0',\n",
    "    word_dropout_ratio=0.0,\n",
    "    word_dropout_perc=0.0,\n",
    "    num_workers=1,\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a87966-0c59-45f7-8502-5e7da6710a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized model with learning_rate = 1e-05 and patience 1\n"
     ]
    }
   ],
   "source": [
    "from model import CoordinateAscentModel\n",
    "\n",
    "# model that was trained at the link given above, gets >99% validation accuracy,\n",
    "# and is trained with word dropout!\n",
    "# checkpoint_path = \"/home/jxm3/research/deidentification/unsupervised-deidentification/saves/ca__roberta__tapas__adv/deid-wikibio-2_default/236desyb_444/checkpoints/epoch=5-step=27317.ckpt\"\n",
    "checkpoint_path = \"/home/jxm3/research/deidentification/unsupervised-deidentification/saves/ca__roberta__tapas__adv/deid-wikibio-2_default/2kyfzwx7_433/checkpoints/epoch=19-step=91059.ckpt\"\n",
    "\n",
    "\n",
    "model = CoordinateAscentModel.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    document_model_name_or_path=\"roberta-base\",\n",
    "    profile_model_name_or_path=\"google/tapas-base\",\n",
    "    learning_rate=1e-5,\n",
    "    pretrained_profile_encoder=False,\n",
    "    lr_scheduler_factor=0.5,\n",
    "    lr_scheduler_patience=1,\n",
    "    train_batch_size=1,\n",
    "    num_workers=1,\n",
    "    gradient_clip_val=10.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1079e-107e-4da5-ac2b-9b941d1f0eda",
   "metadata": {},
   "source": [
    "## 2. Define attack in TextAttack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "996b9503-11dd-4378-bc97-794e195448be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textattack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9137c22-612e-44c4-8557-42dcdabd8fd5",
   "metadata": {},
   "source": [
    "### (a) Beam search + replace with `[MASK]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee1838b-420d-4fc0-a849-45afcf3f1b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<AttackedText \"<mask> my name is Jack\">,\n",
       " <AttackedText \"Hello <mask> name is Jack\">,\n",
       " <AttackedText \"Hello my <mask> is Jack\">,\n",
       " <AttackedText \"Hello my name <mask> Jack\">,\n",
       " <AttackedText \"Hello my name is <mask>\">]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WordSwapSingleWord(textattack.transformations.word_swap.WordSwap):\n",
    "    \"\"\"Takes a sentence and transforms it by replacing with a single fixed word.\n",
    "    \"\"\"\n",
    "    single_word: str\n",
    "    def __init__(self, single_word: str = \"?\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.single_word = single_word\n",
    "\n",
    "    def _get_replacement_words(self, _word: str):\n",
    "        return [self.single_word]\n",
    "\n",
    "transformation = WordSwapSingleWord(single_word=dm.document_tokenizer.mask_token)\n",
    "transformation(textattack.shared.AttackedText(\"Hello my name is Jack\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d1de22-75f2-4049-8cf8-6023ddf4403d",
   "metadata": {},
   "source": [
    "### (b) \"Attack success\" as fullfilment of the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d259f78c-2ece-4727-87e6-b7cb714e5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "\n",
    "class ChangeClassificationToBelowTopKClasses(textattack.goal_functions.ClassificationGoalFunction):\n",
    "    k: int\n",
    "    def __init__(self, *args, k: int = 1, **kwargs):\n",
    "        self.k = k\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _is_goal_complete(self, model_output, _):\n",
    "        original_class_score = model_output[self.ground_truth_output]\n",
    "        num_better_classes = (model_output > original_class_score).sum()\n",
    "        return num_better_classes >= self.k\n",
    "\n",
    "    def _get_score(self, model_output, _):\n",
    "        return 1 - model_output[self.ground_truth_output]\n",
    "    \n",
    "    \n",
    "    \"\"\"have to reimplement the following method to change the precision on the sum-to-one condition.\"\"\"\n",
    "    def _process_model_outputs(self, inputs, scores):\n",
    "        \"\"\"Processes and validates a list of model outputs.\n",
    "        This is a task-dependent operation. For example, classification\n",
    "        outputs need to have a softmax applied.\n",
    "        \"\"\"\n",
    "        # Automatically cast a list or ndarray of predictions to a tensor.\n",
    "        if isinstance(scores, list):\n",
    "            scores = torch.tensor(scores)\n",
    "\n",
    "        # Ensure the returned value is now a tensor.\n",
    "        if not isinstance(scores, torch.Tensor):\n",
    "            raise TypeError(\n",
    "                \"Must have list, np.ndarray, or torch.Tensor of \"\n",
    "                f\"scores. Got type {type(scores)}\"\n",
    "            )\n",
    "\n",
    "        # Validation check on model score dimensions\n",
    "        if scores.ndim == 1:\n",
    "            # Unsqueeze prediction, if it's been squeezed by the model.\n",
    "            if len(inputs) == 1:\n",
    "                scores = scores.unsqueeze(dim=0)\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "                )\n",
    "        elif scores.ndim != 2:\n",
    "            # If model somehow returns too may dimensions, throw an error.\n",
    "            raise ValueError(\n",
    "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "            )\n",
    "        elif scores.shape[0] != len(inputs):\n",
    "            # If model returns an incorrect number of scores, throw an error.\n",
    "            raise ValueError(\n",
    "                f\"Model return score of shape {scores.shape} for {len(inputs)} inputs.\"\n",
    "            )\n",
    "        elif not ((scores.sum(dim=1) - 1).abs() < 1e-4).all():\n",
    "            # Values in each row should sum up to 1. The model should return a\n",
    "            # set of numbers corresponding to probabilities, which should add\n",
    "            # up to 1. Since they are `torch.float` values, allow a small\n",
    "            # error in the summation.\n",
    "            scores = torch.nn.functional.softmax(scores, dim=1)\n",
    "            if not ((scores.sum(dim=1) - 1).abs() < 1e-4).all():\n",
    "                raise ValueError(\"Model scores do not add up to 1.\")\n",
    "        return scores.cpu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4405c-876a-4246-b33d-dbdfc80cd85c",
   "metadata": {},
   "source": [
    "## (c) Model wrapper that computes similarities of input documents with validation profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86315cd9-1f98-4c8a-b877-5cc6c015d886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              1.44it/s]\r"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "def precompute_profile_embeddings():\n",
    "    model.profile_model.cuda()\n",
    "    model.profile_model.eval()\n",
    "\n",
    "    model.val_profile_embeddings = np.zeros((len(dm.val_dataset), model.profile_embedding_dim))\n",
    "    for val_batch in tqdm.tqdm(dm.val_dataloader()[0], desc=\"Precomputing val embeddings\", colour=\"green\", leave=False):\n",
    "        with torch.no_grad():\n",
    "            profile_embeddings = model.forward_profile(batch=val_batch)\n",
    "        model.val_profile_embeddings[val_batch[\"text_key_id\"]] = profile_embeddings.cpu()\n",
    "    model.val_profile_embeddings = torch.tensor(model.val_profile_embeddings, dtype=torch.float32)\n",
    "    model.profile_model.train()\n",
    "\n",
    "precompute_profile_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd35ad75-a681-4168-87b8-efee22ea41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from model.model import Model\n",
    "\n",
    "class MyModelWrapper(textattack.models.wrappers.ModelWrapper):\n",
    "    model: Model\n",
    "    tokenizer: transformers.AutoTokenizer\n",
    "    profile_embeddings: torch.Tensor\n",
    "    max_seq_length: int\n",
    "    \n",
    "    def __init__(self, model: Model, tokenizer: transformers.AutoTokenizer, max_seq_length: int = 128):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.profile_embeddings = torch.tensor(model.val_profile_embeddings)\n",
    "        self.max_seq_length = max_seq_length\n",
    "                 \n",
    "    def to(self, device):\n",
    "        self.model.to(device)\n",
    "        self.profile_embeddings.to(device)\n",
    "        return self # so semantics `model = MyModelWrapper().to('cuda')` works properly\n",
    "\n",
    "    def __call__(self, text_input_list: List[str], batch_size=32):\n",
    "        model_device = next(self.model.parameters()).device\n",
    "        \n",
    "        doc_tokenized = self.tokenizer.batch_encode_plus(\n",
    "            text_input_list,\n",
    "            max_length=self.max_seq_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        doc_tokenized = {f'document__{k}': v for k,v in doc_tokenized.items()}\n",
    "        with torch.no_grad():\n",
    "            document_embeddings = self.model.forward_document(batch=doc_tokenized, document_type='document')\n",
    "            document_to_profile_logits = document_embeddings @ self.profile_embeddings.T.to(model_device)\n",
    "            document_to_profile_probs = torch.nn.functional.softmax(\n",
    "                document_to_profile_logits, dim=-1\n",
    "            )\n",
    "        assert document_to_profile_probs.shape == (len(text_input_list), len(self.profile_embeddings))\n",
    "        return document_to_profile_probs\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeee781-ae57-47c4-8679-52014830cc7e",
   "metadata": {},
   "source": [
    "## (d) Dataset that loads Wikipedia documents with names as labels\n",
    "\n",
    "Oh, and it filters out examples that are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35ca719-fdad-45ee-b979-9c2a67d58c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import datasets\n",
    "\n",
    "class WikiDataset(textattack.datasets.Dataset):\n",
    "    dataset: datasets.Dataset\n",
    "    \n",
    "    def __init__(self, dm: WikipediaDataModule):\n",
    "        self.shuffled = True\n",
    "        self.dataset = [ex for ex in dm.val_dataset]\n",
    "        self.label_names = list(dm.val_dataset['name'])\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, i: int) -> Tuple[OrderedDict, int]:\n",
    "        input_dict = OrderedDict([\n",
    "            ('document', self.dataset[i]['document'])\n",
    "        ])\n",
    "        return input_dict, self.dataset[i]['text_key_id']\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abde44f-912e-4f31-8abd-8706ce99bbc6",
   "metadata": {},
   "source": [
    "## 3. Run attack once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ebcc6fb-26ac-44dd-b5c9-84ca92cbfa61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.loggers import CSVLogger\n",
    "from textattack.shared import AttackedText\n",
    "\n",
    "import pandas as pd\n",
    "class CustomCSVLogger(CSVLogger):\n",
    "    \"\"\"Logs attack results to a CSV.\"\"\"\n",
    "\n",
    "    def log_attack_result(self, result: textattack.goal_function_results.ClassificationGoalFunctionResult):\n",
    "        # TODO print like 'mask1', 'mask2',\n",
    "        original_text, perturbed_text = result.diff_color(self.color_method)\n",
    "        original_text = original_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
    "        perturbed_text = perturbed_text.replace(\"\\n\", AttackedText.SPLIT_TOKEN)\n",
    "        result_type = result.__class__.__name__.replace(\"AttackResult\", \"\")\n",
    "        row = {\n",
    "            \"original_person\": result.original_result._processed_output[0],\n",
    "            \"original_text\": original_text,\n",
    "            \"perturbed_person\": result.perturbed_result._processed_output[0],\n",
    "            \"perturbed_text\": perturbed_text,\n",
    "            \"original_score\": result.original_result.score,\n",
    "            \"perturbed_score\": result.perturbed_result.score,\n",
    "            \"original_output\": result.original_result.output,\n",
    "            \"perturbed_output\": result.perturbed_result.output,\n",
    "            \"ground_truth_output\": result.original_result.ground_truth_output,\n",
    "            \"num_queries\": result.num_queries,\n",
    "            \"result_type\": result_type,\n",
    "        }\n",
    "        self.df = pd.concat([self.df, pd.DataFrame([row])], ignore_index=True)\n",
    "        self._flushed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f77f286-3f48-44b5-b341-35582807ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxNumWordsModified(textattack.constraints.PreTransformationConstraint):\n",
    "    def __init__(self, max_num_words: int):\n",
    "        self.max_num_words = max_num_words\n",
    "\n",
    "    def _get_modifiable_indices(self, current_text):\n",
    "        \"\"\"Returns the word indices in current_text which are able to be\n",
    "        modified.\"\"\"\n",
    "\n",
    "        if len(current_text.attack_attrs[\"modified_indices\"]) >= self.max_num_words:\n",
    "            return set()\n",
    "        else:\n",
    "            return set(range(len(current_text.words)))\n",
    "\n",
    "    def extra_repr_keys(self):\n",
    "        return [\"max_num_words\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a421b8a-9a20-47dd-93ae-2527bca28109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-1c87bb4263f0>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.profile_embeddings = torch.tensor(model.val_profile_embeddings)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MyModelWrapper at 0x7faa817a9400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper = MyModelWrapper(model=model, tokenizer=dm.document_tokenizer)\n",
    "model_wrapper.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39658538-0f2b-41b3-81d2-c2da2b294edb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdataset\u001b[49m[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m doc_test \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m pred_idx \u001b[38;5;241m=\u001b[39m model_wrapper([doc_test])\u001b[38;5;241m.\u001b[39margmax()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(dataset[2][0]['document'])\n",
    "doc_test = dataset[2][0]['document']\n",
    "\n",
    "pred_idx = model_wrapper([doc_test]).argmax()\n",
    "dataset[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd29e545-f4b0-4863-a5be-f8a400f8c396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_wrapper.max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3cbe2f6-609c-41be-9dbc-d33217451223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "textattack: No entry found for goal function <class '__main__.ChangeClassificationToBelowTopKClasses'>.\n",
      "textattack: Unknown if model of class <class 'model.coordinate_ascent.CoordinateAscentModel'> compatible with goal function <class '__main__.ChangeClassificationToBelowTopKClasses'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack(\n",
      "  (search_method): BeamSearch(\n",
      "    (beam_width):  4\n",
      "  )\n",
      "  (goal_function):  ChangeClassificationToBelowTopKClasses\n",
      "  (transformation):  WordSwapSingleWord\n",
      "  (constraints): \n",
      "    (0): RepeatModification\n",
      "    (1): MaxNumWordsModified(\n",
      "        (max_num_words):  50\n",
      "      )\n",
      "  (is_black_box):  True\n",
      ") \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 1/15 [00:07<01:50,  7.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:   7%|▋         | 1/15 [00:07<01:50,  7.87s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 0 / 0 / 1:  13%|█▎        | 2/15 [00:08<00:53,  4.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  13%|█▎        | 2/15 [00:08<00:53,  4.13s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 2 / 0 / 0 / 2:  20%|██        | 3/15 [00:10<00:41,  3.43s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  20%|██        | 3/15 [00:10<00:41,  3.44s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 3 / 0 / 0 / 3:  27%|██▋       | 4/15 [00:12<00:33,  3.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  27%|██▋       | 4/15 [00:12<00:33,  3.01s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 4 / 0 / 0 / 4:  33%|███▎      | 5/15 [00:14<00:28,  2.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  33%|███▎      | 5/15 [00:14<00:28,  2.86s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 5 / 0 / 0 / 5:  40%|████      | 6/15 [00:15<00:23,  2.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 6 / 0 / 0 / 6:  40%|████      | 6/15 [00:15<00:23,  2.59s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 6 / 0 / 0 / 6:  47%|████▋     | 7/15 [00:32<00:37,  4.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 7 / 0 / 0 / 7:  47%|████▋     | 7/15 [00:32<00:37,  4.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 7 / 0 / 0 / 7:  53%|█████▎    | 8/15 [00:34<00:30,  4.30s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 1 / 21 / 0 / 22:  11%|█         | 22/200 [01:47<14:29,  4.88s/it][A\n",
      "\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 8 / 0 / 0 / 8:  60%|██████    | 9/15 [00:40<00:26,  4.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 9 / 0 / 0 / 9:  60%|██████    | 9/15 [00:40<00:26,  4.48s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 9 / 0 / 0 / 9:  67%|██████▋   | 10/15 [00:43<00:21,  4.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 10 / 0 / 0 / 10:  67%|██████▋   | 10/15 [00:43<00:21,  4.38s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 10 / 0 / 0 / 10:  73%|███████▎  | 11/15 [00:45<00:16,  4.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 11 / 0 / 0 / 11:  73%|███████▎  | 11/15 [00:45<00:16,  4.10s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 11 / 0 / 0 / 11:  80%|████████  | 12/15 [01:07<00:16,  5.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 12 / 0 / 0 / 12:  80%|████████  | 12/15 [01:07<00:16,  5.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 12 / 0 / 0 / 12:  87%|████████▋ | 13/15 [01:30<00:13,  6.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 13 / 0 / 0 / 13:  87%|████████▋ | 13/15 [01:30<00:13,  6.93s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 13 / 0 / 0 / 13:  93%|█████████▎| 14/15 [01:33<00:06,  6.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 14 / 0 / 0 / 14:  93%|█████████▎| 14/15 [01:33<00:06,  6.67s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 14 / 0 / 0 / 14: 100%|██████████| 15/15 [01:53<00:00,  7.58s/it]\u001b[A\u001b[A\n",
      "\n",
      "[Succeeded / Failed / Skipped / Total] 15 / 0 / 0 / 15: 100%|██████████| 15/15 [01:53<00:00,  7.58s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+-------------------------------+--------+\n",
      "| Attack Results                |        |\n",
      "+-------------------------------+--------+\n",
      "| Number of successful attacks: | 15     |\n",
      "| Number of failed attacks:     | 0      |\n",
      "| Number of skipped attacks:    | 0      |\n",
      "| Original accuracy:            | 100.0% |\n",
      "| Accuracy under attack:        | 0.0%   |\n",
      "| Attack success rate:          | 100.0% |\n",
      "| Average perturbed word %:     | 22.31% |\n",
      "| Average num. words per input: | 51.93  |\n",
      "| Avg num queries:              | 1534.8 |\n",
      "+-------------------------------+--------+"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "textattack: Logging to CSV at path results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_person</th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_person</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael iii of alexandria</td>\n",
       "      <td>pope <font color = red>michael</font> <font color = red>iii</font> <font color = red>of</font> alexandria (also known as <font color = red>khail</font> <font color = red>iii</font>) was the coptic pope of alexandria and patriarch of <font color = red>the</font> see of st. mark (880 -- <font color = red>907</font>) .<SPLIT>in 882 , the governor of egypt , ahmad ibn tulun , forced khail to pay heavy contributions , forcing him to sell a church and some attached properties to the local jewish community .<SPLIT>this building was at one time believed to have later become the site of the cairo geniza .<SPLIT></td>\n",
       "      <td>Roy godfrey</td>\n",
       "      <td>pope <<font color = gray>mask</font>> <<font color = gray>mask</font>> <<font color = gray>mask</font>> alexandria (also known as <<font color = gray>mask</font>> <<font color = gray>mask</font>>) was the coptic pope of alexandria and patriarch of <<font color = gray>mask</font>> see of st. mark (880 -- <<font color = gray>mask</font>>) .<SPLIT>in 882 , the governor of egypt , ahmad ibn tulun , forced khail to pay heavy contributions , forcing him to sell a church and some attached properties to the local jewish community .<SPLIT>this building was at one time believed to have later become the site of the cairo geniza .<SPLIT></td>\n",
       "      <td>0.030294</td>\n",
       "      <td>0.979676</td>\n",
       "      <td>0</td>\n",
       "      <td>8198</td>\n",
       "      <td>0</td>\n",
       "      <td>1742</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hui jun</td>\n",
       "      <td><font color = green>hui</font> <font color = green>jun</font> is a male former <font color = green>table</font> tennis player from china .<SPLIT></td>\n",
       "      <td>Liu xiaolong</td>\n",
       "      <td><<font color = gray>mask</font>> <<font color = gray>mask</font>> is a male former <<font color = gray>mask</font>> tennis player from china .<SPLIT></td>\n",
       "      <td>0.042970</td>\n",
       "      <td>0.992899</td>\n",
       "      <td>1</td>\n",
       "      <td>10388</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Okan öztürk</td>\n",
       "      <td><font color = blue>okan</font> <font color = blue>Öztürk</font> (born <font color = blue>30</font> <font color = blue>november</font> <font color = blue>1977</font>) is a <font color = blue>turkish</font> professional footballer .<SPLIT>he currently plays as a <font color = blue>striker</font> for yeni <font color = blue>malatyaspor</font> .<SPLIT></td>\n",
       "      <td>Musashi suzuki</td>\n",
       "      <td><<font color = green>mask</font>> <<font color = green>mask</font>> (born <<font color = green>mask</font>> <<font color = green>mask</font>> <<font color = green>mask</font>>) is a <<font color = green>mask</font>> professional footballer .<SPLIT>he currently plays as a <<font color = green>mask</font>> for yeni <<font color = green>mask</font>> .<SPLIT></td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.999179</td>\n",
       "      <td>2</td>\n",
       "      <td>4221</td>\n",
       "      <td>2</td>\n",
       "      <td>469</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marie stephan</td>\n",
       "      <td><font color = purple>marie</font> <font color = purple>stephan</font> , (born <font color = purple>march</font> 14 , <font color = purple>1996</font>) is a professional squash player who represents <font color = purple>france</font> .<SPLIT>she reached a career-high world ranking of world no. 101 in july 2015 .<SPLIT></td>\n",
       "      <td>Cecelia cortes</td>\n",
       "      <td><<font color = gray>mask</font>> <<font color = gray>mask</font>> , (born <<font color = gray>mask</font>> 14 , <<font color = gray>mask</font>>) is a professional squash player who represents <<font color = gray>mask</font>> .<SPLIT>she reached a career-high world ranking of world no. 101 in july 2015 .<SPLIT></td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.966863</td>\n",
       "      <td>3</td>\n",
       "      <td>12998</td>\n",
       "      <td>3</td>\n",
       "      <td>420</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leonard l. martino</td>\n",
       "      <td><font color = yellow>leonard</font> <font color = yellow>l</font>. <font color = yellow>martino</font> is a former <font color = yellow>democratic</font> member of the <font color = yellow>pennsylvania</font> house of representatives .<SPLIT>he was <font color = yellow>born</font> <font color = yellow>in</font> butler to michael and angela pitullio martino .<SPLIT></td>\n",
       "      <td>Andrew ciafardini</td>\n",
       "      <td><<font color = cyan>mask</font>> <<font color = cyan>mask</font>>. <<font color = cyan>mask</font>> is a former <<font color = cyan>mask</font>> member of the <<font color = cyan>mask</font>> house of representatives .<SPLIT>he was <<font color = cyan>mask</font>> <<font color = cyan>mask</font>> butler to michael and angela pitullio martino .<SPLIT></td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.995229</td>\n",
       "      <td>4</td>\n",
       "      <td>1207</td>\n",
       "      <td>4</td>\n",
       "      <td>542</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salome jens</td>\n",
       "      <td><font color = orange>salome</font> <font color = orange>jens</font> (born <font color = orange>may</font> 8 , <font color = orange>1935</font>) is an american stage , film and television actress .<SPLIT>she is perhaps best known for portraying the female changeling on '' '' .<SPLIT></td>\n",
       "      <td>Linda kozlowski</td>\n",
       "      <td><<font color = gray>mask</font>> <<font color = gray>mask</font>> (born <<font color = gray>mask</font>> 8 , <<font color = gray>mask</font>>) is an american stage , film and television actress .<SPLIT>she is perhaps best known for portraying the female changeling on '' '' .<SPLIT></td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.989484</td>\n",
       "      <td>5</td>\n",
       "      <td>9248</td>\n",
       "      <td>5</td>\n",
       "      <td>302</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Carl crawford</td>\n",
       "      <td><font color = pink>carl</font> demonte <font color = pink>crawford</font> (born <font color = pink>august</font> <font color = pink>5</font> , <font color = pink>1981</font>) , <font color = pink>nicknamed</font> `` the perfect storm '' , is an american professional baseball <font color = pink>left</font> <font color = pink>fielder</font> with <font color = pink>the</font> <font color = pink>los</font> <font color = pink>angeles</font> <font color = pink>dodgers</font> of major league baseball (mlb) .<SPLIT>he bats and throws left-handed .<SPLIT><font color = pink>crawford</font> was drafted by the tampa bay devil rays in the second round (52nd overall) of the 1999 major league baseball draft .<SPLIT>he made his major league debut in 2002 .<SPLIT><font color = pink>crawford</font> has more triples (121) than any other active baseball player .<SPLIT></td>\n",
       "      <td>Wade davis</td>\n",
       "      <td><<font color = red>mask</font>> demonte <<font color = red>mask</font>> (born <<font color = red>mask</font>> <<font color = red>mask</font>> , <<font color = red>mask</font>>) , <<font color = red>mask</font>> `` the perfect storm '' , is an american professional baseball <<font color = red>mask</font>> <<font color = red>mask</font>> with <<font color = red>mask</font>> <<font color = red>mask</font>> <<font color = red>mask</font>> <<font color = red>mask</font>> of major league baseball (mlb) .<SPLIT>he bats and throws left-handed .<SPLIT><<font color = red>mask</font>> was drafted by the tampa bay devil rays in the second round (52nd overall) of the 1999 major league baseball draft .<SPLIT>he made his major league debut in 2002 .<SPLIT><<font color = red>mask</font>> has more triples (121) than any other active baseball player .<SPLIT></td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.992993</td>\n",
       "      <td>6</td>\n",
       "      <td>8580</td>\n",
       "      <td>6</td>\n",
       "      <td>3612</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jim bob</td>\n",
       "      <td><font color = cyan>jim</font> <font color = cyan>bob</font> (born <font color = cyan>james</font> neil morrison on 22 november <font color = cyan>1960</font>) is a british musician and author , best known as the singer of indie <font color = cyan>punk</font> band carter usm .<SPLIT></td>\n",
       "      <td>Ronald milner</td>\n",
       "      <td><<font color = purple>mask</font>> <<font color = purple>mask</font>> (born <<font color = purple>mask</font>> neil morrison on 22 november <<font color = purple>mask</font>>) is a british musician and author , best known as the singer of indie <<font color = purple>mask</font>> band carter usm .<SPLIT></td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.991314</td>\n",
       "      <td>7</td>\n",
       "      <td>8263</td>\n",
       "      <td>7</td>\n",
       "      <td>420</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Riddick parker</td>\n",
       "      <td><font color = gray>riddick</font> <font color = gray>parker</font> (born <font color = gray>november</font> <font color = gray>20</font> , <font color = gray>1972</font> in <font color = gray>emporia</font> , <font color = gray>virginia</font>) is a former professional american football <font color = gray>defensive</font> <font color = gray>lineman</font> for the seattle seahawks , san diego chargers , new england patriots , baltimore ravens , and san francisco 49ers of the national football league .<SPLIT></td>\n",
       "      <td>Charles johnson</td>\n",
       "      <td><<font color = green>mask</font>> <<font color = green>mask</font>> (born <<font color = green>mask</font>> <<font color = green>mask</font>> , <<font color = green>mask</font>> in <<font color = green>mask</font>> , <<font color = green>mask</font>>) is a former professional american football <<font color = green>mask</font>> <<font color = green>mask</font>> for the seattle seahawks , san diego chargers , new england patriots , baltimore ravens , and san francisco 49ers of the national football league .<SPLIT></td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.994003</td>\n",
       "      <td>8</td>\n",
       "      <td>1971</td>\n",
       "      <td>8</td>\n",
       "      <td>1111</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blessed osanna of cattaro -lrb- ozana kotorska -rrb-</td>\n",
       "      <td>blessed <font color = brown>osanna</font> <font color = brown>of</font> <font color = brown>cattaro</font> t.o.s.d. -lrb-) was a catholic visionary and anchoress from <font color = brown>cattaro</font> (kotor) .<SPLIT>she was a teenage convert from orthodoxy of serbian descent from montenegro (zeta) .<SPLIT>she became a dominican tertiary and was posthumously venerated as a saint in kotor .<SPLIT>she was later <font color = brown>beatified</font> in 1934 .<SPLIT></td>\n",
       "      <td>Willie mcdonald</td>\n",
       "      <td>blessed <<font color = cyan>mask</font>> <<font color = cyan>mask</font>> <<font color = cyan>mask</font>> t.o.s.d. -lrb-) was a catholic visionary and anchoress from <<font color = cyan>mask</font>> (kotor) .<SPLIT>she was a teenage convert from orthodoxy of serbian descent from montenegro (zeta) .<SPLIT>she became a dominican tertiary and was posthumously venerated as a saint in kotor .<SPLIT>she was later <<font color = cyan>mask</font>> in 1934 .<SPLIT></td>\n",
       "      <td>0.010219</td>\n",
       "      <td>0.978553</td>\n",
       "      <td>9</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>828</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Thaila ayala</td>\n",
       "      <td><font color = red>thaila</font> <font color = red>ayala</font> <font color = red>sales</font> (born <font color = red>april</font> <font color = red>14</font> , <font color = red>1986</font> <font color = red>in</font> presidente prudente) is a brazilian actress and model .<SPLIT></td>\n",
       "      <td>Bia seidl</td>\n",
       "      <td><<font color = yellow>mask</font>> <<font color = yellow>mask</font>> <<font color = yellow>mask</font>> (born <<font color = yellow>mask</font>> <<font color = yellow>mask</font>> , <<font color = yellow>mask</font>> <<font color = yellow>mask</font>> presidente prudente) is a brazilian actress and model .<SPLIT></td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.995378</td>\n",
       "      <td>10</td>\n",
       "      <td>3064</td>\n",
       "      <td>10</td>\n",
       "      <td>317</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sven leuenberger</td>\n",
       "      <td><font color = green>sven</font> <font color = green>leuenberger</font> (born <font color = green>august</font> <font color = green>25</font> , <font color = green>1969</font> in <font color = green>niederuzwil</font> , switzerland) is a <font color = green>retired</font> swiss professional ice hockey <font color = green>defender</font> .<SPLIT>playing in the nla-a , <font color = green>leuenberger</font> accumulated 74 goals , 173 assists , and 443 <font color = green>penalty</font> minutes in the regular season .<SPLIT>since the nla 2006 season , <font color = green>leuenberger</font> has been the general manager (<font color = green>sports</font> director) of the sc bern .<SPLIT>on august 1 , 2008 sc bern 's coach suffered , john van boxmeer , a heart attack side-lining him for a month .<SPLIT>during van boxmeer 's absence , general manager sven leuenberger coached the team along with assistant coach konstantin kurashev -lsb- http://www.iihf.com/home-of-hockey/news/news-singleview/article/van-boxmeer-suffers-heart-attack/leuenberger.html] .<SPLIT></td>\n",
       "      <td>Udo segreff</td>\n",
       "      <td><<font color = blue>mask</font>> <<font color = blue>mask</font>> (born <<font color = blue>mask</font>> <<font color = blue>mask</font>> , <<font color = blue>mask</font>> in <<font color = blue>mask</font>> , switzerland) is a <<font color = blue>mask</font>> swiss professional ice hockey <<font color = blue>mask</font>> .<SPLIT>playing in the nla-a , <<font color = blue>mask</font>> accumulated 74 goals , 173 assists , and 443 <<font color = blue>mask</font>> minutes in the regular season .<SPLIT>since the nla 2006 season , <<font color = blue>mask</font>> has been the general manager (<<font color = blue>mask</font>> director) of the sc bern .<SPLIT>on august 1 , 2008 sc bern 's coach suffered , john van boxmeer , a heart attack side-lining him for a month .<SPLIT>during van boxmeer 's absence , general manager sven leuenberger coached the team along with assistant coach konstantin kurashev -lsb- http://www.iihf.com/home-of-hockey/news/news-singleview/article/van-boxmeer-suffers-heart-attack/leuenberger.html] .<SPLIT></td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.986391</td>\n",
       "      <td>11</td>\n",
       "      <td>2572</td>\n",
       "      <td>11</td>\n",
       "      <td>4327</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Brett scott</td>\n",
       "      <td><font color = blue>brett</font> <font color = blue>scott</font> (born <font color = blue>10</font> <font color = blue>april</font> <font color = blue>1962</font>) is a former australian rules footballer who played with the sydney football club in the victorian football league during the <font color = blue>1980s</font> .<SPLIT><font color = blue>scott</font> played his early football with the rock-yerong <font color = blue>creek</font> before being recruited to south melbourne and making his league debut in <font color = blue>1981</font> .<SPLIT>the following year the club relocated to sydney and he took part in the inaugural game for their new city .<SPLIT>injuries restricted his appearances over the years and when he finished in <font color = blue>1989</font> he had <font color = blue>managed</font> just 59 senior games .<SPLIT>after gary buckenara was sacked as sydney 's coach in 1993 , scott acted as a caretaker coach for two games .<SPLIT></td>\n",
       "      <td>Geof motley</td>\n",
       "      <td><<font color = gray>mask</font>> <<font color = gray>mask</font>> (born <<font color = gray>mask</font>> <<font color = gray>mask</font>> <<font color = gray>mask</font>>) is a former australian rules footballer who played with the sydney football club in the victorian football league during the <<font color = gray>mask</font>> .<SPLIT><<font color = gray>mask</font>> played his early football with the rock-yerong <<font color = gray>mask</font>> before being recruited to south melbourne and making his league debut in <<font color = gray>mask</font>> .<SPLIT>the following year the club relocated to sydney and he took part in the inaugural game for their new city .<SPLIT>injuries restricted his appearances over the years and when he finished in <<font color = gray>mask</font>> he had <<font color = gray>mask</font>> just 59 senior games .<SPLIT>after gary buckenara was sacked as sydney 's coach in 1993 , scott acted as a caretaker coach for two games .<SPLIT></td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.990316</td>\n",
       "      <td>12</td>\n",
       "      <td>558</td>\n",
       "      <td>12</td>\n",
       "      <td>4250</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Marlon evans</td>\n",
       "      <td><font color = purple>marlon</font> <font color = purple>evans</font> (born <font color = purple>3</font> <font color = purple>august</font> <font color = purple>1997</font>) is <font color = purple>a</font> <font color = purple>guamanian</font> <font color = purple>international</font> <font color = purple>footballer</font> who plays for <font color = purple>wings</font> in the <font color = purple>guam</font> men 's <font color = purple>soccer</font> league<SPLIT></td>\n",
       "      <td>Ali karimi</td>\n",
       "      <td><<font color = red>mask</font>> <<font color = red>mask</font>> (born <<font color = red>mask</font>> <<font color = red>mask</font>> <<font color = red>mask</font>>) is <<font color = red>mask</font>> <<font color = red>mask</font>> <<font color = red>mask</font>> <<font color = red>mask</font>> who plays for <<font color = red>mask</font>> in the <<font color = red>mask</font>> men 's <<font color = red>mask</font>> league<SPLIT></td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.997571</td>\n",
       "      <td>13</td>\n",
       "      <td>4560</td>\n",
       "      <td>13</td>\n",
       "      <td>727</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jesper blicher</td>\n",
       "      <td><font color = yellow>jesper</font> <font color = yellow>blicher</font> (born <font color = yellow>4</font> <font color = yellow>october</font> <font color = yellow>1988</font>) is a danish professional football midfielder , who currently plays for danish 1st division side lyngby <font color = yellow>boldklub</font> .<SPLIT><font color = yellow>blicher</font> began playing football in kolt-hasselager if , where he was picked for agf , where he got his other footballing education .<SPLIT>he was part of the year ' 88 , who won in the junior league , like michael lumb , frederik krabbe , michael vester , niels kristensen , morten beck andersen and anders syberg , who all had the onset of agf 's 1 .<SPLIT>hold .<SPLIT>in the autumn of 2009 he was loaned to næstved bk , and just before winter transfer window end he switched permanently to the club .<SPLIT>in 2010 he changed to fc fredericia , where he played until 2012 when he got vendsyssel ff as a new club in january 2015 he was given at his own request that he want to terminated his contract with the vendsyssel ff .<SPLIT>on 6 february 2015 he signed a two-year contract with lyngby boldklub<SPLIT></td>\n",
       "      <td>Nicolai poulsen</td>\n",
       "      <td><<font color = cyan>mask</font>> <<font color = cyan>mask</font>> (born <<font color = cyan>mask</font>> <<font color = cyan>mask</font>> <<font color = cyan>mask</font>>) is a danish professional football midfielder , who currently plays for danish 1st division side lyngby <<font color = cyan>mask</font>> .<SPLIT><<font color = cyan>mask</font>> began playing football in kolt-hasselager if , where he was picked for agf , where he got his other footballing education .<SPLIT>he was part of the year ' 88 , who won in the junior league , like michael lumb , frederik krabbe , michael vester , niels kristensen , morten beck andersen and anders syberg , who all had the onset of agf 's 1 .<SPLIT>hold .<SPLIT>in the autumn of 2009 he was loaned to næstved bk , and just before winter transfer window end he switched permanently to the club .<SPLIT>in 2010 he changed to fc fredericia , where he played until 2012 when he got vendsyssel ff as a new club in january 2015 he was given at his own request that he want to terminated his contract with the vendsyssel ff .<SPLIT>on 6 february 2015 he signed a two-year contract with lyngby boldklub<SPLIT></td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.992980</td>\n",
       "      <td>14</td>\n",
       "      <td>10217</td>\n",
       "      <td>14</td>\n",
       "      <td>3867</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "#  Initialize attack\n",
    "# \n",
    "\n",
    "from textattack import Attack\n",
    "from textattack.constraints.pre_transformation import RepeatModification\n",
    "\n",
    "goal_function = ChangeClassificationToBelowTopKClasses(model_wrapper, k=1)\n",
    "constraints = [RepeatModification(), MaxNumWordsModified(max_num_words=50)]\n",
    "transformation = WordSwapSingleWord(single_word=dm.document_tokenizer.mask_token)\n",
    "search_method = textattack.search_methods.BeamSearch(beam_width=4)\n",
    "\n",
    "attack = Attack(\n",
    "    goal_function, constraints, transformation, search_method\n",
    ")\n",
    "\n",
    "from tqdm import tqdm # tqdm provides us a nice progress bar.\n",
    "from textattack.attack_results import SuccessfulAttackResult\n",
    "from textattack import Attacker\n",
    "from textattack import AttackArgs\n",
    "\n",
    "attack_args = AttackArgs(num_examples=15, disable_stdout=True)\n",
    "dataset = WikiDataset(dm)\n",
    "\n",
    "attacker = Attacker(attack, dataset, attack_args)\n",
    "\n",
    "results_iterable = attacker.attack_dataset()\n",
    "\n",
    "logger = CustomCSVLogger(color_method='html')\n",
    "\n",
    "# \n",
    "# Run attack\n",
    "# \n",
    "from tqdm import tqdm\n",
    "for result in results_iterable:\n",
    "    tqdm._instances.clear() # Doesn't fix the progress bar :-(\n",
    "    logger.log_attack_result(result)\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(logger.df.to_html(escape=False)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
