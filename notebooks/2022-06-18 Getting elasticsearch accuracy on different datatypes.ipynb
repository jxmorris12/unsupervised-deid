{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44162e52-42eb-41df-8037-27316a8577d0",
   "metadata": {},
   "source": [
    "# Evaluating ElasticSearch BM-25 top-k accuracy documents & baseline-redacted documents\n",
    "\n",
    "First, we need to connect to ElasticSearch and add all the profiles (as strings) to indexes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aba53b8-3e23-4c8a-9030-17c019088301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.9/site-packages/elasticsearch/connection/http_urllib3.py:209: UserWarning: Connecting to https://rush-compute-01.tech.cornell.edu:9200 using SSL with verify_certs=False is insecure.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "username = \"elastic\"\n",
    "password = \"FjZD_LI-=AJOtsfpq9U*\"\n",
    "\n",
    "url = f\"https://elastic:{password}@rush-compute-01.tech.cornell.edu:9200\"\n",
    "\n",
    "es = Elasticsearch(\n",
    "    url,\n",
    "    # use_ssl = True,\n",
    "    # ca_certs=False,\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1eeae46e-7f61-4379-a252-d95e8809e45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Elasticsearch([{'host': 'rush-compute-01.tech.cornell.edu', 'port': 9200, 'use_ssl': True, 'http_auth': 'elastic:FjZD_LI-=AJOtsfpq9U*'}])>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "809b97eb-b05a-46b6-b189-11374d07093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete an existing index\n",
    "# es.indices.delete(index='val_5_profile_str', ignore=[400, 404])\n",
    "# for idx in [idx for idx in es.indices.get_alias().keys() if not idx.startswith('.')]:\n",
    "#     print('deleting', idx)\n",
    "#     es.indices.delete(index=idx, ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d784a03a-5a8a-422b-bf79-787beaf43f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "from elasticsearch import helpers\n",
    "from elasticsearch_dsl import Index\n",
    "\n",
    "\n",
    "def create_index_from_profiles(index_name: str, dataset_split: str, b: float = 0.9, k1: float = 4.5):\n",
    "    index = Index(index_name, es)\n",
    "    index.settings(\n",
    "        number_of_shards=1, # need one shard since scores are calculated with a single shard!\n",
    "        number_of_replicas=2,\n",
    "        index={\n",
    "            'mapping': {\n",
    "                'ignore_malformed': True,\n",
    "                'total_fields.limit': 20_000\n",
    "            },\n",
    "            \"similarity\" : {\n",
    "              \"default\" : {\n",
    "                \"type\" : \"BM25\",\n",
    "                \"b\": b,\n",
    "                \"k1\": k1\n",
    "              }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    index.create()\n",
    "    \n",
    "\n",
    "    dataset = datasets.load_dataset('wiki_bio', split=dataset_split, version='1.2.0')\n",
    "\n",
    "    def make_prof_table(prof):\n",
    "        table = prof['input_text']['table']\n",
    "        prof_dict = dict(zip(table['column_header'], table['content']))\n",
    "        prof_dict = { k.strip().strip('.|<>'): v.strip().strip('.|<>') for k,v in prof_dict.items() }\n",
    "        if 'no.of.children' in prof_dict:\n",
    "            # fix for one weird error\n",
    "            prof_dict['no of children'] = prof_dict['no.of.children']\n",
    "            del prof_dict['no.of.children']\n",
    "        prof_dict = {k: v for k,v in prof_dict.items() if (len(k) and len(v))}\n",
    "        prof_str = ''\n",
    "        for k,v in prof_dict.items():\n",
    "            prof_str += f'{k} : {v}'\n",
    "            prof_str += '\\n'\n",
    "        return prof_str\n",
    "\n",
    "    prof_data = [make_prof_table(prof) for prof in dataset]\n",
    "\n",
    "    print('inserting', len(prof_data), 'profiles')\n",
    "\n",
    "    prof_data_json = [{'_id': idx, 'body': { 'profile': profile_str, 'id': idx }} for idx, profile_str in enumerate(prof_data)]\n",
    "    return helpers.bulk(es, prof_data_json, index=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a69ea09-1780-4c76-bd11-35af6731b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_index_from_profiles('val_100_profile_str', 'val[:100%]')\n",
    "# create_index_from_profiles('test_100_profile_str', 'test[:100%]')\n",
    "# create_index_from_profiles('train_100_profile_str', 'train[:100%]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4cf1e-4b18-492e-aed7-7b079019d91e",
   "metadata": {},
   "source": [
    "Now that the indices are created, we can iterate over documents and compute the top-K accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "671fe92a-470f-4087-9199-b32d4912580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing WikipediaDataModule with num_workers = 8 and mask token `<mask>`\n",
      "loading wiki_bio[1.2.0] split train[:100%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split val[:100%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading wiki_bio[1.2.0] split test[:100%]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset wiki_bio (/home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da)\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_wiki.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_val____100_____1.2.0__roberta-base_wiki.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_test____100_____1.2.0__roberta-base_wiki.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_val____100_____1.2.0__roberta-base_lexical_redacted.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_test____100_____1.2.0__roberta-base_lexical_redacted.arrow\n",
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_val____100_____1.2.0__roberta-base_ner_spacy_redacted.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e05c8783534167afb89e193fb09df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jxm3/.conda/envs/torch/lib/python3.9/site-packages/transformers/pipelines/base.py:997: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84bea73f4f449cfbc8e494d7ec2630c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72831 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ecab27538b4fc7860ea519bc6b3515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72831 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a359117378d4f3aa2870ef1bfd362ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72831 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46710982d70d4f8f8b950d593d11a894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72831 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00000_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00001_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00002_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00003_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00004_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00005_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00006_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jxm3/.cache/huggingface/datasets/wiki_bio/default/1.2.0/c05ce066e9026831cd7535968a311fc80f074b58868cfdffccbc811dff2ab6da/cache-wiki_bio_train____100_____1.2.0__roberta-base_128_google_tapas-base_tokenized_00007_of_00008.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a253412a213c4a29ad383347d5caa771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94723638b45246c99fd7e87f87852b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3862163891404db1f35a1ae158039f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f2c5e9ab88444e8a0b39367eb893c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d3fcff7a944ff9b27f2e7fed887deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fecaf530fbd439381314ba531508ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40520e62b5645b69263046b5f41eb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384a8fb4122e4b108f40657146deb345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/9103 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d326d7fd5024d559f4717e576427997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb71eb958c43469cace56d8e81963953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a0f7930457430083740a38c97f149e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a4e87ddf3684adba2a0526f0f6ab695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fe0eced29745019e13be8f17088076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954adf6975f84dadbed236869e81d78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac1176ca1354df495c38eb1e4ce0410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/9104 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911cae50a8214de68f73a9acaa5b3420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/9103 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jxm3/research/deidentification/unsupervised-deidentification')\n",
    "\n",
    "import os\n",
    "from dataloader import WikipediaDataModule\n",
    "\n",
    "num_cpus = len(os.sched_getaffinity(0))\n",
    "\n",
    "dm = WikipediaDataModule(\n",
    "    document_model_name_or_path = 'roberta-base',\n",
    "    profile_model_name_or_path = 'google/tapas-base',\n",
    "    dataset_name='wiki_bio',\n",
    "    dataset_train_split='train[:100%]',\n",
    "    dataset_val_split='val[:100%]',\n",
    "    dataset_test_split='test[:100%]',\n",
    "    dataset_version='1.2.0',\n",
    "    num_workers=num_cpus,\n",
    "    train_batch_size=256,\n",
    "    eval_batch_size=256,\n",
    "    max_seq_length=128,\n",
    "    sample_spans=False,\n",
    ")\n",
    "dm.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf890c73-f0f1-4c47-864e-557383bed7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "inf\n",
      "0\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_doc(doc: str) -> str:\n",
    "    # limit 500 words\n",
    "    doc = ' '.join(doc.split(' ')[:500])\n",
    "    # fix braces and remove weird characters\n",
    "    doc = doc.replace('-lrb-', '(').replace('-rrb-', ')')\n",
    "    return re.sub(r'[^\\w|\\s]', ' ',doc)\n",
    "\n",
    "def search_results_for_query_by_index(query: str, index: str, max_hits: int = 10):\n",
    "    # print(query)\n",
    "    search_results = es.search(index=index, q=query, size=max_hits)\n",
    "    num_hits = search_results[\"hits\"][\"total\"][\"value\"]\n",
    "    # print(\"got\", num_hits, \"hits\")\n",
    "    return num_hits, search_results[\"hits\"][\"hits\"]\n",
    "\n",
    "def index_of_doc_id_in_results_list(doc: str, doc_id: int, max_hits=100):\n",
    "    \"\"\"Searches for test doc in all three indices. Returns index of doc in results if found.\"\"\"\n",
    "    _, results = search_results_for_query_by_index(\n",
    "        query=preprocess_doc(doc),\n",
    "        index=\"val_100_profile_str,test_100_profile_str,train_100_profile_str\",\n",
    "        max_hits=max_hits\n",
    "    )\n",
    "    results_from_test_set = [\n",
    "        (idx, result) for (idx, result) in enumerate(results) if result['_index'] == 'test_100_profile_str'\n",
    "    ]\n",
    "    # print(len(results_from_test_set), \"results from test set\")\n",
    "    \n",
    "    for result_idx, result in enumerate(results):\n",
    "        if (result['_index'] == 'test_100_profile_str') and (int(result['_id']) == doc_id):\n",
    "            return result_idx\n",
    "    return float('inf')\n",
    "\n",
    "for i in range(4):\n",
    "    print(index_of_doc_id_in_results_list(dm.test_dataset[i]['document'], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0152be2a-c103-47b9-b20b-f0f05a52573e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:56<00:00,  5.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy = 69.00\n",
      "Top-10 accuracy = 83.40\n",
      "Top-100 accuracy = 92.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import tqdm\n",
    "\n",
    "k_values = [1, 10, 100]\n",
    "total_correct_by_k_doc = collections.defaultdict(lambda: 0)\n",
    "total = 1000\n",
    "for j in tqdm.trange(total):\n",
    "    result_idx = index_of_doc_id_in_results_list(dm.test_dataset[j]['document'], j)\n",
    "    for k in k_values:\n",
    "        if result_idx < k: total_correct_by_k_doc[k] += 1\n",
    "\n",
    "\n",
    "for k in k_values:\n",
    "    acc = total_correct_by_k_doc[k] / total\n",
    "    acc_str = f'Top-{k} accuracy = {acc*100.0:.2f}'\n",
    "    print(acc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e28010b3-58ec-41d1-80c6-2fb624aeb0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:58<00:00,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy = 0.00\n",
      "Top-10 accuracy = 0.10\n",
      "Top-100 accuracy = 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_correct_by_k_lex = collections.defaultdict(lambda: 0)\n",
    "total = 1000\n",
    "for j in tqdm.trange(total):\n",
    "    result_idx = index_of_doc_id_in_results_list(dm.test_dataset[j]['document_redact_lexical'], j)\n",
    "    for k in k_values:\n",
    "        if result_idx < k: total_correct_by_k_lex[k] += 1\n",
    "\n",
    "        \n",
    "for k in k_values:\n",
    "    acc = total_correct_by_k_lex[k] / total\n",
    "    acc_str = f'Top-{k} accuracy = {acc*100.0:.2f}'\n",
    "    print(acc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f9bb5a5-515a-4dab-9fc5-7978bb62cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:29<00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy = 0.10\n",
      "Top-10 accuracy = 0.60\n",
      "Top-100 accuracy = 11.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_correct_by_k_ner = collections.defaultdict(lambda: 0)\n",
    "total = 1000\n",
    "for j in tqdm.trange(total):\n",
    "    result_idx = index_of_doc_id_in_results_list(dm.test_dataset[j]['document_redact_ner_bert'], j)\n",
    "    for k in k_values:\n",
    "        if result_idx < k: total_correct_by_k_ner[k] += 1\n",
    "\n",
    "        \n",
    "for k in k_values:\n",
    "    acc = total_correct_by_k_ner[k] / total\n",
    "    acc_str = f'Top-{k} accuracy = {acc*100.0:.2f}'\n",
    "    print(acc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e7522-63d4-4036-b734-e3b4d8fcd927",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
